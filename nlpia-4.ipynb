{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fe119f7db40>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "zip('cat dog apple lion NYC love'.split(), np.random.rand(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.7385134223129501),\n",
       " ('dog', 0.18660946591739314),\n",
       " ('apple', 0.19279064615127883),\n",
       " ('lion', 0.0886422493017307),\n",
       " ('NYC', 0.3194626604706511),\n",
       " ('love', 0.848490477522399)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip('cat dog apple lion NYC love'.split(), np.random.rand(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:00<00:00, 261460.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>apple</th>\n",
       "      <th>lion</th>\n",
       "      <th>nyc</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top0</th>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top1</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top2</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat  dog  apple  lion  nyc  love\n",
       "top0 -0.6 -0.4    0.5  -0.3  0.4  -0.1\n",
       "top1 -0.1 -0.3   -0.4  -0.1  0.1   0.8\n",
       "top2 -0.3  0.8   -0.1  -0.5  0.0   0.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpia.book.examples.ch04_catdog_lsa_3x6x16 import word_topic_vectors\n",
    "word_topic_vectors.T.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:00<00:00, 446599.98it/s]\n",
      "100%|██████████| 263/263 [00:00<00:00, 463878.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>apple</th>\n",
       "      <th>lion</th>\n",
       "      <th>nyc</th>\n",
       "      <th>love</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>NYC is the Big Apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>NYC is known as the Big Apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I love NYC!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>I wore a hat to the Big Apple party in NYC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Come to NYC. See the Big Apple!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Manhattan is called the Big Apple.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>New York is a big city for a small cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The lion, a big cat, is the king of the jungle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>I love my pet cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I love New York City (NYC).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Your dog chased my cat.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat dog apple lion nyc love                                             text\n",
       "0              1        1                                 NYC is the Big Apple.\n",
       "1              1        1                        NYC is known as the Big Apple.\n",
       "2                       1    1                                      I love NYC!\n",
       "3              1        1           I wore a hat to the Big Apple party in NYC.\n",
       "4              1        1                       Come to NYC. See the Big Apple!\n",
       "5              1                             Manhattan is called the Big Apple.\n",
       "6    1                                  New York is a big city for a small cat.\n",
       "7    1              1           The lion, a big cat, is the king of the jungle.\n",
       "8    1                       1                               I love my pet cat.\n",
       "9                       1    1                      I love New York City (NYC).\n",
       "10   1   1                                              Your dog chased my cat."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpia.book.examples.ch04_catdog_lsa_sorted import lsa_models, prettify_tdm\n",
    "bow_svd, tfidf_svd = lsa_models()\n",
    "prettify_tdm(**bow_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyc</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9  10\n",
       "cat    0  0  0  0  0  0  1  1  1  0   1\n",
       "dog    0  0  0  0  0  0  0  0  0  0   1\n",
       "apple  1  1  0  1  1  1  0  0  0  0   0\n",
       "lion   0  0  0  0  0  0  0  1  0  0   0\n",
       "nyc    1  1  1  1  1  0  0  0  0  1   0\n",
       "love   0  0  1  0  0  0  0  0  1  1   0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = bow_svd['tdm']\n",
    "tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyc</th>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5\n",
       "cat   -0.04  0.83 -0.38 -0.00  0.11 -0.38\n",
       "dog   -0.00  0.21 -0.18 -0.71 -0.39  0.52\n",
       "apple -0.62 -0.21 -0.51  0.00  0.49  0.27\n",
       "lion  -0.00  0.21 -0.18  0.71 -0.39  0.52\n",
       "nyc   -0.75  0.00  0.24 -0.00 -0.52 -0.32\n",
       "love  -0.22  0.42  0.69  0.00  0.41  0.37"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "U, s, Vt = np.linalg.svd(tdm)\n",
    "import pandas as pd\n",
    "pd.DataFrame(U, index=tdm.index).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1, 2.2, 1.8, 1. , 0.8, 0.5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.zeros((len(U), len(Vt)))\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55, 0.55, 0.55, 0.55, 0.55, 0.55])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = []\n",
    "for numdim in range(len(s), 0, -1):\n",
    "    S[numdim-1, numdim-1] = 0\n",
    "    reconstructed_tdm = U.dot(S).dot(Vt)\n",
    "    err.append(np.sqrt(((reconstructed_tdm - tdm).values.flatten() ** 2).sum() / np.product(tdm.shape)))\n",
    "np.array(err).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SMS Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sms0',\n",
       " 'sms1',\n",
       " 'sms2!',\n",
       " 'sms3',\n",
       " 'sms4',\n",
       " 'sms5!',\n",
       " 'sms6',\n",
       " 'sms7',\n",
       " 'sms8!',\n",
       " 'sms9!',\n",
       " 'sms10',\n",
       " 'sms11!',\n",
       " 'sms12!',\n",
       " 'sms13',\n",
       " 'sms14',\n",
       " 'sms15!',\n",
       " 'sms16',\n",
       " 'sms17',\n",
       " 'sms18',\n",
       " 'sms19!',\n",
       " 'sms20',\n",
       " 'sms21',\n",
       " 'sms22',\n",
       " 'sms23',\n",
       " 'sms24',\n",
       " 'sms25',\n",
       " 'sms26',\n",
       " 'sms27',\n",
       " 'sms28',\n",
       " 'sms29',\n",
       " 'sms30',\n",
       " 'sms31',\n",
       " 'sms32',\n",
       " 'sms33',\n",
       " 'sms34!',\n",
       " 'sms35',\n",
       " 'sms36',\n",
       " 'sms37',\n",
       " 'sms38',\n",
       " 'sms39',\n",
       " 'sms40',\n",
       " 'sms41',\n",
       " 'sms42!',\n",
       " 'sms43',\n",
       " 'sms44',\n",
       " 'sms45',\n",
       " 'sms46',\n",
       " 'sms47',\n",
       " 'sms48',\n",
       " 'sms49',\n",
       " 'sms50',\n",
       " 'sms51',\n",
       " 'sms52',\n",
       " 'sms53',\n",
       " 'sms54!',\n",
       " 'sms55',\n",
       " 'sms56!',\n",
       " 'sms57',\n",
       " 'sms58',\n",
       " 'sms59',\n",
       " 'sms60',\n",
       " 'sms61',\n",
       " 'sms62',\n",
       " 'sms63',\n",
       " 'sms64',\n",
       " 'sms65!',\n",
       " 'sms66',\n",
       " 'sms67!',\n",
       " 'sms68!',\n",
       " 'sms69',\n",
       " 'sms70',\n",
       " 'sms71',\n",
       " 'sms72',\n",
       " 'sms73',\n",
       " 'sms74',\n",
       " 'sms75',\n",
       " 'sms76',\n",
       " 'sms77',\n",
       " 'sms78',\n",
       " 'sms79',\n",
       " 'sms80',\n",
       " 'sms81',\n",
       " 'sms82',\n",
       " 'sms83',\n",
       " 'sms84',\n",
       " 'sms85',\n",
       " 'sms86',\n",
       " 'sms87',\n",
       " 'sms88',\n",
       " 'sms89',\n",
       " 'sms90',\n",
       " 'sms91',\n",
       " 'sms92',\n",
       " 'sms93!',\n",
       " 'sms94',\n",
       " 'sms95!',\n",
       " 'sms96',\n",
       " 'sms97',\n",
       " 'sms98',\n",
       " 'sms99',\n",
       " 'sms100',\n",
       " 'sms101',\n",
       " 'sms102',\n",
       " 'sms103',\n",
       " 'sms104',\n",
       " 'sms105',\n",
       " 'sms106',\n",
       " 'sms107',\n",
       " 'sms108',\n",
       " 'sms109',\n",
       " 'sms110',\n",
       " 'sms111',\n",
       " 'sms112',\n",
       " 'sms113',\n",
       " 'sms114!',\n",
       " 'sms115',\n",
       " 'sms116',\n",
       " 'sms117!',\n",
       " 'sms118',\n",
       " 'sms119',\n",
       " 'sms120!',\n",
       " 'sms121!',\n",
       " 'sms122',\n",
       " 'sms123!',\n",
       " 'sms124',\n",
       " 'sms125',\n",
       " 'sms126',\n",
       " 'sms127',\n",
       " 'sms128',\n",
       " 'sms129',\n",
       " 'sms130',\n",
       " 'sms131',\n",
       " 'sms132',\n",
       " 'sms133',\n",
       " 'sms134!',\n",
       " 'sms135!',\n",
       " 'sms136',\n",
       " 'sms137',\n",
       " 'sms138',\n",
       " 'sms139!',\n",
       " 'sms140',\n",
       " 'sms141',\n",
       " 'sms142',\n",
       " 'sms143',\n",
       " 'sms144',\n",
       " 'sms145',\n",
       " 'sms146',\n",
       " 'sms147!',\n",
       " 'sms148',\n",
       " 'sms149',\n",
       " 'sms150',\n",
       " 'sms151',\n",
       " 'sms152',\n",
       " 'sms153',\n",
       " 'sms154',\n",
       " 'sms155',\n",
       " 'sms156',\n",
       " 'sms157',\n",
       " 'sms158',\n",
       " 'sms159!',\n",
       " 'sms160!',\n",
       " 'sms161',\n",
       " 'sms162',\n",
       " 'sms163',\n",
       " 'sms164!',\n",
       " 'sms165!',\n",
       " 'sms166',\n",
       " 'sms167!',\n",
       " 'sms168',\n",
       " 'sms169',\n",
       " 'sms170',\n",
       " 'sms171',\n",
       " 'sms172',\n",
       " 'sms173',\n",
       " 'sms174',\n",
       " 'sms175',\n",
       " 'sms176',\n",
       " 'sms177',\n",
       " 'sms178',\n",
       " 'sms179',\n",
       " 'sms180',\n",
       " 'sms181',\n",
       " 'sms182',\n",
       " 'sms183',\n",
       " 'sms184',\n",
       " 'sms185',\n",
       " 'sms186',\n",
       " 'sms187',\n",
       " 'sms188!',\n",
       " 'sms189',\n",
       " 'sms190',\n",
       " 'sms191!',\n",
       " 'sms192',\n",
       " 'sms193',\n",
       " 'sms194',\n",
       " 'sms195',\n",
       " 'sms196',\n",
       " 'sms197',\n",
       " 'sms198',\n",
       " 'sms199',\n",
       " 'sms200',\n",
       " 'sms201',\n",
       " 'sms202',\n",
       " 'sms203',\n",
       " 'sms204',\n",
       " 'sms205',\n",
       " 'sms206',\n",
       " 'sms207',\n",
       " 'sms208',\n",
       " 'sms209',\n",
       " 'sms210',\n",
       " 'sms211',\n",
       " 'sms212',\n",
       " 'sms213',\n",
       " 'sms214',\n",
       " 'sms215',\n",
       " 'sms216',\n",
       " 'sms217',\n",
       " 'sms218',\n",
       " 'sms219',\n",
       " 'sms220',\n",
       " 'sms221',\n",
       " 'sms222',\n",
       " 'sms223',\n",
       " 'sms224',\n",
       " 'sms225!',\n",
       " 'sms226',\n",
       " 'sms227!',\n",
       " 'sms228',\n",
       " 'sms229',\n",
       " 'sms230',\n",
       " 'sms231',\n",
       " 'sms232',\n",
       " 'sms233',\n",
       " 'sms234',\n",
       " 'sms235!',\n",
       " 'sms236',\n",
       " 'sms237',\n",
       " 'sms238',\n",
       " 'sms239',\n",
       " 'sms240!',\n",
       " 'sms241',\n",
       " 'sms242',\n",
       " 'sms243',\n",
       " 'sms244',\n",
       " 'sms245',\n",
       " 'sms246',\n",
       " 'sms247',\n",
       " 'sms248',\n",
       " 'sms249',\n",
       " 'sms250!',\n",
       " 'sms251',\n",
       " 'sms252',\n",
       " 'sms253',\n",
       " 'sms254',\n",
       " 'sms255',\n",
       " 'sms256',\n",
       " 'sms257',\n",
       " 'sms258',\n",
       " 'sms259!',\n",
       " 'sms260',\n",
       " 'sms261',\n",
       " 'sms262',\n",
       " 'sms263',\n",
       " 'sms264!',\n",
       " 'sms265',\n",
       " 'sms266',\n",
       " 'sms267',\n",
       " 'sms268!',\n",
       " 'sms269',\n",
       " 'sms270!',\n",
       " 'sms271',\n",
       " 'sms272',\n",
       " 'sms273!',\n",
       " 'sms274',\n",
       " 'sms275',\n",
       " 'sms276',\n",
       " 'sms277',\n",
       " 'sms278',\n",
       " 'sms279',\n",
       " 'sms280',\n",
       " 'sms281',\n",
       " 'sms282',\n",
       " 'sms283',\n",
       " 'sms284',\n",
       " 'sms285',\n",
       " 'sms286',\n",
       " 'sms287',\n",
       " 'sms288',\n",
       " 'sms289',\n",
       " 'sms290',\n",
       " 'sms291',\n",
       " 'sms292!',\n",
       " 'sms293',\n",
       " 'sms294',\n",
       " 'sms295',\n",
       " 'sms296',\n",
       " 'sms297',\n",
       " 'sms298',\n",
       " 'sms299',\n",
       " 'sms300!',\n",
       " 'sms301',\n",
       " 'sms302',\n",
       " 'sms303',\n",
       " 'sms304',\n",
       " 'sms305',\n",
       " 'sms306',\n",
       " 'sms307',\n",
       " 'sms308!',\n",
       " 'sms309',\n",
       " 'sms310',\n",
       " 'sms311!',\n",
       " 'sms312',\n",
       " 'sms313',\n",
       " 'sms314',\n",
       " 'sms315',\n",
       " 'sms316',\n",
       " 'sms317',\n",
       " 'sms318',\n",
       " 'sms319',\n",
       " 'sms320',\n",
       " 'sms321',\n",
       " 'sms322',\n",
       " 'sms323',\n",
       " 'sms324!',\n",
       " 'sms325',\n",
       " 'sms326',\n",
       " 'sms327',\n",
       " 'sms328',\n",
       " 'sms329!',\n",
       " 'sms330',\n",
       " 'sms331',\n",
       " 'sms332',\n",
       " 'sms333',\n",
       " 'sms334',\n",
       " 'sms335',\n",
       " 'sms336',\n",
       " 'sms337',\n",
       " 'sms338',\n",
       " 'sms339',\n",
       " 'sms340',\n",
       " 'sms341',\n",
       " 'sms342!',\n",
       " 'sms343',\n",
       " 'sms344',\n",
       " 'sms345',\n",
       " 'sms346',\n",
       " 'sms347',\n",
       " 'sms348',\n",
       " 'sms349',\n",
       " 'sms350',\n",
       " 'sms351',\n",
       " 'sms352!',\n",
       " 'sms353',\n",
       " 'sms354!',\n",
       " 'sms355!',\n",
       " 'sms356',\n",
       " 'sms357',\n",
       " 'sms358',\n",
       " 'sms359',\n",
       " 'sms360',\n",
       " 'sms361',\n",
       " 'sms362!',\n",
       " 'sms363',\n",
       " 'sms364!',\n",
       " 'sms365',\n",
       " 'sms366!',\n",
       " 'sms367',\n",
       " 'sms368!',\n",
       " 'sms369',\n",
       " 'sms370',\n",
       " 'sms371',\n",
       " 'sms372',\n",
       " 'sms373',\n",
       " 'sms374',\n",
       " 'sms375',\n",
       " 'sms376',\n",
       " 'sms377',\n",
       " 'sms378!',\n",
       " 'sms379',\n",
       " 'sms380',\n",
       " 'sms381',\n",
       " 'sms382',\n",
       " 'sms383',\n",
       " 'sms384',\n",
       " 'sms385',\n",
       " 'sms386',\n",
       " 'sms387',\n",
       " 'sms388',\n",
       " 'sms389',\n",
       " 'sms390',\n",
       " 'sms391',\n",
       " 'sms392',\n",
       " 'sms393',\n",
       " 'sms394',\n",
       " 'sms395',\n",
       " 'sms396',\n",
       " 'sms397',\n",
       " 'sms398',\n",
       " 'sms399',\n",
       " 'sms400',\n",
       " 'sms401!',\n",
       " 'sms402',\n",
       " 'sms403',\n",
       " 'sms404',\n",
       " 'sms405',\n",
       " 'sms406',\n",
       " 'sms407',\n",
       " 'sms408',\n",
       " 'sms409',\n",
       " 'sms410',\n",
       " 'sms411',\n",
       " 'sms412',\n",
       " 'sms413!',\n",
       " 'sms414',\n",
       " 'sms415',\n",
       " 'sms416!',\n",
       " 'sms417',\n",
       " 'sms418',\n",
       " 'sms419',\n",
       " 'sms420!',\n",
       " 'sms421',\n",
       " 'sms422',\n",
       " 'sms423',\n",
       " 'sms424',\n",
       " 'sms425',\n",
       " 'sms426',\n",
       " 'sms427',\n",
       " 'sms428!',\n",
       " 'sms429!',\n",
       " 'sms430!',\n",
       " 'sms431',\n",
       " 'sms432',\n",
       " 'sms433',\n",
       " 'sms434',\n",
       " 'sms435!',\n",
       " 'sms436',\n",
       " 'sms437',\n",
       " 'sms438',\n",
       " 'sms439',\n",
       " 'sms440',\n",
       " 'sms441',\n",
       " 'sms442',\n",
       " 'sms443',\n",
       " 'sms444!',\n",
       " 'sms445',\n",
       " 'sms446',\n",
       " 'sms447',\n",
       " 'sms448!',\n",
       " 'sms449',\n",
       " 'sms450',\n",
       " 'sms451',\n",
       " 'sms452',\n",
       " 'sms453',\n",
       " 'sms454',\n",
       " 'sms455',\n",
       " 'sms456',\n",
       " 'sms457',\n",
       " 'sms458',\n",
       " 'sms459!',\n",
       " 'sms460',\n",
       " 'sms461',\n",
       " 'sms462',\n",
       " 'sms463!',\n",
       " 'sms464!',\n",
       " 'sms465',\n",
       " 'sms466',\n",
       " 'sms467',\n",
       " 'sms468',\n",
       " 'sms469',\n",
       " 'sms470',\n",
       " 'sms471',\n",
       " 'sms472!',\n",
       " 'sms473',\n",
       " 'sms474',\n",
       " 'sms475',\n",
       " 'sms476',\n",
       " 'sms477',\n",
       " 'sms478!',\n",
       " 'sms479!',\n",
       " 'sms480',\n",
       " 'sms481',\n",
       " 'sms482',\n",
       " 'sms483',\n",
       " 'sms484',\n",
       " 'sms485',\n",
       " 'sms486!',\n",
       " 'sms487',\n",
       " 'sms488!',\n",
       " 'sms489',\n",
       " 'sms490',\n",
       " 'sms491',\n",
       " 'sms492!',\n",
       " 'sms493',\n",
       " 'sms494!',\n",
       " 'sms495!',\n",
       " 'sms496',\n",
       " 'sms497',\n",
       " 'sms498',\n",
       " 'sms499!',\n",
       " 'sms500',\n",
       " 'sms501',\n",
       " 'sms502',\n",
       " 'sms503',\n",
       " 'sms504',\n",
       " 'sms505!',\n",
       " 'sms506',\n",
       " 'sms507',\n",
       " 'sms508',\n",
       " 'sms509',\n",
       " 'sms510',\n",
       " 'sms511!',\n",
       " 'sms512',\n",
       " 'sms513',\n",
       " 'sms514',\n",
       " 'sms515',\n",
       " 'sms516',\n",
       " 'sms517',\n",
       " 'sms518',\n",
       " 'sms519',\n",
       " 'sms520',\n",
       " 'sms521!',\n",
       " 'sms522',\n",
       " 'sms523!',\n",
       " 'sms524!',\n",
       " 'sms525!',\n",
       " 'sms526',\n",
       " 'sms527',\n",
       " 'sms528',\n",
       " 'sms529',\n",
       " 'sms530',\n",
       " 'sms531!',\n",
       " 'sms532',\n",
       " 'sms533!',\n",
       " 'sms534!',\n",
       " 'sms535!',\n",
       " 'sms536!',\n",
       " 'sms537',\n",
       " 'sms538',\n",
       " 'sms539',\n",
       " 'sms540',\n",
       " 'sms541',\n",
       " 'sms542',\n",
       " 'sms543',\n",
       " 'sms544',\n",
       " 'sms545',\n",
       " 'sms546',\n",
       " 'sms547',\n",
       " 'sms548',\n",
       " 'sms549',\n",
       " 'sms550',\n",
       " 'sms551',\n",
       " 'sms552',\n",
       " 'sms553',\n",
       " 'sms554',\n",
       " 'sms555!',\n",
       " 'sms556',\n",
       " 'sms557',\n",
       " 'sms558',\n",
       " 'sms559',\n",
       " 'sms560',\n",
       " 'sms561',\n",
       " 'sms562!',\n",
       " 'sms563',\n",
       " 'sms564',\n",
       " 'sms565!',\n",
       " 'sms566',\n",
       " 'sms567',\n",
       " 'sms568',\n",
       " 'sms569',\n",
       " 'sms570',\n",
       " 'sms571',\n",
       " 'sms572',\n",
       " 'sms573',\n",
       " 'sms574',\n",
       " 'sms575',\n",
       " 'sms576',\n",
       " 'sms577',\n",
       " 'sms578',\n",
       " 'sms579',\n",
       " 'sms580',\n",
       " 'sms581',\n",
       " 'sms582',\n",
       " 'sms583',\n",
       " 'sms584',\n",
       " 'sms585!',\n",
       " 'sms586',\n",
       " 'sms587',\n",
       " 'sms588',\n",
       " 'sms589',\n",
       " 'sms590!',\n",
       " 'sms591',\n",
       " 'sms592',\n",
       " 'sms593',\n",
       " 'sms594!',\n",
       " 'sms595',\n",
       " 'sms596',\n",
       " 'sms597',\n",
       " 'sms598!',\n",
       " 'sms599',\n",
       " 'sms600',\n",
       " 'sms601',\n",
       " 'sms602!',\n",
       " 'sms603',\n",
       " 'sms604',\n",
       " 'sms605',\n",
       " 'sms606',\n",
       " 'sms607',\n",
       " 'sms608',\n",
       " 'sms609',\n",
       " 'sms610!',\n",
       " 'sms611',\n",
       " 'sms612',\n",
       " 'sms613',\n",
       " 'sms614',\n",
       " 'sms615',\n",
       " 'sms616',\n",
       " 'sms617!',\n",
       " 'sms618',\n",
       " 'sms619',\n",
       " 'sms620',\n",
       " 'sms621',\n",
       " 'sms622',\n",
       " 'sms623',\n",
       " 'sms624',\n",
       " 'sms625',\n",
       " 'sms626',\n",
       " 'sms627',\n",
       " 'sms628',\n",
       " 'sms629',\n",
       " 'sms630',\n",
       " 'sms631',\n",
       " 'sms632',\n",
       " 'sms633',\n",
       " 'sms634',\n",
       " 'sms635',\n",
       " 'sms636',\n",
       " 'sms637',\n",
       " 'sms638!',\n",
       " 'sms639',\n",
       " 'sms640',\n",
       " 'sms641',\n",
       " 'sms642',\n",
       " 'sms643',\n",
       " 'sms644',\n",
       " 'sms645',\n",
       " 'sms646',\n",
       " 'sms647',\n",
       " 'sms648',\n",
       " 'sms649',\n",
       " 'sms650',\n",
       " 'sms651',\n",
       " 'sms652',\n",
       " 'sms653',\n",
       " 'sms654',\n",
       " 'sms655',\n",
       " 'sms656',\n",
       " 'sms657!',\n",
       " 'sms658',\n",
       " 'sms659',\n",
       " 'sms660',\n",
       " 'sms661',\n",
       " 'sms662!',\n",
       " 'sms663',\n",
       " 'sms664',\n",
       " 'sms665',\n",
       " 'sms666',\n",
       " 'sms667',\n",
       " 'sms668',\n",
       " 'sms669',\n",
       " 'sms670',\n",
       " 'sms671',\n",
       " 'sms672!',\n",
       " 'sms673',\n",
       " 'sms674',\n",
       " 'sms675',\n",
       " 'sms676',\n",
       " 'sms677!',\n",
       " 'sms678',\n",
       " 'sms679',\n",
       " 'sms680',\n",
       " 'sms681',\n",
       " 'sms682',\n",
       " 'sms683',\n",
       " 'sms684',\n",
       " 'sms685',\n",
       " 'sms686',\n",
       " 'sms687',\n",
       " 'sms688',\n",
       " 'sms689',\n",
       " 'sms690',\n",
       " 'sms691',\n",
       " 'sms692',\n",
       " 'sms693',\n",
       " 'sms694',\n",
       " 'sms695',\n",
       " 'sms696',\n",
       " 'sms697',\n",
       " 'sms698',\n",
       " 'sms699',\n",
       " 'sms700!',\n",
       " 'sms701',\n",
       " 'sms702',\n",
       " 'sms703!',\n",
       " 'sms704',\n",
       " 'sms705!',\n",
       " 'sms706',\n",
       " 'sms707',\n",
       " 'sms708',\n",
       " 'sms709',\n",
       " 'sms710',\n",
       " 'sms711',\n",
       " 'sms712',\n",
       " 'sms713',\n",
       " 'sms714',\n",
       " 'sms715!',\n",
       " 'sms716',\n",
       " 'sms717',\n",
       " 'sms718',\n",
       " 'sms719!',\n",
       " 'sms720',\n",
       " 'sms721',\n",
       " 'sms722',\n",
       " 'sms723',\n",
       " 'sms724!',\n",
       " 'sms725',\n",
       " 'sms726',\n",
       " 'sms727!',\n",
       " 'sms728!',\n",
       " 'sms729',\n",
       " 'sms730',\n",
       " 'sms731',\n",
       " 'sms732',\n",
       " 'sms733',\n",
       " 'sms734',\n",
       " 'sms735',\n",
       " 'sms736',\n",
       " 'sms737',\n",
       " 'sms738',\n",
       " 'sms739',\n",
       " 'sms740',\n",
       " 'sms741',\n",
       " 'sms742',\n",
       " 'sms743',\n",
       " 'sms744!',\n",
       " 'sms745',\n",
       " 'sms746!',\n",
       " 'sms747',\n",
       " 'sms748',\n",
       " 'sms749',\n",
       " 'sms750',\n",
       " 'sms751',\n",
       " 'sms752!',\n",
       " 'sms753',\n",
       " 'sms754',\n",
       " 'sms755',\n",
       " 'sms756',\n",
       " 'sms757',\n",
       " 'sms758',\n",
       " 'sms759',\n",
       " 'sms760!',\n",
       " 'sms761',\n",
       " 'sms762',\n",
       " 'sms763',\n",
       " 'sms764',\n",
       " 'sms765',\n",
       " 'sms766',\n",
       " 'sms767',\n",
       " 'sms768',\n",
       " 'sms769',\n",
       " 'sms770',\n",
       " 'sms771',\n",
       " 'sms772',\n",
       " 'sms773!',\n",
       " 'sms774',\n",
       " 'sms775!',\n",
       " 'sms776',\n",
       " 'sms777!',\n",
       " 'sms778',\n",
       " 'sms779',\n",
       " 'sms780',\n",
       " 'sms781!',\n",
       " 'sms782',\n",
       " 'sms783',\n",
       " 'sms784!',\n",
       " 'sms785',\n",
       " 'sms786',\n",
       " 'sms787',\n",
       " 'sms788',\n",
       " 'sms789',\n",
       " 'sms790',\n",
       " 'sms791',\n",
       " 'sms792!',\n",
       " 'sms793',\n",
       " 'sms794',\n",
       " 'sms795',\n",
       " 'sms796',\n",
       " 'sms797!',\n",
       " 'sms798',\n",
       " 'sms799',\n",
       " 'sms800',\n",
       " 'sms801!',\n",
       " 'sms802',\n",
       " 'sms803',\n",
       " 'sms804',\n",
       " 'sms805',\n",
       " 'sms806',\n",
       " 'sms807',\n",
       " 'sms808',\n",
       " 'sms809!',\n",
       " 'sms810',\n",
       " 'sms811',\n",
       " 'sms812',\n",
       " 'sms813',\n",
       " 'sms814',\n",
       " 'sms815',\n",
       " 'sms816',\n",
       " 'sms817',\n",
       " 'sms818!',\n",
       " 'sms819',\n",
       " 'sms820',\n",
       " 'sms821',\n",
       " 'sms822',\n",
       " 'sms823',\n",
       " 'sms824',\n",
       " 'sms825',\n",
       " 'sms826',\n",
       " 'sms827!',\n",
       " 'sms828',\n",
       " 'sms829',\n",
       " 'sms830',\n",
       " 'sms831',\n",
       " 'sms832',\n",
       " 'sms833',\n",
       " 'sms834',\n",
       " 'sms835',\n",
       " 'sms836',\n",
       " 'sms837',\n",
       " 'sms838',\n",
       " 'sms839',\n",
       " 'sms840',\n",
       " 'sms841',\n",
       " 'sms842',\n",
       " 'sms843',\n",
       " 'sms844',\n",
       " 'sms845',\n",
       " 'sms846',\n",
       " 'sms847',\n",
       " 'sms848',\n",
       " 'sms849!',\n",
       " 'sms850',\n",
       " 'sms851!',\n",
       " 'sms852',\n",
       " 'sms853',\n",
       " 'sms854',\n",
       " 'sms855',\n",
       " 'sms856',\n",
       " 'sms857',\n",
       " 'sms858',\n",
       " 'sms859',\n",
       " 'sms860!',\n",
       " 'sms861',\n",
       " 'sms862!',\n",
       " 'sms863',\n",
       " 'sms864',\n",
       " 'sms865',\n",
       " 'sms866',\n",
       " 'sms867',\n",
       " 'sms868',\n",
       " 'sms869',\n",
       " 'sms870',\n",
       " 'sms871',\n",
       " 'sms872!',\n",
       " 'sms873',\n",
       " 'sms874',\n",
       " 'sms875',\n",
       " 'sms876!',\n",
       " 'sms877',\n",
       " 'sms878',\n",
       " 'sms879',\n",
       " 'sms880!',\n",
       " 'sms881',\n",
       " 'sms882!',\n",
       " 'sms883',\n",
       " 'sms884!',\n",
       " 'sms885',\n",
       " 'sms886',\n",
       " 'sms887',\n",
       " 'sms888',\n",
       " 'sms889',\n",
       " 'sms890',\n",
       " 'sms891',\n",
       " 'sms892',\n",
       " 'sms893',\n",
       " 'sms894',\n",
       " 'sms895',\n",
       " 'sms896',\n",
       " 'sms897',\n",
       " 'sms898',\n",
       " 'sms899',\n",
       " 'sms900',\n",
       " 'sms901',\n",
       " 'sms902',\n",
       " 'sms903',\n",
       " 'sms904',\n",
       " 'sms905',\n",
       " 'sms906',\n",
       " 'sms907!',\n",
       " 'sms908',\n",
       " 'sms909',\n",
       " 'sms910',\n",
       " 'sms911',\n",
       " 'sms912',\n",
       " 'sms913',\n",
       " 'sms914',\n",
       " 'sms915',\n",
       " 'sms916',\n",
       " 'sms917',\n",
       " 'sms918!',\n",
       " 'sms919',\n",
       " 'sms920',\n",
       " 'sms921',\n",
       " 'sms922',\n",
       " 'sms923',\n",
       " 'sms924!',\n",
       " 'sms925',\n",
       " 'sms926',\n",
       " 'sms927',\n",
       " 'sms928',\n",
       " 'sms929!',\n",
       " 'sms930',\n",
       " 'sms931',\n",
       " 'sms932',\n",
       " 'sms933',\n",
       " 'sms934',\n",
       " 'sms935',\n",
       " 'sms936',\n",
       " 'sms937',\n",
       " 'sms938',\n",
       " 'sms939',\n",
       " 'sms940',\n",
       " 'sms941',\n",
       " 'sms942',\n",
       " 'sms943',\n",
       " 'sms944',\n",
       " 'sms945',\n",
       " 'sms946',\n",
       " 'sms947',\n",
       " 'sms948',\n",
       " 'sms949',\n",
       " 'sms950',\n",
       " 'sms951',\n",
       " 'sms952',\n",
       " 'sms953',\n",
       " 'sms954',\n",
       " 'sms955',\n",
       " 'sms956',\n",
       " 'sms957',\n",
       " 'sms958',\n",
       " 'sms959',\n",
       " 'sms960',\n",
       " 'sms961',\n",
       " 'sms962!',\n",
       " 'sms963!',\n",
       " 'sms964',\n",
       " 'sms965',\n",
       " 'sms966',\n",
       " 'sms967',\n",
       " 'sms968',\n",
       " 'sms969',\n",
       " 'sms970',\n",
       " 'sms971',\n",
       " 'sms972',\n",
       " 'sms973!',\n",
       " 'sms974',\n",
       " 'sms975',\n",
       " 'sms976',\n",
       " 'sms977',\n",
       " 'sms978',\n",
       " 'sms979',\n",
       " 'sms980',\n",
       " 'sms981',\n",
       " 'sms982',\n",
       " 'sms983!',\n",
       " 'sms984',\n",
       " 'sms985',\n",
       " 'sms986',\n",
       " 'sms987',\n",
       " 'sms988',\n",
       " 'sms989',\n",
       " 'sms990',\n",
       " 'sms991',\n",
       " 'sms992',\n",
       " 'sms993',\n",
       " 'sms994',\n",
       " 'sms995',\n",
       " 'sms996',\n",
       " 'sms997',\n",
       " 'sms998',\n",
       " 'sms999',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nlpia.data.loaders import get_data\n",
    "sms = get_data('sms-spam')\n",
    "index = ['sms{}{}'.format(i, '!'*j)\n",
    "        for (i,j) in zip(range(len(sms)), sms.spam)]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's now an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       spam                                                    text\n",
       "sms0      0  Go until jurong point, crazy.. Available only in bu...\n",
       "sms1      0                           Ok lar... Joking wif u oni...\n",
       "sms2!     1  Free entry in 2 a wkly comp to win FA Cup final tkt...\n",
       "sms3      0       U dun say so early hor... U c already then say...\n",
       "sms4      0  Nah I don't think he goes to usf, he lives around h...\n",
       "sms5!     1  FreeMsg Hey there darling it's been 3 week's now an..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.index = index\n",
    "sms.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate TF-IDF vectors for each messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4837x9232 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 82353 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=sms.text)\n",
    "tfidf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_docs = tfidf_docs.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9232"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4837, 9232)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_docs = pd.DataFrame(tfidf_docs)\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean()\n",
    "tfidf_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.spam.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have an imbalanced dataset and more features (words) than messages. Therefore, we are more likely to overfit and our spam filter will only dependent on spammy words being in the spammy messages. But the spammers could just use synonyms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=16)\n",
    "pca = pca.fit(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "columns = ['topic{}'.format(i) for i in range(pca.n_components)]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  topic9  topic10  topic11  topic12  \\\n",
       "sms0    0.201   0.003   0.037   0.011  -0.019  -0.053   0.039  -0.065   0.012  -0.081    0.010   -0.009   -0.008   \n",
       "sms1    0.404  -0.094  -0.078   0.051   0.100   0.047   0.023   0.065   0.024  -0.024   -0.006    0.033    0.039   \n",
       "sms2!  -0.030  -0.048   0.090  -0.067   0.091  -0.043  -0.000  -0.002  -0.057   0.050    0.127    0.021    0.019   \n",
       "sms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  -0.166  -0.073   0.063  -0.106    0.022    0.020    0.066   \n",
       "sms4    0.002   0.031   0.038   0.034  -0.075  -0.092  -0.044   0.062  -0.046   0.031    0.029   -0.010    0.029   \n",
       "sms5!  -0.016   0.059   0.014  -0.006   0.122  -0.040   0.005   0.168  -0.024   0.066    0.039    0.063   -0.010   \n",
       "\n",
       "       topic13  topic14  topic15  \n",
       "sms0    -0.030   -0.016    0.033  \n",
       "sms1    -0.031    0.054   -0.046  \n",
       "sms2!   -0.019   -0.055    0.031  \n",
       "sms3    -0.068    0.019   -0.074  \n",
       "sms4     0.029   -0.081   -0.017  \n",
       "sms5!    0.071    0.011    0.030  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.11076313e-02,  8.18235007e-03, -1.21138177e-03, ...,\n",
       "         5.71865954e-04,  5.71865954e-04,  5.71865954e-04],\n",
       "       [ 6.35352949e-02,  7.64904390e-03,  2.67509525e-04, ...,\n",
       "         1.02158841e-03,  1.02158841e-03,  1.02158841e-03],\n",
       "       [ 7.08131424e-02,  2.68897828e-02,  1.32488772e-04, ...,\n",
       "        -9.53033699e-04, -9.53033699e-04, -9.53033699e-04],\n",
       "       ...,\n",
       "       [ 1.65419479e-01, -3.86049644e-02,  2.68376203e-03, ...,\n",
       "         2.07670044e-06,  2.07670044e-06,  2.07670044e-06],\n",
       "       [-1.01381106e-02, -1.66832820e-02,  8.46081756e-04, ...,\n",
       "         6.02090474e-04,  6.02090474e-04,  6.02090474e-04],\n",
       "       [ 2.01244376e-02, -2.91443661e-02,  1.33792835e-04, ...,\n",
       "        -4.04553954e-04, -4.04553954e-04, -4.04553954e-04]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 3807,\n",
       " 'until': 8487,\n",
       " 'jurong': 4675,\n",
       " 'point': 6296,\n",
       " ',': 13,\n",
       " 'crazy': 2549,\n",
       " '..': 21,\n",
       " 'available': 1531,\n",
       " 'only': 5910,\n",
       " 'in': 4396,\n",
       " 'bugis': 1973,\n",
       " 'n': 5594,\n",
       " 'great': 3894,\n",
       " 'world': 8977,\n",
       " 'la': 4811,\n",
       " 'e': 3056,\n",
       " 'buffet': 1971,\n",
       " '...': 25,\n",
       " 'cine': 2277,\n",
       " 'there': 8071,\n",
       " 'got': 3855,\n",
       " 'amore': 1296,\n",
       " 'wat': 8736,\n",
       " 'ok': 5874,\n",
       " 'lar': 4848,\n",
       " 'joking': 4642,\n",
       " 'wif': 8875,\n",
       " 'u': 8395,\n",
       " 'oni': 5906,\n",
       " 'free': 3604,\n",
       " 'entry': 3195,\n",
       " '2': 471,\n",
       " 'a': 1054,\n",
       " 'wkly': 8933,\n",
       " 'comp': 2386,\n",
       " 'to': 8192,\n",
       " 'win': 8890,\n",
       " 'fa': 3328,\n",
       " 'cup': 2608,\n",
       " 'final': 3450,\n",
       " 'tkts': 8180,\n",
       " '21st': 497,\n",
       " 'may': 5272,\n",
       " '2005': 487,\n",
       " '.': 15,\n",
       " 'text': 8020,\n",
       " '87121': 948,\n",
       " 'receive': 6688,\n",
       " 'question': 6574,\n",
       " '(': 9,\n",
       " 'std': 7651,\n",
       " 'txt': 8379,\n",
       " 'rate': 6628,\n",
       " ')': 10,\n",
       " 't': 7889,\n",
       " '&': 7,\n",
       " \"c's\": 2020,\n",
       " 'apply': 1383,\n",
       " '08452810075': 115,\n",
       " 'over': 6003,\n",
       " '18': 438,\n",
       " \"'\": 8,\n",
       " 's': 6959,\n",
       " 'dun': 3041,\n",
       " 'say': 7034,\n",
       " 'so': 7438,\n",
       " 'early': 3069,\n",
       " 'hor': 4207,\n",
       " 'c': 2019,\n",
       " 'already': 1268,\n",
       " 'then': 8065,\n",
       " 'nah': 5606,\n",
       " 'i': 4311,\n",
       " \"don't\": 2948,\n",
       " 'think': 8092,\n",
       " 'he': 4048,\n",
       " 'goes': 3819,\n",
       " 'usf': 8537,\n",
       " 'lives': 5004,\n",
       " 'around': 1435,\n",
       " 'here': 4104,\n",
       " 'though': 8111,\n",
       " 'freemsg': 3613,\n",
       " 'hey': 4116,\n",
       " 'darling': 2666,\n",
       " \"it's\": 4535,\n",
       " 'been': 1693,\n",
       " '3': 591,\n",
       " \"week's\": 8788,\n",
       " 'now': 5784,\n",
       " 'and': 1310,\n",
       " 'no': 5732,\n",
       " 'word': 8967,\n",
       " 'back': 1584,\n",
       " '!': 0,\n",
       " \"i'd\": 4312,\n",
       " 'like': 4954,\n",
       " 'some': 7454,\n",
       " 'fun': 3677,\n",
       " 'you': 9158,\n",
       " 'up': 8489,\n",
       " 'for': 3552,\n",
       " 'it': 4533,\n",
       " 'still': 7674,\n",
       " '?': 1037,\n",
       " 'tb': 7955,\n",
       " 'xxx': 9097,\n",
       " 'chgs': 2230,\n",
       " 'send': 7127,\n",
       " '£': 9216,\n",
       " '1.50': 344,\n",
       " 'rcv': 6641,\n",
       " 'even': 3240,\n",
       " 'my': 5584,\n",
       " 'brother': 1942,\n",
       " 'is': 4519,\n",
       " 'not': 5769,\n",
       " 'speak': 7529,\n",
       " 'with': 8918,\n",
       " 'me': 5281,\n",
       " 'they': 8083,\n",
       " 'treat': 8312,\n",
       " 'aids': 1214,\n",
       " 'patent': 6106,\n",
       " 'as': 1452,\n",
       " 'per': 6148,\n",
       " 'your': 9171,\n",
       " 'request': 6796,\n",
       " 'melle': 5315,\n",
       " 'oru': 5968,\n",
       " 'minnaminunginte': 5386,\n",
       " 'nurungu': 5807,\n",
       " 'vettam': 8599,\n",
       " 'has': 4022,\n",
       " 'set': 7154,\n",
       " 'callertune': 2047,\n",
       " 'all': 1253,\n",
       " 'callers': 2046,\n",
       " 'press': 6418,\n",
       " '*': 11,\n",
       " '9': 982,\n",
       " 'copy': 2489,\n",
       " 'friends': 3634,\n",
       " 'winner': 8900,\n",
       " 'valued': 8569,\n",
       " 'network': 5678,\n",
       " 'customer': 2620,\n",
       " 'have': 4036,\n",
       " 'selected': 7113,\n",
       " 'receivea': 6689,\n",
       " '900': 986,\n",
       " 'prize': 6450,\n",
       " 'reward': 6851,\n",
       " 'claim': 2283,\n",
       " 'call': 2038,\n",
       " '09061701461': 263,\n",
       " 'code': 2344,\n",
       " 'kl341': 4771,\n",
       " 'valid': 8565,\n",
       " '12': 384,\n",
       " 'hours': 4226,\n",
       " 'had': 3965,\n",
       " 'mobile': 5441,\n",
       " '11': 371,\n",
       " 'months': 5484,\n",
       " 'or': 5946,\n",
       " 'more': 5489,\n",
       " 'r': 6590,\n",
       " 'entitled': 3192,\n",
       " 'update': 8495,\n",
       " 'the': 8052,\n",
       " 'latest': 4862,\n",
       " 'colour': 2364,\n",
       " 'mobiles': 5442,\n",
       " 'camera': 2058,\n",
       " 'co': 2333,\n",
       " 'on': 5897,\n",
       " '08002986030': 99,\n",
       " \"i'm\": 4314,\n",
       " 'gonna': 3834,\n",
       " 'be': 1669,\n",
       " 'home': 4176,\n",
       " 'soon': 7483,\n",
       " 'want': 8715,\n",
       " 'talk': 7921,\n",
       " 'about': 1076,\n",
       " 'this': 8100,\n",
       " 'stuff': 7741,\n",
       " 'anymore': 1350,\n",
       " 'tonight': 8235,\n",
       " 'k': 4683,\n",
       " \"i've\": 4316,\n",
       " 'cried': 2566,\n",
       " 'enough': 3182,\n",
       " 'today': 8199,\n",
       " 'six': 7341,\n",
       " 'chances': 2172,\n",
       " 'cash': 2116,\n",
       " 'from': 3652,\n",
       " '100': 354,\n",
       " '20,000': 482,\n",
       " 'pounds': 6357,\n",
       " '>': 1035,\n",
       " 'csh': 2584,\n",
       " '87575': 952,\n",
       " 'cost': 2501,\n",
       " '150p': 415,\n",
       " '/': 27,\n",
       " 'day': 2683,\n",
       " '6days': 827,\n",
       " '16': 431,\n",
       " '+': 12,\n",
       " 'tsandcs': 8344,\n",
       " 'reply': 6788,\n",
       " 'hl': 4148,\n",
       " '4': 659,\n",
       " 'info': 4433,\n",
       " 'urgent': 8513,\n",
       " 'won': 8950,\n",
       " '1': 337,\n",
       " 'week': 8787,\n",
       " 'membership': 5321,\n",
       " 'our': 5980,\n",
       " '100,000': 355,\n",
       " 'jackpot': 4564,\n",
       " ':': 1006,\n",
       " '81010': 900,\n",
       " 'www.dbuk.net': 9039,\n",
       " 'lccltd': 4880,\n",
       " 'pobox': 6286,\n",
       " '4403ldnw1a7rw18': 696,\n",
       " 'searching': 7081,\n",
       " 'right': 6863,\n",
       " 'words': 8968,\n",
       " 'thank': 8037,\n",
       " 'breather': 1912,\n",
       " 'promise': 6487,\n",
       " 'wont': 8958,\n",
       " 'take': 7913,\n",
       " 'help': 4089,\n",
       " 'granted': 3883,\n",
       " 'will': 8887,\n",
       " 'fulfil': 3673,\n",
       " 'wonderful': 8955,\n",
       " 'blessing': 1802,\n",
       " 'at': 1488,\n",
       " 'times': 8158,\n",
       " 'date': 2675,\n",
       " 'sunday': 7805,\n",
       " 'xxxmobilemovieclub': 9098,\n",
       " 'use': 8531,\n",
       " 'credit': 2556,\n",
       " 'click': 2306,\n",
       " 'wap': 8719,\n",
       " 'link': 4977,\n",
       " 'next': 5696,\n",
       " 'message': 5340,\n",
       " 'http://wap': 4259,\n",
       " 'xxxmobilemovieclub.com': 9099,\n",
       " '=': 1031,\n",
       " 'qjkgighjjgcbl': 6566,\n",
       " 'oh': 5869,\n",
       " 'watching': 8743,\n",
       " ':)': 1008,\n",
       " 'eh': 3116,\n",
       " 'remember': 6755,\n",
       " 'how': 4233,\n",
       " 'spell': 7545,\n",
       " 'his': 4139,\n",
       " 'name': 5612,\n",
       " 'yes': 9137,\n",
       " 'did': 2823,\n",
       " 'v': 8553,\n",
       " 'naughty': 5635,\n",
       " 'make': 5193,\n",
       " 'wet': 8828,\n",
       " 'fine': 3458,\n",
       " 'if': 4350,\n",
       " 'that': 8045,\n",
       " '\\x92': 9211,\n",
       " 'way': 8753,\n",
       " 'feel': 3400,\n",
       " 'its': 4546,\n",
       " 'gota': 3856,\n",
       " 'b': 1560,\n",
       " 'england': 3173,\n",
       " 'macedonia': 5156,\n",
       " '-': 14,\n",
       " 'dont': 2952,\n",
       " 'miss': 5402,\n",
       " 'goals': 3812,\n",
       " 'team': 7968,\n",
       " 'news': 5692,\n",
       " 'ur': 8510,\n",
       " 'national': 5629,\n",
       " '87077': 947,\n",
       " 'eg': 3109,\n",
       " 'try': 8340,\n",
       " 'wales': 8695,\n",
       " 'scotland': 7060,\n",
       " '4txt': 737,\n",
       " 'ú1': 9220,\n",
       " '20': 481,\n",
       " 'poboxox': 6287,\n",
       " '36504w45wq': 629,\n",
       " 'seriously': 7147,\n",
       " '‘': 9225,\n",
       " 'm': 5139,\n",
       " 'going': 3823,\n",
       " 'ha': 3961,\n",
       " 'ü': 9221,\n",
       " 'pay': 6119,\n",
       " 'first': 3476,\n",
       " 'when': 8840,\n",
       " 'da': 2639,\n",
       " 'stock': 7678,\n",
       " 'comin': 2376,\n",
       " 'aft': 1182,\n",
       " 'finish': 3462,\n",
       " 'lunch': 5121,\n",
       " 'str': 7702,\n",
       " 'down': 2974,\n",
       " 'lor': 5058,\n",
       " 'ard': 1410,\n",
       " 'smth': 7422,\n",
       " 'ffffffffff': 3420,\n",
       " 'alright': 1269,\n",
       " 'can': 2062,\n",
       " 'meet': 5303,\n",
       " 'sooner': 7485,\n",
       " 'just': 4677,\n",
       " 'forced': 3554,\n",
       " 'myself': 5591,\n",
       " 'eat': 3081,\n",
       " 'slice': 7372,\n",
       " 'really': 6670,\n",
       " 'hungry': 4287,\n",
       " 'tho': 8107,\n",
       " 'sucks': 7778,\n",
       " 'mark': 5230,\n",
       " 'getting': 3767,\n",
       " 'worried': 8981,\n",
       " 'knows': 4782,\n",
       " 'sick': 7289,\n",
       " 'turn': 8362,\n",
       " 'pizza': 6238,\n",
       " 'lol': 5035,\n",
       " 'always': 1279,\n",
       " 'convincing': 2476,\n",
       " 'catch': 2128,\n",
       " 'bus': 1993,\n",
       " 'are': 1411,\n",
       " 'frying': 3660,\n",
       " 'an': 1305,\n",
       " 'egg': 3111,\n",
       " 'tea': 7962,\n",
       " 'eating': 3084,\n",
       " \"mom's\": 5463,\n",
       " 'left': 4901,\n",
       " 'dinner': 2858,\n",
       " 'do': 2909,\n",
       " 'love': 5081,\n",
       " \"we're\": 8760,\n",
       " 'packing': 6032,\n",
       " 'car': 2085,\n",
       " \"i'll\": 4313,\n",
       " 'let': 4923,\n",
       " 'know': 4779,\n",
       " \"there's\": 8074,\n",
       " 'room': 6906,\n",
       " 'ahhh': 1209,\n",
       " 'work': 8970,\n",
       " 'vaguely': 8560,\n",
       " 'what': 8832,\n",
       " 'does': 2923,\n",
       " 'wait': 8689,\n",
       " \"that's\": 8048,\n",
       " 'clear': 2300,\n",
       " 'were': 8817,\n",
       " 'sure': 7832,\n",
       " 'being': 1713,\n",
       " 'sarcastic': 7010,\n",
       " 'why': 8868,\n",
       " 'x': 9076,\n",
       " \"doesn't\": 2926,\n",
       " 'live': 5000,\n",
       " 'us': 8525,\n",
       " 'yeah': 9125,\n",
       " 'was': 8728,\n",
       " 'apologetic': 1371,\n",
       " 'fallen': 3352,\n",
       " 'out': 5983,\n",
       " 'she': 7199,\n",
       " 'actin': 1123,\n",
       " 'spoilt': 7572,\n",
       " 'child': 2238,\n",
       " 'caught': 2132,\n",
       " 'till': 8152,\n",
       " 'but': 1999,\n",
       " 'we': 8757,\n",
       " \"won't\": 8951,\n",
       " 'doing': 2938,\n",
       " 'too': 8242,\n",
       " 'badly': 1589,\n",
       " 'cheers': 2214,\n",
       " 'tell': 7985,\n",
       " 'anything': 1356,\n",
       " 'fear': 3391,\n",
       " 'of': 5847,\n",
       " 'fainting': 3344,\n",
       " 'housework': 4231,\n",
       " 'quick': 6577,\n",
       " 'cuppa': 2610,\n",
       " 'thanks': 8038,\n",
       " 'subscription': 7766,\n",
       " 'ringtone': 6872,\n",
       " 'uk': 8415,\n",
       " 'charged': 2184,\n",
       " '5': 745,\n",
       " 'month': 5479,\n",
       " 'please': 6265,\n",
       " 'confirm': 2431,\n",
       " 'by': 2016,\n",
       " 'replying': 6790,\n",
       " 'yup': 9192,\n",
       " 'look': 5046,\n",
       " 'timings': 8162,\n",
       " 'msg': 5528,\n",
       " 'again': 1190,\n",
       " 'xuhui': 9093,\n",
       " 'learn': 4892,\n",
       " '2nd': 567,\n",
       " 'her': 4099,\n",
       " 'lesson': 4921,\n",
       " '8am': 974,\n",
       " 'oops': 5921,\n",
       " \"roommate's\": 6909,\n",
       " 'done': 2950,\n",
       " 'see': 7098,\n",
       " 'letter': 4926,\n",
       " 'decide': 2711,\n",
       " 'hello': 4084,\n",
       " \"how's\": 4235,\n",
       " 'saturday': 7024,\n",
       " 'texting': 8027,\n",
       " \"you'd\": 9159,\n",
       " 'decided': 2712,\n",
       " 'tomo': 8224,\n",
       " 'trying': 8342,\n",
       " 'invite': 4493,\n",
       " 'pls': 6273,\n",
       " 'ahead': 1208,\n",
       " 'watts': 8751,\n",
       " 'wanted': 8716,\n",
       " 'weekend': 8791,\n",
       " 'abiola': 1072,\n",
       " 'forget': 3560,\n",
       " 'need': 5654,\n",
       " 'crave': 2546,\n",
       " 'most': 5499,\n",
       " 'sweet': 7863,\n",
       " 'arabian': 1407,\n",
       " 'steed': 7658,\n",
       " 'mmmmmm': 5431,\n",
       " 'yummy': 9187,\n",
       " '07732584351': 62,\n",
       " 'rodger': 6895,\n",
       " 'burns': 1990,\n",
       " 'tried': 8321,\n",
       " 're': 6645,\n",
       " 'sms': 7416,\n",
       " 'nokia': 5744,\n",
       " 'camcorder': 2056,\n",
       " '08000930705': 95,\n",
       " 'delivery': 2750,\n",
       " 'tomorrow': 8226,\n",
       " 'who': 8859,\n",
       " 'seeing': 7101,\n",
       " 'hope': 4198,\n",
       " 'man': 5203,\n",
       " 'well': 8807,\n",
       " 'endowed': 3163,\n",
       " 'am': 1281,\n",
       " '<#>': 1024,\n",
       " 'inches': 4401,\n",
       " 'calls': 2053,\n",
       " 'messages': 5344,\n",
       " 'missed': 5405,\n",
       " \"didn't\": 2828,\n",
       " 'get': 3760,\n",
       " 'hep': 4098,\n",
       " 'immunisation': 4379,\n",
       " 'nigeria': 5708,\n",
       " 'fair': 3345,\n",
       " 'hopefully': 4201,\n",
       " 'tyler': 8389,\n",
       " \"can't\": 2063,\n",
       " 'could': 2511,\n",
       " 'maybe': 5274,\n",
       " 'ask': 1463,\n",
       " 'bit': 1779,\n",
       " 'stubborn': 7730,\n",
       " 'hospital': 4214,\n",
       " 'kept': 4730,\n",
       " 'telling': 7986,\n",
       " 'weak': 8762,\n",
       " 'sucker': 7776,\n",
       " 'hospitals': 4215,\n",
       " 'suckers': 7777,\n",
       " 'thinked': 8093,\n",
       " 'time': 8154,\n",
       " 'saw': 7033,\n",
       " 'class': 2292,\n",
       " 'gram': 3875,\n",
       " 'usually': 8543,\n",
       " 'runs': 6949,\n",
       " 'half': 3977,\n",
       " 'eighth': 3119,\n",
       " 'smarter': 7395,\n",
       " 'gets': 3763,\n",
       " 'almost': 1264,\n",
       " 'whole': 8862,\n",
       " 'second': 7085,\n",
       " 'fyi': 3693,\n",
       " 'ride': 6862,\n",
       " 'morning': 5493,\n",
       " \"he's\": 4050,\n",
       " 'crashing': 2545,\n",
       " 'place': 6240,\n",
       " 'wow': 8997,\n",
       " 'never': 5683,\n",
       " 'realized': 6668,\n",
       " 'embarassed': 3144,\n",
       " 'accomodations': 1103,\n",
       " 'thought': 8112,\n",
       " 'liked': 4955,\n",
       " 'since': 7314,\n",
       " 'best': 1733,\n",
       " 'seemed': 7105,\n",
       " 'happy': 4011,\n",
       " '\"': 1,\n",
       " 'cave': 2136,\n",
       " 'sorry': 7494,\n",
       " 'give': 3788,\n",
       " 'offered': 5855,\n",
       " 'embarassing': 3145,\n",
       " 'ac': 1089,\n",
       " 'sptv': 7594,\n",
       " 'new': 5687,\n",
       " 'jersey': 4608,\n",
       " 'devils': 2803,\n",
       " 'detroit': 2797,\n",
       " 'red': 6711,\n",
       " 'wings': 8898,\n",
       " 'play': 6255,\n",
       " 'ice': 4330,\n",
       " 'hockey': 4161,\n",
       " 'correct': 2494,\n",
       " 'incorrect': 4412,\n",
       " 'end': 3158,\n",
       " 'mallika': 5202,\n",
       " 'sherawat': 7208,\n",
       " 'yesterday': 9141,\n",
       " 'find': 3455,\n",
       " '@': 1038,\n",
       " '<url>': 1030,\n",
       " 'congrats': 2437,\n",
       " 'year': 9126,\n",
       " 'special': 7531,\n",
       " 'cinema': 2278,\n",
       " 'pass': 6094,\n",
       " 'yours': 9176,\n",
       " '09061209465': 258,\n",
       " 'suprman': 7830,\n",
       " 'matrix': 5263,\n",
       " 'starwars': 7638,\n",
       " 'etc': 3230,\n",
       " 'bx420': 2014,\n",
       " 'ip4': 4502,\n",
       " '5we': 781,\n",
       " '150pm': 417,\n",
       " 'later': 4861,\n",
       " 'meeting': 5305,\n",
       " 'where': 8846,\n",
       " 'reached': 6652,\n",
       " 'gauti': 3728,\n",
       " 'sehwag': 7110,\n",
       " 'odi': 5846,\n",
       " 'series': 7145,\n",
       " 'pick': 6211,\n",
       " '$': 5,\n",
       " 'burger': 1985,\n",
       " 'yourself': 9177,\n",
       " 'move': 5513,\n",
       " 'pain': 6039,\n",
       " 'killing': 4754,\n",
       " 'good': 3836,\n",
       " 'joke': 4636,\n",
       " 'girls': 3785,\n",
       " 'situation': 7338,\n",
       " 'seekers': 7102,\n",
       " 'part': 6081,\n",
       " 'checking': 2208,\n",
       " 'iq': 4508,\n",
       " 'roommates': 6910,\n",
       " 'took': 8245,\n",
       " 'forever': 3557,\n",
       " 'come': 2371,\n",
       " 'double': 2966,\n",
       " 'check': 2204,\n",
       " 'hair': 3972,\n",
       " 'dresser': 2998,\n",
       " 'said': 6980,\n",
       " 'wun': 9024,\n",
       " 'cut': 2624,\n",
       " 'short': 7248,\n",
       " 'nice': 5701,\n",
       " 'pleased': 6266,\n",
       " 'advise': 1165,\n",
       " 'following': 3534,\n",
       " 'recent': 6692,\n",
       " 'review': 6849,\n",
       " 'mob': 5439,\n",
       " 'awarded': 1549,\n",
       " '1500': 414,\n",
       " 'bonus': 1844,\n",
       " '09066364589': 306,\n",
       " 'song': 7478,\n",
       " 'dedicated': 2722,\n",
       " 'which': 8853,\n",
       " 'dedicate': 2721,\n",
       " 'valuable': 8566,\n",
       " 'frnds': 3643,\n",
       " 'rply': 6925,\n",
       " 'complimentary': 2406,\n",
       " 'trip': 8322,\n",
       " 'eurodisinc': 3234,\n",
       " 'trav': 8304,\n",
       " 'aco': 1119,\n",
       " '41': 679,\n",
       " '1000': 356,\n",
       " 'dis': 2871,\n",
       " '6': 785,\n",
       " 'morefrmmob': 5490,\n",
       " 'shracomorsglsuplt': 7273,\n",
       " '10': 350,\n",
       " 'ls1': 5103,\n",
       " '3aj': 638,\n",
       " 'hear': 4062,\n",
       " 'divorce': 2900,\n",
       " 'barbie': 1620,\n",
       " 'comes': 2373,\n",
       " \"ken's\": 4728,\n",
       " 'plane': 6247,\n",
       " 'wah': 8682,\n",
       " 'lucky': 5114,\n",
       " 'save': 7029,\n",
       " 'money': 5470,\n",
       " 'hee': 4075,\n",
       " 'finished': 3464,\n",
       " 'hi': 4120,\n",
       " 'babe': 1574,\n",
       " 'im': 4368,\n",
       " 'wanna': 8713,\n",
       " 'something': 7464,\n",
       " 'xx': 9094,\n",
       " 'performed': 6155,\n",
       " 'waiting': 8692,\n",
       " 'machan': 5158,\n",
       " 'once': 5901,\n",
       " 'thats': 8051,\n",
       " 'cool': 2481,\n",
       " 'gentleman': 3751,\n",
       " 'dignity': 2848,\n",
       " 'respect': 6816,\n",
       " 'peoples': 6147,\n",
       " 'very': 8598,\n",
       " 'much': 5544,\n",
       " 'shy': 7283,\n",
       " 'pa': 6027,\n",
       " 'operate': 5928,\n",
       " 'after': 1183,\n",
       " 'same': 6996,\n",
       " 'looking': 5050,\n",
       " 'job': 4623,\n",
       " \"ta's\": 7896,\n",
       " 'earn': 3070,\n",
       " 'ah': 1204,\n",
       " 'stop': 7688,\n",
       " 'urgnt': 8517,\n",
       " 'real': 6662,\n",
       " 'yo': 9152,\n",
       " 'tickets': 8142,\n",
       " 'one': 5903,\n",
       " 'jacket': 4563,\n",
       " 'used': 8532,\n",
       " 'multis': 5553,\n",
       " 'started': 7632,\n",
       " 'requests': 6797,\n",
       " 'came': 2057,\n",
       " 'bed': 1686,\n",
       " 'coins': 2350,\n",
       " 'factory': 3335,\n",
       " 'gotta': 3860,\n",
       " 'nitros': 5727,\n",
       " 'ela': 3124,\n",
       " 'kano': 4708,\n",
       " 'il': 4362,\n",
       " 'download': 2975,\n",
       " 'wen': 8811,\n",
       " 'don': 2947,\n",
       " 'stand': 7620,\n",
       " 'close': 2313,\n",
       " 'll': 5008,\n",
       " 'another': 1332,\n",
       " 'night': 5710,\n",
       " 'spent': 7550,\n",
       " 'late': 4858,\n",
       " 'afternoon': 1185,\n",
       " 'casualty': 2126,\n",
       " 'means': 5291,\n",
       " \"haven't\": 4039,\n",
       " 'any': 1346,\n",
       " 'y': 9107,\n",
       " '42moro': 689,\n",
       " 'includes': 4405,\n",
       " 'sheets': 7203,\n",
       " 'smile': 7403,\n",
       " 'pleasure': 6268,\n",
       " 'trouble': 8328,\n",
       " 'pours': 6359,\n",
       " 'rain': 6602,\n",
       " 'sum': 7798,\n",
       " 'hurts': 4297,\n",
       " 'becoz': 1684,\n",
       " 'someone': 7457,\n",
       " 'loves': 5090,\n",
       " 'smiling': 7407,\n",
       " 'service': 7150,\n",
       " 'representative': 6794,\n",
       " '0800 169 6031': 86,\n",
       " 'between': 1741,\n",
       " '10am': 365,\n",
       " '9pm': 1002,\n",
       " 'guaranteed': 3930,\n",
       " '5000': 755,\n",
       " 'havent': 4040,\n",
       " 'planning': 6251,\n",
       " 'buy': 2004,\n",
       " 'lido': 4937,\n",
       " '530': 767,\n",
       " 'show': 7264,\n",
       " 'collected': 2358,\n",
       " 'simply': 7311,\n",
       " 'password': 6102,\n",
       " 'mix': 5421,\n",
       " '85069': 934,\n",
       " 'verify': 8594,\n",
       " 'usher': 8538,\n",
       " 'britney': 1932,\n",
       " 'fml': 3525,\n",
       " 'po': 6284,\n",
       " 'box': 1879,\n",
       " '5249': 764,\n",
       " 'mk17': 5424,\n",
       " '92h': 990,\n",
       " '450ppw': 705,\n",
       " 'telugu': 7991,\n",
       " 'movie': 5516,\n",
       " 'abt': 1084,\n",
       " 'loads': 5014,\n",
       " 'loans': 5016,\n",
       " 'wk': 8928,\n",
       " 'hols': 4174,\n",
       " 'run': 6946,\n",
       " 'forgot': 3565,\n",
       " 'hairdressers': 3974,\n",
       " 'appointment': 1386,\n",
       " 'four': 3584,\n",
       " 'shower': 7266,\n",
       " 'beforehand': 1702,\n",
       " 'cause': 2133,\n",
       " 'prob': 6456,\n",
       " 'coffee': 2345,\n",
       " 'animation': 1319,\n",
       " 'nothing': 5774,\n",
       " 'else': 3138,\n",
       " 'okay': 5877,\n",
       " 'price': 6431,\n",
       " 'long': 5042,\n",
       " 'legal': 4904,\n",
       " 'them': 8061,\n",
       " 'ave': 1536,\n",
       " 'ams': 1301,\n",
       " 'gone': 3832,\n",
       " '4the': 735,\n",
       " 'driving': 3007,\n",
       " 'test': 8014,\n",
       " 'yet': 9142,\n",
       " \"you're\": 9162,\n",
       " 'mean': 5287,\n",
       " 'guess': 3936,\n",
       " 'gave': 3729,\n",
       " 'boston': 1866,\n",
       " 'men': 5326,\n",
       " 'changed': 2174,\n",
       " 'search': 7080,\n",
       " 'location': 5019,\n",
       " 'nyc': 5819,\n",
       " 'cuz': 2631,\n",
       " 'signin': 7299,\n",
       " 'page': 6035,\n",
       " 'says': 7038,\n",
       " 'umma': 8423,\n",
       " 'life': 4940,\n",
       " 'vava': 8580,\n",
       " 'lot': 5066,\n",
       " 'dear': 2699,\n",
       " 'wishes': 8912,\n",
       " 'birthday': 1777,\n",
       " 'making': 5197,\n",
       " 'truly': 8335,\n",
       " 'memorable': 5323,\n",
       " 'aight': 1216,\n",
       " 'hit': 4141,\n",
       " 'would': 8993,\n",
       " 'ip': 4501,\n",
       " 'address': 1141,\n",
       " 'considering': 2449,\n",
       " 'computer': 2412,\n",
       " \"isn't\": 4528,\n",
       " 'minecraft': 5380,\n",
       " 'server': 7149,\n",
       " 'grumpy': 3923,\n",
       " 'old': 5889,\n",
       " 'people': 6146,\n",
       " 'mom': 5462,\n",
       " 'better': 1738,\n",
       " 'lying': 5135,\n",
       " 'jokes': 4640,\n",
       " 'worry': 8983,\n",
       " 'busy': 1998,\n",
       " 'plural': 6277,\n",
       " 'noun': 5781,\n",
       " 'research': 6802,\n",
       " 'dinner.msg': 2859,\n",
       " 'cos': 2499,\n",
       " 'things': 8091,\n",
       " 'scared': 7044,\n",
       " 'mah': 5180,\n",
       " 'loud': 5076,\n",
       " 'gent': 3749,\n",
       " 'contact': 2454,\n",
       " 'last': 4855,\n",
       " 'weekends': 8793,\n",
       " 'draw': 2989,\n",
       " 'shows': 7272,\n",
       " '09064012160': 282,\n",
       " 'k52': 4691,\n",
       " '12hrs': 398,\n",
       " '150ppm': 419,\n",
       " 'wa': 8677,\n",
       " 'openin': 5925,\n",
       " 'sentence': 7138,\n",
       " 'formal': 3569,\n",
       " 'anyway': 1360,\n",
       " 'juz': 4682,\n",
       " 'tt': 8348,\n",
       " 'eatin': 3083,\n",
       " 'puttin': 6554,\n",
       " 'weight': 8798,\n",
       " 'haha': 3968,\n",
       " 'anythin': 1355,\n",
       " 'happened': 4003,\n",
       " 'entered': 3185,\n",
       " 'cabin': 2025,\n",
       " \"b'day\": 1562,\n",
       " 'boss': 1865,\n",
       " 'felt': 3411,\n",
       " 'askd': 1464,\n",
       " 'invited': 4494,\n",
       " 'apartment': 1365,\n",
       " 'went': 8814,\n",
       " 'specially': 7536,\n",
       " 'holiday': 4171,\n",
       " 'flights': 3502,\n",
       " 'inc': 4399,\n",
       " 'operator': 5929,\n",
       " '08712778109': 166,\n",
       " '10p': 368,\n",
       " 'min': 5372,\n",
       " 'goodo': 3846,\n",
       " 'must': 5575,\n",
       " 'friday': 3626,\n",
       " 'egg-potato': 3112,\n",
       " 'ratio': 6631,\n",
       " 'tortilla': 8262,\n",
       " 'needed': 5656,\n",
       " 'hmm': 4153,\n",
       " 'uncle': 8433,\n",
       " 'informed': 4438,\n",
       " 'paying': 6124,\n",
       " 'school': 7050,\n",
       " 'directly': 2865,\n",
       " 'food': 3542,\n",
       " 'private': 6447,\n",
       " '2004': 486,\n",
       " 'account': 1107,\n",
       " 'statement': 7641,\n",
       " '07742676969': 64,\n",
       " '786': 864,\n",
       " 'unredeemed': 8477,\n",
       " 'points': 6297,\n",
       " '08719180248': 213,\n",
       " 'identifier': 4344,\n",
       " '45239': 707,\n",
       " 'expires': 3307,\n",
       " '2000': 484,\n",
       " 'caller': 2045,\n",
       " '5/9': 752,\n",
       " '03': 46,\n",
       " 'landline': 4835,\n",
       " '09064019788': 288,\n",
       " '42wr29c': 690,\n",
       " 'apples': 1381,\n",
       " 'pairs': 6044,\n",
       " 'malarky': 5199,\n",
       " 'todays': 8205,\n",
       " 'voda': 8645,\n",
       " 'numbers': 5804,\n",
       " 'ending': 3160,\n",
       " '7548': 856,\n",
       " '350': 624,\n",
       " 'award': 1548,\n",
       " 'match': 5251,\n",
       " '08712300220': 149,\n",
       " 'quoting': 6589,\n",
       " '4041': 674,\n",
       " 'standard': 7621,\n",
       " 'rates': 6629,\n",
       " 'app': 1375,\n",
       " 'sao': 7004,\n",
       " 'mu': 5542,\n",
       " 'predict': 6392,\n",
       " \"ü'll\": 9222,\n",
       " 'buying': 2007,\n",
       " 'yetunde': 9144,\n",
       " \"hasn't\": 4024,\n",
       " 'sent': 7137,\n",
       " 'bother': 1869,\n",
       " 'sending': 7129,\n",
       " 'involve': 4498,\n",
       " \"shouldn't\": 7259,\n",
       " 'imposed': 4386,\n",
       " 'apologise': 1372,\n",
       " 'girl': 3782,\n",
       " 'del': 2740,\n",
       " 'bak': 1597,\n",
       " 'lucyxx': 5118,\n",
       " 'tmorrow.pls': 8185,\n",
       " 'accomodate': 1102,\n",
       " 'answer': 1335,\n",
       " 'sunshine': 7812,\n",
       " 'quiz': 6584,\n",
       " 'q': 6559,\n",
       " 'top': 8253,\n",
       " 'sony': 7480,\n",
       " 'dvd': 3051,\n",
       " 'player': 6257,\n",
       " 'country': 2518,\n",
       " 'algarve': 1245,\n",
       " 'ansr': 1334,\n",
       " '82277': 907,\n",
       " 'sp': 7516,\n",
       " 'tyrone': 8394,\n",
       " 'laid': 4827,\n",
       " 'dogging': 2932,\n",
       " 'locations': 5020,\n",
       " 'direct': 2864,\n",
       " 'join': 4631,\n",
       " \"uk's\": 8416,\n",
       " 'largest': 4852,\n",
       " 'bt': 1958,\n",
       " 'txting': 8383,\n",
       " 'gravel': 3888,\n",
       " '69888': 822,\n",
       " 'nt': 5791,\n",
       " 'ec2a': 3086,\n",
       " '31p': 611,\n",
       " '@150p': 1039,\n",
       " 'haf': 3967,\n",
       " 'msn': 5534,\n",
       " 'yijue@hotmail.com': 9149,\n",
       " 'him': 4132,\n",
       " 'rooms': 6911,\n",
       " 'befor': 1699,\n",
       " 'activities': 1129,\n",
       " \"you'll\": 9161,\n",
       " 'msgs': 5533,\n",
       " 'chat': 2195,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDFVectorizer stores the vocab as a dicgtionary that maps each term to an index number\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([3807, 8487, 4675, 6296, 13, 2549, 21, 1531, 5910, 4396, 1973, 5594, 3894, 8977, 4811, 3056, 1971, 25, 2277, 8071, 3855, 1296, 8736, 5874, 4848, 4642, 8875, 8395, 5906, 3604, 3195, 471, 1054, 8933, 2386, 8192, 8890, 3328, 2608, 3450, 8180, 497, 5272, 487, 15, 8020, 948, 6688, 6574, 9, 7651, 8379, 6628, 10, 7889, 7, 2020, 1383, 115, 6003, 438, 8, 6959, 3041, 7034, 7438, 3069, 4207, 2019, 1268, 8065, 5606, 4311, 2948, 8092, 4048, 3819, 8537, 5004, 1435, 4104, 8111, 3613, 4116, 2666, 4535, 1693, 591, 8788, 5784, 1310, 5732, 8967, 1584, 0, 4312, 4954, 7454, 3677, 9158, 8489, 3552, 4533, 7674, 1037, 7955, 9097, 2230, 7127, 9216, 344, 6641, 3240, 5584, 1942, 4519, 5769, 7529, 8918, 5281, 8083, 8312, 1214, 6106, 1452, 6148, 9171, 6796, 5315, 5968, 5386, 5807, 8599, 4022, 7154, 2047, 1253, 2046, 6418, 11, 982, 2489, 3634, 8900, 8569, 5678, 2620, 4036, 7113, 6689, 986, 6450, 6851, 2283, 2038, 263, 2344, 4771, 8565, 384, 4226, 3965, 5441, 371, 5484, 5946, 5489, 6590, 3192, 8495, 8052, 4862, 2364, 5442, 2058, 2333, 5897, 99, 4314, 3834, 1669, 4176, 7483, 8715, 7921, 1076, 8100, 7741, 1350, 8235, 4683, 4316, 2566, 3182, 8199, 7341, 2172, 2116, 3652, 354, 482, 6357, 1035, 2584, 952, 2501, 415, 27, 2683, 827, 431, 12, 8344, 6788, 4148, 659, 4433, 8513, 8950, 337, 8787, 5321, 5980, 355, 4564, 1006, 900, 9039, 4880, 6286, 696, 7081, 6863, 8968, 8037, 1912, 6487, 8958, 7913, 4089, 3883, 8887, 3673, 8955, 1802, 1488, 8158, 2675, 7805, 9098, 8531, 2556, 2306, 8719, 4977, 5696, 5340, 4259, 9099, 1031, 6566, 5869, 8743, 1008, 3116, 6755, 4233, 7545, 4139, 5612, 9137, 2823, 8553, 5635, 5193, 8828, 3458, 4350, 8045, 9211, 8753, 3400, 4546, 3856, 1560, 3173, 5156, 14, 2952, 5402, 3812, 7968, 5692, 8510, 5629, 947, 3109, 8340, 8695, 7060, 737, 9220, 481, 6287, 629, 7147, 9225, 5139, 3823, 3961, 9221, 6119, 3476, 8840, 2639, 7678, 2376, 1182, 3462, 5121, 7702, 2974, 5058, 1410, 7422, 3420, 1269, 2062, 5303, 7485, 4677, 3554, 5591, 3081, 7372, 6670, 4287, 8107, 7778, 5230, 3767, 8981, 4782, 7289, 8362, 6238, 5035, 1279, 2476, 2128, 1993, 1411, 3660, 1305, 3111, 7962, 3084, 5463, 4901, 2858, 2909, 5081, 8760, 6032, 2085, 4313, 4923, 4779, 8074, 6906, 1209, 8970, 8560, 8832, 2923, 8689, 8048, 2300, 8817, 7832, 1713, 7010, 8868, 9076, 2926, 5000, 8525, 9125, 8728, 1371, 3352, 5983, 7199, 1123, 7572, 2238, 2132, 8152, 1999, 8757, 8951, 2938, 8242, 1589, 2214, 7985, 1356, 3391, 5847, 3344, 4231, 6577, 2610, 8038, 7766, 6872, 8415, 2184, 745, 5479, 6265, 2431, 2016, 6790, 9192, 5046, 8162, 5528, 1190, 9093, 4892, 567, 4099, 4921, 974, 5921, 6909, 2950, 7098, 4926, 2711, 4084, 4235, 7024, 8027, 9159, 2712, 8224, 8342, 4493, 6273, 1208, 8751, 8716, 8791, 1072, 3560, 5654, 2546, 5499, 7863, 1407, 7658, 5431, 9187, 62, 6895, 1990, 8321, 6645, 7416, 5744, 2056, 95, 2750, 8226, 8859, 7101, 4198, 5203, 8807, 3163, 1281, 1024, 4401, 2053, 5344, 5405, 2828, 3760, 4098, 4379, 5708, 3345, 4201, 8389, 2063, 2511, 5274, 1463, 1779, 7730, 4214, 4730, 7986, 8762, 7776, 4215, 7777, 8093, 8154, 7033, 2292, 3875, 8543, 6949, 3977, 3119, 7395, 3763, 1264, 8862, 7085, 3693, 6862, 5493, 4050, 2545, 6240, 8997, 5683, 6668, 3144, 1103, 8112, 4955, 7314, 1733, 7105, 4011, 1, 2136, 7494, 3788, 5855, 3145, 1089, 7594, 5687, 4608, 2803, 2797, 6711, 8898, 6255, 4330, 4161, 2494, 4412, 3158, 5202, 7208, 9141, 3455, 1038, 1030, 2437, 9126, 7531, 2278, 6094, 9176, 258, 7830, 5263, 7638, 3230, 2014, 4502, 781, 417, 4861, 5305, 8846, 6652, 3728, 7110, 5846, 7145, 6211, 5, 1985, 9177, 5513, 6039, 4754, 3836, 4636, 3785, 7338, 7102, 6081, 2208, 4508, 6910, 8245, 3557, 2371, 2966, 2204, 3972, 2998, 6980, 9024, 2624, 7248, 5701, 6266, 1165, 3534, 6692, 6849, 5439, 1549, 414, 1844, 306, 7478, 2722, 8853, 2721, 8566, 3643, 6925, 2406, 8322, 3234, 8304, 1119, 679, 356, 2871, 785, 5490, 7273, 350, 5103, 638, 4062, 2900, 1620, 2373, 4728, 6247, 8682, 5114, 7029, 5470, 4075, 3464, 4120, 1574, 4368, 8713, 7464, 9094, 6155, 8692, 5158, 5901, 8051, 2481, 3751, 2848, 6816, 6147, 8598, 5544, 7283, 6027, 5928, 1183, 6996, 5050, 4623, 7896, 3070, 1204, 7688, 8517, 6662, 9152, 8142, 5903, 4563, 8532, 5553, 7632, 6797, 2057, 1686, 2350, 3335, 3860, 5727, 3124, 4708, 4362, 2975, 8811, 2947, 7620, 2313, 5008, 1332, 5710, 7550, 4858, 1185, 2126, 5291, 4039, 1346, 9107, 689, 4405, 7203, 7403, 6268, 8328, 6359, 6602, 7798, 4297, 1684, 7457, 5090, 7407, 7150, 6794, 86, 1741, 365, 1002, 3930, 755, 4040, 6251, 2004, 4937, 767, 7264, 2358, 7311, 6102, 5421, 934, 8594, 8538, 1932, 3525, 6284, 1879, 764, 5424, 990, 705, 7991, 5516, 1084, 5014, 5016, 8928, 4174, 6946, 3565, 3974, 1386, 3584, 7266, 1702, 2133, 6456, 2345, 1319, 5774, 3138, 5877, 6431, 5042, 4904, 8061, 1536, 1301, 3832, 735, 3007, 8014, 9142, 9162, 5287, 3936, 3729, 1866, 5326, 2174, 7080, 5019, 5819, 2631, 7299, 6035, 7038, 8423, 4940, 8580, 5066, 2699, 8912, 1777, 5197, 8335, 5323, 1216, 4141, 8993, 4501, 1141, 2449, 2412, 4528, 5380, 7149, 3923, 5889, 6146, 5462, 1738, 5135, 4640, 8983, 1998, 6277, 5781, 6802, 2859, 2499, 8091, 7044, 5180, 5076, 3749, 2454, 4855, 8793, 2989, 7272, 282, 4691, 398, 419, 8677, 5925, 7138, 3569, 1360, 4682, 8348, 3083, 6554, 8798, 3968, 1355, 4003, 3185, 2025, 1562, 1865, 3411, 1464, 4494, 1365, 8814, 7536, 4171, 3502, 4399, 5929, 166, 368, 5372, 3846, 5575, 3626, 3112, 6631, 8262, 5656, 4153, 8433, 4438, 6124, 7050, 2865, 3542, 6447, 486, 1107, 7641, 64, 864, 8477, 6297, 213, 4344, 707, 3307, 484, 2045, 752, 46, 4835, 288, 690, 1381, 6044, 5199, 8205, 8645, 5804, 3160, 856, 624, 1548, 5251, 149, 6589, 674, 7621, 6629, 1375, 7004, 5542, 6392, 9222, 2007, 9144, 4024, 7137, 1869, 7129, 4498, 7259, 4386, 1372, 3782, 2740, 1597, 5118, 8185, 1102, 1335, 7812, 6584, 6559, 8253, 7480, 3051, 6257, 2518, 1245, 1334, 907, 7516, 8394, 4827, 2932, 5020, 2864, 4631, 8416, 4852, 1958, 8383, 3888, 822, 5791, 3086, 611, 1039, 3967, 5534, 9149, 4132, 6911, 1699, 1129, 9161, 5533, 2195, 7848, 4013, 7151, 826, 1194, 9183, 4879, 8391, 4898, 6354, 7326, 5185, 7877, 5812, 8166, 4999, 5080, 6173, 2531, 7475, 8108, 5839, 2636, 1758, 8058, 4068, 3932, 5698, 5922, 9110, 2965, 8835, 7611, 7918, 6786, 6622, 7167, 3412, 5018, 5126, 5675, 5108, 119, 8425, 4397, 1706, 6560, 6385, 4012, 2744, 7316, 1773, 7444, 8896, 3516, 5684, 8101, 6263, 8393, 3258, 2868, 3510, 8893, 7223, 7468, 5512, 2992, 8922, 2266, 4653, 5069, 8367, 4318, 3292, 3971, 5413, 1682, 1062, 4897, 4227, 4480, 1880, 5407, 1325, 9127, 57, 1438, 165, 4722, 6975, 1680, 3199, 3252, 7099, 6073, 3985, 3280, 3063, 7548, 1857, 612, 3326, 4495, 3631, 692, 9058, 3642, 800, 1611, 5954, 7256, 2458, 3859, 1610, 4479, 5333, 2604, 5455, 265, 6964, 1542, 5411, 8917, 1723, 5904, 3220, 3363, 1917, 5660, 4826, 2402, 3568, 2289, 1273, 8545, 8733, 1556, 1613, 4154, 4197, 5581, 2884, 4931, 2377, 1817, 4082, 2076, 1714, 7838, 5522, 4364, 2325, 7523, 1707, 1643, 9163, 2104, 5201, 8365, 7649, 8151, 9209, 7410, 8987, 2927, 5026, 7573, 5213, 8758, 7020, 3302, 8219, 4948, 4203, 5854, 3224, 1390, 7739, 1361, 3868, 8337, 3953, 3895, 3991, 3456, 8974, 8276, 5674, 5558, 8847, 1886, 1551, 5391, 3614, 103, 1000, 383, 9090, 6595, 4676, 1644, 7329, 8539, 3465, 8462, 606, 1516, 9030, 4632, 4890, 8271, 2694, 6170, 9208, 3452, 2401, 2524, 4547, 4240, 7791, 7650, 1074, 5966, 3247, 7687, 7158, 8913, 5524, 4033, 7701, 3984, 2693, 8186, 457, 5953, 5525, 4713, 3241, 1580, 3582, 3157, 1964, 2665, 4552, 2362, 6720, 7774, 4454, 1026, 4732, 6403, 1600, 6927, 8294, 4336, 4796, 3842, 7366, 3698, 1275, 2672, 3207, 5971, 2075, 5957, 2679, 7703, 2930, 2442, 1700, 6725, 1760, 1868, 7240, 1756, 6660, 8833, 1953, 1904, 6852, 7123, 7738, 5738, 4907, 7507, 4054, 6395, 7371, 6104, 3418, 5714, 3080, 7126, 3275, 5225, 3926, 1495, 6732, 5969, 2044, 8406, 4463, 2887, 4384, 3440, 7887, 6778, 7241, 4001, 6902, 5725, 7047, 754, 970, 2357, 9027, 571, 199, 3735, 5539, 1388, 6086, 2096, 5849, 3523, 7631, 4210, 3532, 7625, 7295, 3694, 1423, 2390, 3128, 5547, 7715, 8033, 7964, 1664, 7966, 2426, 4922, 17, 3712, 8697, 2570, 6885, 7291, 7708, 6934, 1649, 2832, 3506, 6992, 512, 6685, 1045, 6141, 6440, 8507, 2316, 8883, 6650, 8068, 1421, 8903, 5062, 6168, 1419, 23, 4744, 698, 607, 7088, 1148, 8399, 6845, 8096, 7532, 248, 8221, 4065, 4847, 2115, 6267, 7981, 1538, 7583, 7218, 5292, 7300, 1277, 8215, 4484, 1594, 3331, 8741, 8739, 3590, 8042, 3256, 8398, 8272, 2382, 8776, 7378, 1465, 4702, 1640, 4449, 2829, 3843, 3483, 8693, 2705, 7364, 2439, 2142, 8658, 393, 5572, 945, 8191, 9046, 2367, 465, 6625, 2031, 3015, 2728, 2725, 774, 4167, 1666, 1317, 8873, 2908, 2240, 8333, 7269, 2724, 1173, 2091, 4734, 5209, 8504, 641, 7222, 7916, 584, 5973, 8541, 4824, 1916, 5723, 4910, 5648, 3297, 4053, 5428, 4644, 7847, 5087, 8609, 3990, 855, 1359, 5680, 5388, 8472, 6078, 5381, 7245, 6017, 2894, 5125, 36, 964, 6869, 3960, 4209, 5609, 4219, 818, 8484, 2861, 8712, 6246, 7469, 2558, 2324, 2262, 2323, 946, 377, 5425, 586, 3264, 3493, 4595, 7321, 2190, 6568, 2183, 7499, 5622, 3159, 7808, 6637, 4896, 8982, 1824, 1652, 4159, 3753, 6576, 942, 9026, 5362, 5833, 1746, 6888, 5162, 3769, 8054, 3986, 2151, 3674, 7872, 8247, 2733, 4723, 3737, 3982, 3368, 5881, 8542, 3952, 6097, 1212, 1347, 8124, 4925, 1578, 2577, 4224, 3538, 4602, 1010, 3738, 7184, 8238, 8239, 5876, 3098, 6613, 5891, 7133, 3727, 7748, 2055, 2009, 1099, 6803, 7522, 7891, 6197, 8497, 7307, 2087, 5101, 110, 3164, 528, 8470, 3949, 1392, 4295, 7972, 2579, 2831, 6280, 6913, 3887, 1954, 7455, 4126, 2833, 7225, 7237, 7045, 4372, 2729, 7471, 2543, 7949, 3629, 5285, 8948, 1130, 1805, 738, 6894, 494, 1069, 8463, 4761, 4257, 8665, 4334, 639, 2677, 4123, 6754, 1847, 4650, 3636, 3996, 8117, 8064, 5689, 7114, 3710, 8230, 3854, 1576, 7581, 3480, 3684, 910, 3717, 4737, 1413, 1853, 1094, 7330, 2312, 5132, 4660, 2626, 4946, 1722, 7878, 1957, 3166, 7393, 483, 8794, 935, 2581, 8901, 925, 5143, 655, 4049, 3632, 539, 5761, 6825, 5587, 8989, 5065, 5168, 1161, 6311, 4719, 6361, 9154, 3043, 7908, 1331, 5012, 3033, 1179, 1007, 2710, 382, 100, 2029, 5337, 2271, 4766, 2598, 6365, 3831, 4806, 1994, 3830, 8691, 6181, 8759, 3944, 1930, 6252, 3501, 6458, 8282, 6702, 6659, 8949, 6656, 4950, 1370, 4685, 6840, 4378, 3759, 3485, 4969, 8601, 1095, 5800, 107, 940, 931, 6406, 2171, 3237, 8624, 6446, 7655, 3154, 6062, 6792, 7818, 8564, 4945, 923, 6642, 2618, 196, 7897, 8897, 2854, 7835, 2050, 6343, 358, 8030, 8926, 2108, 3389, 1799, 4125, 7706, 4474, 2301, 8377, 6916, 3934, 7957, 6373, 9148, 4277, 5799, 7391, 6421, 7175, 2910, 7165, 9096, 821, 8385, 4604, 4506, 1367, 3246, 5397, 7362, 8524, 3383, 1636, 3436, 1236, 4586, 6976, 8785, 4523, 5392, 1201, 9017, 2051, 5899, 7328, 6756, 5350, 4468, 6169, 4456, 1256, 3271, 7942, 1215, 8172, 7954, 2117, 2614, 5270, 2118, 2139, 139, 4118, 7794, 623, 4839, 6920, 8671, 8450, 5464, 7607, 1314, 2352, 6347, 2237, 1012, 1514, 7645, 3579, 2682, 6724, 1251, 1911, 1219, 9194, 8496, 5508, 7481, 1825, 5950, 5445, 876, 94, 3327, 2882, 6923, 3688, 9052, 188, 8459, 3740, 8945, 8910, 2601, 7570, 7925, 1203, 8888, 6716, 7894, 239, 7107, 2825, 6700, 4005, 4968, 7293, 1632, 6523, 4109, 6120, 6876, 1927, 7946, 1679, 4111, 8595, 6482, 6370, 5414, 1835, 6779, 6581, 7384, 8016, 3942, 6012, 6743, 6675, 3533, 2521, 8704, 4895, 993, 833, 6201, 5599, 6016, 4936, 5427, 730, 6774, 5443, 96, 5948, 4043, 4275, 7015, 4486, 6225, 4745, 5858, 4845, 2684, 7282, 1875, 841, 6154, 2032, 5481, 2613, 6159, 1132, 6891, 6555, 1996, 6552, 6218, 1472, 3332, 6217, 1230, 6983, 8687, 5693, 3872, 3814, 4633, 3459, 1255, 7467, 8637, 4420, 2173, 3425, 6578, 1147, 949, 6305, 8229, 111, 458, 657, 424, 5641, 2203, 2552, 7221, 5749, 9135, 5099, 8317, 1989, 7635, 7685, 7376, 2877, 6281, 3384, 2667, 8937, 7646, 2999, 1995, 7128, 1018, 1489, 3675, 4512, 8090, 5882, 9116, 4619, 7353, 2755, 1789, 1925, 8812, 1034, 2678, 1019, 4803, 281, 620, 8836, 3811, 513, 2394, 889, 9072, 4051, 5030, 5615, 4066, 5446, 1134, 3238, 61, 9112, 8384, 1157, 2455, 332, 401, 7340, 4217, 1207, 243, 4833, 602, 8648, 7530, 3316, 345, 478, 595, 668, 749, 1506, 790, 845, 880, 985, 4516, 7200, 1063, 8520, 840, 3225, 5375, 3791, 4947, 8941, 1830, 8515, 8661, 8514, 4302, 7249, 4820, 7510, 1432, 1302, 4819, 3429, 3666, 6819, 627, 311, 648, 8576, 599, 1662, 688, 4881, 8756, 1848, 8141, 4131, 8032, 1466, 2943, 7255, 4500, 7996, 1380, 4652, 4025, 3736, 753, 1749, 2564, 6967, 8273, 7828, 1036, 5871, 8267, 2852, 3915, 8820, 5471, 5473, 4239, 3851, 4242, 2936, 3583, 4625, 7026, 4600, 1804, 3287, 4758, 2419, 3997, 5070, 2792, 8296, 1091, 5942, 4393, 5015, 6546, 854, 4181, 7997, 8805, 6429, 6727, 88, 7284, 5958, 8334, 1304, 8511, 1676, 4469, 8947, 6833, 2450, 4757, 1467, 6375, 4978, 3072, 8350, 342, 4529, 1587, 8129, 2841, 3403, 2716, 2487, 4426, 4058, 3790, 6677, 8499, 40, 521, 4669, 5940, 2018, 6601, 6438, 6691, 5949, 2933, 7750, 3385, 6334, 3175, 6886, 7379, 1759, 5219, 4842, 5883, 2681, 5775, 7999, 4, 268, 7960, 6973, 616, 2632, 7068, 3186, 6767, 3494, 8297, 6768, 1614, 2837, 2185, 2838, 1001, 2794, 5438, 823, 1937, 2605, 4441, 8909, 1003, 8001, 5159, 980, 8841, 8095, 5280, 7084, 7939, 3390, 4589, 8134, 3350, 1127, 8006, 2425, 8634, 9025, 2768, 1882, 3337, 3799, 6615, 1108, 3024, 8284, 6844, 5310, 5755, 5468, 1093, 4565, 6684, 2154, 870, 6651, 3433, 3122, 5060, 3434, 2844, 5798, 5036, 3477, 8745, 390, 410, 232, 1568, 204, 2673, 1859, 5997, 8827, 4307, 6077, 8622, 5643, 1343, 1926, 3407, 6773, 7297, 5930, 4567, 4800, 7303, 7563, 2181, 5267, 7753, 7309, 3695, 7072, 1292, 1227, 6369, 7502, 6672, 3640, 7501, 3563, 4659, 7941, 677, 4507, 5520, 919, 4322, 4882, 430, 5540, 1840, 2, 5475, 2162, 7374, 4574, 8279, 8256, 4260, 6770, 6229, 8031, 8301, 4919, 6460, 1668, 2732, 5765, 1850, 3625, 8437, 2242, 1160, 1710, 1075, 3085, 3139, 6214, 7903, 6935, 2060, 472, 39, 1500, 143, 996, 9077, 8200, 413, 933, 7027, 5319, 5857, 194, 592, 7755, 8483, 6425, 4823, 7320, 6698, 8921, 509, 2177, 7984, 6186, 2967, 485, 74, 884, 8428, 209, 681, 439, 48, 8201, 8854, 4206, 4808, 5198, 1612, 4887, 6100, 4765, 1120, 7079, 6457, 1023, 3377, 3461, 8078, 2003, 8426, 6843, 8170, 9029, 5483, 1040, 5269, 2583, 8772, 575, 3359, 6588, 2799, 1071, 4990, 8436, 5063, 7994, 7115, 2429, 5237, 5843, 5378, 1634, 6707, 6630, 2483, 4220, 4492, 2034, 3174, 1811, 8778, 5896, 1962, 1250, 2630, 7322, 8123, 6028, 2028, 2341, 7842, 6763, 6020, 2597, 4294, 8786, 8119, 1116, 1483, 7905, 3746, 3338, 2754, 1815, 5829, 3527, 8721, 5367, 5177, 5055, 6047, 2199, 6157, 7305, 4527, 4956, 5825, 8548, 2134, 5580, 7811, 3227, 8079, 5908, 6215, 1225, 5311, 4038, 3373, 8973, 1618, 7790, 3739, 1946, 3741, 1623, 3662, 565, 5721, 4333, 1286, 3611, 2049, 5918, 6861, 3322, 3956, 8834, 7405, 2644, 7067, 2820, 5412, 9117, 5554, 7048, 2298, 4815, 3820, 2958, 338, 224, 1420, 2285, 234, 1433, 5236, 8700, 8454, 7424, 1783, 2654, 3648, 7036, 1782, 4557, 8021, 101, 3272, 4750, 4620, 7998, 4052, 6580, 4591, 9155, 3141, 5313, 4016, 3857, 7604, 9146, 7590, 899, 7890, 9069, 185, 469, 6355, 154, 4974, 369, 1189, 6490, 65, 180, 686, 506, 3878, 6448, 7623, 5729, 1327, 91, 3290, 8287, 6219, 5555, 6413, 1404, 1796, 8347, 5840, 6611, 7692, 7870, 4421, 5842, 5752, 9087, 1041, 560, 525, 7447, 7533, 9206, 5703, 6075, 6914, 4822, 79, 77, 1918, 1617, 5681, 4376, 7463, 498, 3233, 6834, 2647, 916, 8562, 3709, 20, 1339, 6573, 7796, 2767, 2157, 5866, 3690, 4285, 3992, 1675, 1519, 8434, 7236, 7280, 4915, 6655, 3358, 4010, 7433, 8770, 8208, 3637, 3916, 2889, 1242, 2421, 6525, 1965, 3003, 8533, 5862, 6038, 5231, 8252, 6321, 5043, 2668, 8023, 1412, 516, 6346, 3733, 972, 8646, 712, 5253, 287, 3580, 7161, 7160, 4283, 5426, 9223, 8657, 4168, 8795, 6129, 4261, 8343, 886, 3685, 7865, 1769, 5029, 2642, 3416, 6827, 8039, 7505, 3106, 1921, 8784, 8136, 1260, 1898, 7915, 8291, 8326, 4643, 2114, 4993, 7995, 2275, 8435, 182, 676, 608, 3142, 6928, 7849, 654, 3750, 7477, 6915, 7634, 6051, 8353, 8822, 8277, 1734, 4083, 3018, 3016, 2696, 4381, 7804, 3073, 2321, 6884, 3263, 8882, 960, 965, 6402, 195, 8442, 4878, 3198, 6060, 6782, 3415, 2691, 6404, 6335, 4704, 7845, 1020, 3156, 5618, 1598, 4703, 2105, 4828, 4160, 1719, 4865, 106, 6350, 7104, 5939, 113, 2897, 7037, 6131, 4783, 8829, 6224, 1547, 8397, 3602, 9130, 7064, 5041, 4115, 3309, 7077, 976, 9106, 7782, 4846, 7163, 1690, 971, 8028, 3696, 449, 422, 4760, 2580, 1975, 5220, 4395, 8228, 2223, 2340, 1748, 1106, 2378, 3169, 1333, 8260, 1838, 699, 29, 159, 3369, 718, 408, 434, 441, 4873, 6541, 6317, 5051, 3867, 3193, 1243, 2492, 3715, 9228, 6426, 2739, 3517, 8800, 4339, 7439, 7417, 1550, 8318, 4020, 3006, 3366, 5596, 2717, 9037, 1240, 4078, 1168, 6475, 8816, 2043, 7332, 1169, 1188, 9014, 7735, 2806, 4293, 2680, 7106, 8161, 7232, 1509, 170, 872, 7709, 2960, 16, 7119, 701, 392, 316, 1566, 51, 2582, 685, 2042, 5444, 7669, 7539, 6558, 171, 5157, 8505, 1478, 5377, 8527, 1191, 6960, 8952, 3503, 2479, 4599, 6947, 7675, 3402, 4538, 1150, 5166, 2495, 4941, 6948, 7073, 8718, 1570, 2659, 3274, 4618, 8636, 1239, 4605, 7667, 556, 5096, 6410, 3023, 7591, 9123, 7653, 8371, 5665, 8237, 5934, 3374, 1135, 6386, 2701, 809, 8381, 901, 733, 2595, 5273, 6882, 3375, 3707, 1498, 3792, 3966, 2311, 7260, 6664, 8684, 7251, 3734, 3325, 991, 7763, 909, 4092, 132, 8761, 7574, 3786, 6667, 669, 8115, 7944, 6401, 3779, 4984, 2137, 4934, 7495, 2435, 4172, 1351, 7524, 3346, 5194, 6341, 6198, 8603, 1124, 6074, 866, 131, 3881, 4286, 8432, 307, 2318, 49, 37, 2284, 5145, 6282, 535, 5451, 852, 3927, 5535, 3330, 9140, 8914, 5243, 2280, 7800, 7696, 954, 7347, 8345, 174, 468, 6177, 3822, 5304, 8954, 8171, 8085, 2987, 7051, 2315, 1376, 3004, 4400, 1362, 2649, 4291, 3021, 8750, 4338, 8768, 7517, 6213, 8302, 7412, 1705, 5085, 7317, 3951, 7363, 6535, 1697, 90, 6620, 5926, 2514, 7201, 3487, 7547, 2836, 5005, 6152, 2385, 359, 6309, 125, 8257, 8359, 7760, 903, 6301, 205, 3176, 3537, 1712, 8109, 2929, 7506, 4575, 5895, 8797, 8962, 8440, 2822, 6221, 41, 412, 1530, 6183, 8848, 3635, 8060, 2072, 5700, 5144, 1397, 1028, 5734, 898, 5255, 9043, 628, 8675, 5760, 2121, 92, 3765, 958, 6206, 6853, 728, 2905, 640, 4380, 1217, 7413, 1854, 1678, 8409, 6961, 2506, 3774, 9181, 4135, 1864, 1591, 5988, 7308, 760, 7216, 6279, 1754, 7420, 5776, 5905, 5453, 9167, 3706, 2912, 6820, 1845, 3177, 9175, 3766, 4289, 5009, 580, 7486, 5086, 9100, 7630, 1113, 7325, 2081, 7973, 7421, 9174, 9038, 652, 3319, 129, 499, 2327, 999, 1244, 5487, 5149, 2186, 887, 5745, 6310, 9199, 122, 6478, 1784, 3969, 1889, 8363, 3900, 1987, 5459, 292, 2617, 75, 5254, 6953, 4165, 1198, 6954, 7358, 4802, 7831, 3789, 8421, 2516, 1086, 7833, 7773, 3482, 98, 4409, 5604, 6695, 4096, 5480, 8777, 8659, 7028, 7482, 8444, 562, 2408, 6384, 5501, 297, 4323, 351, 1545, 2360, 7344, 981, 6367, 5293, 9085, 7087, 8725, 6994, 6261, 4587, 3946, 4389, 2972, 6669, 7682, 8303, 7860, 5264, 7238, 8711, 4448, 8148, 8596, 6318, 8512, 1739, 6466, 6006, 2097, 7562, 7423, 5084, 6841, 3351, 8979, 2883, 8627, 914, 3970, 1306, 7018, 6931, 7579, 5614, 7931, 3748, 8843, 2443, 7496, 5072, 2498, 4859, 9184, 7823, 2144, 8629, 6705, 5593, 257, 9063, 1395, 2448, 8707, 1982, 6132, 71, 9102, 218, 680, 55, 6332, 1772, 2179, 8535, 8320, 6471, 2170, 2911, 1454, 7895, 85, 6193, 4170, 7030, 3011, 2599, 5621, 1494, 5975, 7182, 7210, 366, 773, 8305, 280, 5794, 2535, 3486, 2125, 5003, 6256, 5358, 245, 291, 7694, 83, 6762, 2976, 4255, 5588, 4775, 8992, 4884, 8717, 2611, 3773, 5360, 3764, 7732, 3065, 8289, 5246, 5872, 7814, 9182, 6163, 5155, 8528, 3772, 8480, 4299, 3340, 6972, 8430, 3339, 8878, 5566, 5811, 2629, 2593, 2594, 2592, 2588, 2587, 4349, 8137, 7816, 3886, 5933, 4007, 1197, 3304, 3036, 7162, 6000, 4497, 7963, 7399, 8195, 2775, 7952, 1479, 8986, 2187, 4856, 7663, 5234, 2903, 6592, 4933, 7721, 5751, 1851, 6278, 3907, 3901, 8857, 3669, 5959, 7698, 4579, 5200, 6985, 3730, 2200, 140, 343, 6026, 842, 6134, 162, 9196, 9150, 5636, 6234, 7867, 6223, 2835, 1015, 2255, 4319, 1138, 5530, 9011, 1049, 6203, 6733, 9124, 5151, 1459, 1533, 4173, 1502, 6918, 1809, 5179, 2834, 7373, 4801, 959, 454, 6368, 425, 673, 8673, 3627, 1276, 8004, 5956, 5437, 6021, 5465, 3649, 8849, 6997, 7257, 5266, 276, 5129, 619, 7345, 8766, 4596, 3417, 8653, 4684, 272, 766, 4245, 470, 7744, 1798, 4894, 9004, 8240, 6128, 8650, 6291, 8086, 6244, 5299, 3530, 7497, 1822, 6693, 7057, 7490, 7086, 1382, 1385, 5868, 3301, 6204, 376, 7959, 8666, 5025, 2257, 5526, 2821, 7197, 8339, 1192, 3889, 2098, 3406, 4073, 2913, 1877, 3448, 7699, 8396, 1894, 2715, 7310, 5178, 8810, 6838, 5634, 231, 5150, 2164, 3957, 7333, 2270, 5652, 8212, 9165, 8876, 4959, 8049, 1402, 474, 4212, 6593, 3066, 2233, 6858, 2317, 9012, 1133, 2542, 1860, 1836, 1861, 1753, 5816, 4113, 8763, 5771, 6984, 2259, 2685, 6352, 7919, 6699, 3120, 2109, 642, 8611, 278, 8610, 4585, 2907, 6308, 5746, 6776, 3665, 3012, 5092, 9188, 1206, 8407, 8227, 811, 4510, 877, 805, 807, 2561, 7974, 834, 782, 9218, 7075, 2000, 7491, 6744, 868, 6090, 772, 7719, 7354, 5394, 4610, 1801, 3219, 6579, 1736, 1520, 2188, 4080, 4063, 7880, 6049, 1826, 2968, 2970, 2465, 6363, 4788, 8467, 3209, 4107, 1401, 5935, 1027, 4731, 8008, 3360, 5295, 5089, 7829, 6735, 2602, 2039, 2590, 4178, 3183, 4524, 1599, 3285, 3798, 1324, 4558, 3457, 6430, 2337, 4370, 3536, 7514, 2508, 7090, 3362, 293, 2676, 395, 6112, 8122, 7065, 6271, 1470, 3556, 7619, 4899, 7204, 5619, 6604, 9203, 7229, 2735, 4015, 5370, 4909, 7155, 3443, 5088, 1795, 7786, 8138, 5821, 3093, 6865, 3543, 7540, 3047, 8641, 3801, 3803, 3805, 1501, 6887, 253, 5104, 2417, 3097, 3507, 1810, 2198, 8699, 2925, 7146, 4746, 4672, 653, 7121, 2674, 1308, 8080, 1718, 4147, 1399, 4918, 6936, 7432, 3020, 7130, 4445, 761, 4234, 8126, 2713, 3078, 3514, 2391, 4110, 2638, 8626, 8357, 4961, 926, 8931, 416, 7975, 7824, 6469, 2686, 6405, 3451, 8635, 8976, 9040, 6791, 1780, 2761, 240, 6846, 635, 5146, 838, 1645, 233, 2023, 9086, 5120, 4664, 5806, 7209, 5831, 6023, 5870, 1287, 6070, 5600, 4743, 4694, 4793, 4329, 4790, 8356, 5517, 2486, 7074, 2472, 6731, 7844, 8616, 6300, 6210, 2704, 2753, 1507, 5284, 8113, 4102, 2993, 1910, 5613, 4101, 4103, 7493, 3432, 2548, 4100, 6497, 6248, 7319, 6377, 2615, 5195, 6995, 8066, 3591, 5659, 2310, 3262, 4550, 720, 1280, 2427, 1022, 7528, 3989, 7324, 2846, 260, 526, 436, 5141, 589, 8726, 594, 273, 2918, 2035, 2405, 3612, 7948, 5994, 8225, 6958, 8481, 7764, 6686, 3140, 6416, 3624, 7720, 6344, 1270, 3776, 2307, 5642, 4475, 9007, 8457, 2771, 7336, 8891, 3013, 1786, 1223, 4437, 5826, 5913, 4263, 7839, 1546, 4095, 4539, 3906, 7411, 5256, 2810, 6893, 7980, 4225, 3914, 3045, 2468, 3236, 700, 32, 223, 7541, 7542, 891, 7854, 2197, 6639, 2068, 2227, 93, 5875, 1224, 7843, 892, 9070, 2130, 8128, 3703, 3354, 1943, 8865, 3213, 2843, 4243, 7945, 7006, 6209, 460, 137, 8767, 3445, 4924, 7173, 2485, 1009, 5777, 5112, 5232, 927, 112, 6603, 7643, 7932, 8630, 721, 7166, 8059, 2625, 824, 7335, 4698, 1159, 2657, 6137, 2381, 8586, 5668, 2413, 1603, 6095, 7304, 5792, 3009, 1044, 6908, 8998, 6614, 6025, 5115, 3167, 4883, 796, 6033, 5116, 4540, 5317, 4211, 5164, 8249, 1757, 5815, 4152, 4526, 2220, 8588, 3505, 1908, 2586, 1329, 3995, 5196, 1252, 5024, 8984, 7185, 6587, 6322, 4648, 2147, 6290, 123, 8649, 215, 8089, 1422, 3397, 4134, 549, 8043, 5663, 2557, 1728, 5601, 8445, 2260, 3184, 9047, 7761, 464, 1389, 7124, 1364, 2748, 3296, 603, 7722, 1431, 5152, 3939, 8708, 4367, 6172, 9023, 5417, 2560, 5122, 5960, 216, 2400, 6096, 7056, 6190, 784, 3074, 5743, 944, 8382, 727, 6380, 1396, 6896, 1737, 4490, 1344, 1200, 6472, 451, 2741, 1100, 8574, 3797, 9051, 6187, 117, 7759, 928, 9066, 160, 7427, 6547, 1042, 336, 3095, 4351, 6524, 7132, 1051, 2651, 3019, 1639, 4357, 568, 6912, 9103, 5491, 6747, 8826, 3898, 3235, 5736, 2251, 2917, 7479, 4042, 533, 455, 5276, 4281, 570, 1529, 3848, 5890, 6623, 5316, 4352, 7498, 3255, 5467, 4809, 156, 3504, 7281, 1752, 3795, 3291, 3123, 5722, 4133, 2138, 4186, 4593, 1110, 3286, 6212, 2980, 207, 8683, 4452, 579, 8801, 9213, 4889, 4630, 4455, 5461, 6276, 6765, 3261, 1115, 2830, 1717, 1687, 8070, 4810, 8550, 4603, 3273, 325, 559, 4577, 5385, 708, 7977, 2215, 2152, 8133, 2973, 2467, 896, 8802, 5452, 7616, 6477, 4607, 4515, 3342, 3315, 3001, 8956, 5974, 2928, 8275, 777, 995, 6118, 2769, 4581, 2873, 1776, 2161, 6527, 2994, 5820, 8839, 2790, 3431, 3388, 7159, 4004, 5885, 2342, 4505, 8988, 3718, 5782, 4541, 7893, 3593, 1936, 4772, 4580, 2645, 2782, 7445, 2801, 4572, 8613, 3825, 8614, 5033, 5574, 4573, 333, 4983, 4981, 4982, 9054, 5964, 643, 4641, 7559, 1653, 7195, 1271, 4345, 3784, 2366, 2662, 7752, 8844, 3891, 6758, 4994, 8747, 9227, 4021, 6353, 6196, 1294, 6657, 7198, 5390, 6067, 2529, 8577, 6837, 1646, 7000, 8509, 883, 3396, 6951, 4331, 7885, 2065, 2100, 3845, 3726, 6114, 4473, 8644, 2404, 1555, 2245, 830, 7836, 3148, 8452, 3620, 4791, 4916, 3603, 6570, 6093, 8427, 1969, 8144, 2247, 7815, 3756, 967, 7025, 126, 8077, 8187, 2392, 7504, 3806, 8754, 1573, 5410, 9178, 5653, 2474, 8132, 8924, 4296, 5189, 7866, 1787, 2005, 715, 6, 6366, 5238, 1685, 8449, 1544, 6461, 2165, 7783, 8858, 1440, 7813, 7657, 2652, 5458, 3562, 5348, 6653, 8281, 3365, 135, 493, 405, 2573, 2536, 780, 116, 1658, 831, 3254, 6052, 5984, 3441, 1619, 9003, 2528, 7070, 3752, 1673, 5704, 8220, 3334, 8392, 8500, 208, 1518, 4266, 4662, 348, 4973, 4929, 8181, 4341, 6107, 1378, 3655, 6109, 8701, 1427, 7254, 6806, 8099, 8169, 7902, 7700, 6195, 9015, 5288, 5227, 3783, 3874, 4496, 7990, 26, 5488, 722, 6323, 8233, 6272, 6226, 4513, 2252, 8869, 5823, 6259, 8479, 3105, 1523, 1785, 2027, 6697, 4749, 6059, 7234, 7713, 2793, 7315, 6123, 4332, 8523, 1744, 3598, 7192, 2879, 8655, 2101, 5061, 4696, 8355, 5944, 1735, 6374, 1577, 5748, 1727, 6045, 5486, 3844, 5532, 7430, 7988, 8269, 2265, 1701, 6751, 7306, 5010, 7302, 423, 3276, 6850, 1883, 4482, 3288, 7589, 8866, 2795, 3190, 1445, 2669, 2424, 2969, 8316, 2336, 6041, 3248, 6701, 1265, 8583, 8911, 4485, 3044, 5406, 3945, 1222, 2088, 1139, 8352, 1914, 1920, 3622, 8376, 6826, 8029, 6293, 9067, 3032, 2250, 3678, 4057, 475, 2787, 3067, 6944, 3522, 5474, 2160, 5943, 1655, 2191, 6609, 6372, 7749, 7801, 5252, 5945, 175, 7596, 5188, 2286, 326, 1873, 2503, 5856, 9114, 5134, 1482, 4451, 5563, 5133, 1248, 3979, 4720, 1766, 6479, 3092, 6010, 8573, 5334, 8369, 1060, 303, 82, 38, 6495, 70, 4863, 1016, 621, 7958, 5818, 5531, 6162, 5117, 4267, 5306, 2606, 327, 5384, 437, 8957, 873, 836, 778, 734, 6171, 5633, 2963, 7900, 4408, 1790, 5068, 4724, 3849, 5222, 8167, 5456, 2418, 1950, 2410, 6544, 5577, 4491, 895, 9028, 8652, 1218, 7172, 8640, 2155, 2574, 7458, 4658, 537, 4885, 7349, 6520, 4216, 4347, 4979, 7888, 8268, 2471, 1266, 7629, 4710, 8015, 7039, 5083, 3278, 5724, 4891, 3118, 3439, 3571, 2878, 4241, 2168, 3794, 5091, 1442, 7252, 4461, 1948, 1447, 2490, 7544, 7009, 346, 142, 763, 3577, 6904, 2591, 3153, 1517, 5717, 7487, 7069, 7261, 2656, 8453, 1220, 849, 1510, 939, 8672, 2842, 3068, 5759, 4789, 8688, 6597, 3955, 9190, 3293, 4661, 3221, 8149, 3267, 7569, 9010, 7334, 6596, 8881, 1558, 5418, 2428, 9050, 2736, 4635, 3453, 6505, 1797, 3442, 7190, 4616, 1778, 5645, 7846, 6600, 1970, 7512, 6398, 4726, 8270, 6222, 2089, 2504, 6857, 3228, 8336, 3317, 1017, 3723, 3714, 1162, 2319, 6030, 7901, 7810, 3277, 3466, 2959, 8880, 1793, 4369, 6945, 4700, 5859, 848, 5768, 4346, 6654, 3600, 8863, 7017, 4388, 5282, 4537, 2791, 2389, 2219, 4992, 5961, 1884, 7882, 1490, 2523, 2796, 2766, 6521, 6180, 3318, 6519, 4059, 7754, 3005, 1061, 6529, 8591, 1941, 2193, 2228, 4666, 4119, 5707, 4917, 2776, 1025, 4747, 588, 7704, 2850, 8919, 1349, 3353, 3553, 7401, 5368, 3469, 7526, 3492, 6634, 9091, 7473, 18, 19, 2578, 4188, 5990, 6501, 220, 1791, 3818, 1803, 2221, 5894, 4914, 4689, 6113, 4031, 8886, 538, 585, 8927, 2863, 5093, 4548, 3775, 8223, 7188, 4466, 2633, 3615, 804, 6929, 6455, 4434, 121, 6712, 9053, 8106, 7108, 1320, 1641, 3638, 3491, 7489, 4867, 8902, 8248, 5793, 249, 2436, 8748, 1931, 4221, 5039, 43, 2013, 765, 7850, 7920, 835, 1318, 2010, 1152, 3103, 8173, 2984, 8175, 3771, 1136, 5564, 3295, 8373, 1944, 7219, 8722, 2452, 2095, 8731, 7840, 3619, 3544, 334, 1261, 2388, 6824, 7821, 3929, 2372, 3401, 5011, 5450, 906, 574, 4150, 150, 4721, 7874, 2648, 9002, 3521, 7470, 3243, 4821, 8999, 7576, 3838, 4908, 1125, 897, 9048, 161, 8694, 6088, 6855, 5049, 2688, 1997, 328, 4578, 5500, 4458, 7520, 6189, 3585, 2851, 5289, 2409, 5492, 230, 1057, 5482, 5448, 636, 3029, 4594, 8274, 8482, 4342, 7294, 6752, 5190, 7171, 4583, 7598, 2541, 31, 2847, 6690, 277, 6873, 3607, 8789, 5617, 7476, 7449, 6627, 3034, 6298, 8799, 5571, 3146, 7639, 6618, 6449, 5955, 902, 3379, 5349, 4756, 1013, 1097, 8246, 3770, 6643, 8286, 5515, 7383, 7377, 1205, 8932, 5808, 7040, 7535, 8680, 4957, 2888, 4725, 6571, 2786, 3617, 6489, 3861, 7662, 5355, 8469, 1234, 388, 794, 2440, 323, 8664, 442, 2295, 3473, 1885, 489, 6391, 8283, 1046, 5408, 4194, 7622, 3188, 4273, 4870, 7670, 4417, 6381, 4645, 1768, 7521, 2855, 9210, 6777, 385, 6178, 711, 4571, 5153, 1232, 2397, 5212, 7797, 4222, 3524, 2267, 756, 3079, 7982, 222, 530, 50, 8298, 3468, 2812, 1593, 2048, 105, 2576, 67, 2054, 2978, 8053, 4549, 4553, 8990, 8082, 4041, 8491, 5677, 7016, 2853, 2416, 331, 400, 8556, 7442, 4459, 5805, 9164, 7387, 1683, 3963, 3531, 6053, 6092, 2274, 8290, 2111, 1583, 7049, 2808, 5658, 7731, 3962, 4305, 2849, 5545, 2456, 8592, 5330, 8075, 6759, 3561, 3257, 4654, 5210, 63, 4321, 808, 378, 6730, 614, 8022, 1247, 3094, 7120, 1983, 1151, 4488, 5963, 1408, 2451, 28, 5827, 7156, 1238, 3, 286, 2568, 1021, 1492, 6696, 2553, 3444, 3716, 4169, 1451, 8299, 7917, 6194, 2827, 4470, 4554, 5229, 4545, 578, 8522, 2094, 3529, 3281, 6453, 3323, 9074, 2785, 4893, 3347, 1338, 4509, 1178, 7609, 4183, 8306, 1800, 389, 757, 609, 6037, 7109, 1695, 2370, 6089, 8709, 8351, 8011, 4609, 7286, 2141, 7274, 2870, 3410, 7465, 3054, 4949, 8002, 6031, 2708, 9160, 1605, 1213, 8540, 7602, 5583, 4223, 3697, 6486, 2211, 7143, 4298, 3964, 1585, 3592, 5671, 813, 236, 7762, 2982, 894, 662, 4988, 4622, 2379, 6784, 5565, 6258, 7728, 3171, 7989, 5356, 3136, 4767, 8508, 399, 9078, 360, 5537, 1563, 97, 2637, 8906, 5262, 932, 8193, 6127, 806, 200, 1960, 6126, 3398, 6694, 1816, 4028, 2445, 3187, 2743, 7906, 8782, 7357, 4869, 8447, 1896, 7714, 6227, 8685, 3380, 5429, 8764, 6550, 4773, 3314, 6532, 8870, 6661, 7826, 7605, 8104, 6515, 4647, 6451, 5646, 1615, 6140, 1745, 1774, 5249, 247, 7206, 8438, 1543, 8456, 3282, 4628, 66, 445, 270, 1085, 7082, 4853, 7644, 320, 3321, 1048, 7288, 1050, 507, 5519, 136, 3540, 8884, 8411, 4055, 4962, 8582, 6064, 6242, 893, 114, 8073, 7898, 4829, 1974, 7436, 1316, 7434, 3435, 3137, 4359, 5864, 2330, 3037, 3921, 6411, 6188, 2477, 3133, 184, 6924, 2331, 5756, 3419, 4695, 3671, 4943, 7053, 9201, 7078, 6565, 1121, 660, 1105, 4309, 9020, 1328, 127, 298, 6494, 8660, 2110, 2896, 1534, 5716, 7066, 4340, 1353, 7693, 2299, 6444, 2453, 3090, 319, 5376, 5374, 5105, 3500, 4146, 6722, 2502, 7448, 235, 8198, 7680, 367, 5078, 2127, 363, 8946, 4136, 1143, 1228, 3110, 4328, 5242, 2723, 9008, 5472, 1474, 3871, 7375, 294, 6121, 4187, 7864, 4866, 4045, 2538, 8012, 3392, 1876, 4440, 5813, 3757, 2745, 8094, 488, 3428, 4079, 951, 1832, 5466, 7212, 6739, 1450, 1289, 269, 4911, 3639, 2893, 1342, 2493, 2655, 1637, 6496, 6950, 797, 152, 704, 6509, 8231, 6376, 2616, 9129, 6122, 4035, 6879, 731, 4037, 6408, 555, 3404, 5325, 2470, 9153, 2977, 5320, 1181, 7446, 5192, 6899, 5995, 5314, 1775, 977, 871, 1923, 3581, 4471, 8638, 6941, 6823, 1726, 6940, 8088, 4446, 6427, 3610, 102, 1285, 5172, 2807, 5235, 4770, 7196, 5632, 5915, 1348, 7904, 7348, 467, 432, 6364, 8055, 5836, 3114, 6351, 2540, 7022, 664, 4938, 1373, 6139, 4748, 1855, 7771, 7337, 4651, 6029, 7697, 2158, 3720, 4431, 1171, 4406, 2036, 321, 2123, 1363, 795, 5147, 450, 8102, 6071, 5639, 6831, 7174, 1903, 1211, 6974, 3980, 302, 997, 6545, 6230, 5136, 9132, 1661, 1945, 3787, 2363, 1439, 3130, 8860, 3017, 3744, 8920, 503, 504, 7369, 8953, 5345, 558, 8380, 406, 4814, 8388, 5762, 4282, 2956, 4860, 936, 5277, 8738, 6859, 4680, 7035, 3162, 5852, 5682, 553, 8551, 5148, 5861, 3489, 9136, 929, 3168, 637, 8667, 9156, 6018, 7710, 4584, 7488, 6510, 8184, 2627, 2819, 1446, 4407, 118, 682, 4238, 5257, 6993, 1515, 1527, 7313, 6658, 1428, 8654, 6933, 3408, 4849, 7822, 2305, 3938, 1497, 5298, 7618, 374, 1899, 8872, 3121, 8729, 5735, 5705, 6254, 6956, 8618, 9045, 418, 5165, 1418, 7586, 6511, 7664, 6459, 5048, 9084, 3978, 8003, 5204, 4114, 4483, 6312, 4504, 6738, 7231, 2817, 8013, 3386, 5720, 7214, 1521, 2248, 5742, 5655, 5278, 5218, 6467, 6809, 8329, 1569, 522, 5239, 9032, 187, 7724, 6971, 1703, 3299, 2555, 7672, 5496, 6800, 7648, 547, 1972, 7021, 6236, 6567, 878, 596, 2297, 6397, 5767, 8679, 5037, 7899, 5838, 4759, 2920, 7758, 7624, 5366, 2628, 4130, 4753, 2824, 2356, 7097, 5485, 5393, 4864, 4751, 7443, 24, 4185, 7534, 4816, 7180, 1704, 7397, 2759, 3249, 9138, 2565, 4375, 8278, 8518, 5993, 979, 6671, 542, 2955, 2954, 5586, 8056, 4532, 8222, 9120, 6324, 4327, 7323, 6514, 3919, 2249, 6326, 2296, 9115, 3478, 1692, 8211, 7537, 4569, 5644, 2308, 665, 5795, 1981, 2698, 1535, 5352, 6036, 3437, 5917, 725, 5498, 8783, 786, 8041, 6143, 2687, 8130, 4177, 8554, 1055, 4805, 3059, 5597, 7892, 4317, 5595, 3058, 8026, 2527, 3644, 3284, 6608, 4906, 5651, 1288, 1988, 6481, 2463, 4175, 8819, 1449, 2354, 8341, 1763, 2293, 554, 8696, 2113, 7207, 169, 2892, 5395, 9173, 8364, 3599, 3815, 6715, 4693, 666, 289, 4627, 4733, 7402, 1715, 4472, 3155, 7382, 1104, 2885, 5733, 4778, 7285, 4991, 6245, 1235, 4128, 1890, 2387, 1368, 1068, 552, 5670, 1654, 7993, 8473, 2891, 5695, 7509, 9186, 5207, 6556, 4404, 726, 7042, 6737, 6399, 561, 6099, 329, 2756, 7571, 6591, 290, 8118, 6986, 7213, 6605, 2398, 2919, 6764, 550, 5077, 5006, 6898, 5079, 8218, 2375, 2206, 7565, 7769, 601, 3049, 8404, 35, 536, 7176, 937, 543, 962, 956, 651, 8742, 5290, 1254, 1901, 4646, 4428, 1033, 4308, 846, 7737, 1689, 8429, 8690, 8589, 8930, 4271, 5233, 4927, 5361, 5951, 8493, 576, 1323, 6760, 211, 496, 5186, 5346, 238, 6839, 8557, 4248, 5773, 3994, 6294, 2212, 7970, 8047, 6585, 3031, 2491, 908, 30, 1444, 1592, 1794, 201, 7961, 8057, 2981, 6454, 7298, 8720, 6138, 5624, 9207, 4764, 4784, 4798, 5607, 5371, 9202, 8942, 4621, 4278, 7441, 4597, 8985, 7617, 2650, 6761, 8572, 3129, 353, 309, 1309, 1670, 3298, 1553, 4614, 4522, 8206, 8972, 8855, 9204, 7627, 8852, 3454, 1249, 8250, 3606, 5947, 4303, 6333, 2156, 2326, 3659, 8474, 1174, 7500, 6875, 6830, 1967, 888, 157, 6019, 6338, 2287, 7577, 3981, 4530, 8796, 3367, 3547, 7355, 3711, 1128, 514, 7058, 957, 2347, 3306, 6649, 5476, 5477, 6306, 7707, 148, 5931, 2131, 5294, 3231, 2153, 8295, 6503, 3954, 5131, 5110, 8120, 8103, 1400, 3027, 8332, 7543, 8939, 4465, 8139, 5001, 4009, 551, 3002, 3269, 6066, 1414, 2030, 1827, 4387, 2990, 3841, 7013, 1487, 2213, 3597, 1648, 1137, 9041, 6551, 1681, 254, 8668, 6818, 4002, 6220, 8916, 1895, 6942, 3781, 8647, 7059, 7186, 4799, 9118, 2809, 8558, 3702, 4740, 7789, 6420, 4966, 3039, 8035, 5880, 2939, 2997, 4877, 4755, 5673, 2017, 8831, 4717, 6897, 2282, 5625, 3449, 7380, 729, 8734, 2254, 2269, 2815, 6750, 8905, 7971, 7452, 5567, 6302, 6575, 667, 2480, 750, 8585, 789, 5184, 843, 882, 5568, 1922, 6331, 2368, 3025, 3589, 2411, 7052, 6548, 1336, 5167, 2895, 2906, 6400, 4439, 6612, 3862, 128, 2415, 500, 7157, 3211, 978, 1814, 4145, 1565, 5863, 1321, 9031, 9013, 347, 4423, 7873, 2867, 4817, 2569, 2770, 7950, 1968, 4624, 4840, 7819, 6483, 2279, 4374, 1807, 6303, 6866, 2497, 4544, 4712, 4742, 6540, 6034, 8261, 6084, 7386, 2383, 6619, 920, 9049, 6864, 372, 1952, 2951, 7055, 6068, 1924, 6499, 7202, 2396, 1740, 1956, 5850, 7788, 2789, 1067, 7575, 5914, 2064, 6295, 4371, 2086, 6926, 3356, 802, 7606, 3687, 5022, 5023, 4735, 4601, 3075, 1621, 6932, 7588, 312, 2399, 8678, 573, 6054, 4673, 4707, 3000, 7603, 3008, 1387, 7263, 6061, 3903, 3283, 2985, 7727, 7705, 6241, 3115, 5650, 3808, 6793, 6745, 2500, 4304, 262, 505, 1117, 47, 4046, 6801, 3623, 6468, 5657, 5527, 7983, 4427, 2646, 6835, 2112, 1755, 6746, 3692, 1177, 4006, 8867, 5174, 7597, 1441, 9189, 2281, 3204, 6502, 6264, 7642, 799, 921, 1837, 7567, 4797, 5401, 2414, 5430, 5300, 1708, 6734, 6161, 6810, 6270, 6742, 2747, 6881, 1729, 1297, 6394, 1111, 6480, 1721, 3378, 7246, 4402, 3670, 2420, 6443, 3904, 8625, 3837, 8009, 905, 9071, 4435, 4184, 6493, 1991, 1164, 7425, 6586, 890, 335, 6955, 130, 3802, 2441, 7460, 3847, 6419, 2983, 7817, 8420, 8259, 5506, 8354, 1114, 4792, 2915, 6900, 5694, 2640, 3520, 1711, 8838, 1283, 6216, 8608, 4738, 6938, 3208, 5844, 922, 3126, 6977, 1471, 4531, 7937, 938, 2765, 5982, 4247, 2434, 4208, 4467, 646, 3513, 2800, 6002, 2635, 1659, 7275, 8503, 3876, 8160, 1366, 2706, 4324, 4244, 8265, 3852, 7584, 6868, 1415, 7601, 364, 2964, 8400, 9005, 2641, 4249, 3064, 5113, 7628, 6828, 4777, 9068, 7695, 4450, 5328, 7415, 4199, 1764, 2167, 557, 4182, 1906, 3983, 2140, 6666, 1078, 133, 435, 8475, 4818, 6083, 2986, 3559, 8313, 2845, 3329, 2520, 8935, 68, 301, 7806, 6382, 8176, 6638, 1609, 4785, 2071, 2210, 6058, 7398, 3813, 1448, 6050, 740, 7976, 8204, 5893, 8530, 1417, 7089, 7951, 5245, 8143, 5052, 2942, 6530, 7549, 7953, 7183, 1856, 4960, 22, 7043, 5602, 3215, 8674, 783, 6753, 1933, 1295, 1939, 4392, 7135, 8842, 817, 6821, 1274, 5610, 5830, 3661, 2369, 5661, 6360, 7683, 5764, 1073, 7152, 6262, 5279, 1064, 7007, 4649, 7409, 1322, 5605, 9193, 3206, 2774, 5119, 5454, 2217, 3657, 8923, 7582, 3364, 387, 370, 7142, 227, 1571, 7224, 5797, 8062, 1052, 6533, 6184, 3394, 4355, 3266, 7296, 5669, 8488, 4274, 7431, 8823, 6046, 6442, 3987, 8418, 3376, 3918, 911, 2192, 7640, 7936, 577, 6164, 2690, 7656, 6728, 6371, 3518, 4228, 6526, 3864, 4678, 6004, 1892, 5570, 8358, 5409, 5130, 2067, 492, 524, 3117, 7370, 2660, 1725, 5173, 1541, 5359, 2544, 2600, 2163, 6239, 8178, 4705, 6432, 6870, 4229, 1897, 6531, 2901, 8140, 5785, 2777, 1088, 4985, 5676, 8087, 2291, 1437, 5970, 6683, 3471, 5097, 825, 1663, 456, 4390, 3686, 3551, 7610, 4851, 2338, 2661, 7978, 3289, 6785, 5419, 6063, 6136, 1443, 2589, 3197, 2423, 2461, 6717, 7772, 9226, 4464, 176, 1004, 6937, 1176, 8372, 2899, 2526, 2559, 7268, 6339, 6358, 4939, 3827, 4857, 5447, 2550, 7367, 3460, 9151, 3768, 630, 9016, 8804, 6500, 4476, 9212, 3515, 89, 791, 7979, 6042, 6903, 6412, 5992, 5176, 5302, 147, 2509, 255, 1567, 865, 1656, 6314, 6228, 7862, 5702, 1284, 5363, 8360, 4556, 9131, 5404, 3647, 832, 3605, 3650, 963, 7927, 2971, 3988, 5770, 6890, 1537, 4582, 6508, 7716, 3618, 2261, 8266, 2348, 3933, 2653, 3311, 5757, 7408, 3731, 2575, 5514, 2002, 3608, 8662, 2145, 8370, 3046, 6807, 7083, 6325, 819, 758, 7689, 7170, 6043, 8703, 6441, 3911, 3912, 4018, 8300, 1118, 5786, 7271, 7191, 1504, 7926, 6465, 2937, 2052, 5095, 6905, 7857, 3713, 2996, 6130, 9145, 2359, 2430, 8324, 1307, 6135, 4088, 8806, 2148, 7775, 5919, 242, 768, 6832, 3308, 548, 5389, 4280, 7740, 9022, 3250, 9104, 7453, 462, 1340, 4987, 3490, 5034, 850, 4972, 8183, 8182, 4868, 3472, 4335, 151, 3430, 8965, 8769, 197, 3722, 5160, 3668, 6981, 4354, 5590, 1951, 2979, 3498, 341, 523, 173, 7967, 1878, 2532, 5711, 2011, 2225, 8604, 7181, 2530, 8319, 6504, 2444, 1919, 2779, 5796, 3689, 4140, 4542, 4611, 5787, 4360, 2924, 7230, 4561, 1070, 7385, 5216, 7005, 5214, 9108, 4162, 2253, 7851, 1199, 3548, 2551, 7868, 8153, 1839, 8214, 3993, 4443, 6292, 1716, 5747, 732, 7131, 3777, 6342, 541, 5814, 6474, 8145, 8961, 6681, 3905, 6522, 2006, 3438, 3191, 8446, 1872, 6200, 2881, 5909, 5265, 5851, 4394, 6867, 3270, 8821, 4236, 4976, 671, 4559, 4804, 4151, 815, 2268, 544, 6990, 1391, 7002, 6795, 7233, 8408, 3545, 4418, 7965, 2243, 3414, 2671, 5495, 1186, 3242, 6757, 9172, 6606, 4655, 4944, 2689, 7472, 8264, 3902, 7118, 4444, 7929, 8735, 8529, 6125, 6328, 723, 4913, 1870, 2537, 7247, 8752, 3550, 2303, 3588, 3646, 3053, 7360, 7802, 617, 2175, 1379, 6624, 7381, 7404, 8254, 8775, 9128, 8485, 4288, 4256, 7767, 3850, 6082, 1146, 1079, 9095, 8633, 7690, 153, 1196, 3840, 5250, 1557, 1315, 7654, 4521, 5307, 3546, 6144, 3305, 7292, 8098, 6968, 4385, 8147, 8940, 3349, 8663, 1852, 3355, 9133, 5169, 5637, 6423, 5616, 6424, 1278, 3239, 8892, 5059, 6871, 7508, 7652, 4179, 7612, 3150, 748, 4200, 5892, 7614, 8904, 8607, 4129, 4656, 5457, 6108, 3179, 5223, 6434, 6808, 4487, 8698, 2120, 1326, 1808, 527, 52, 6766, 138, 6507, 3549, 1820, 6192, 5685, 1065, 6842, 4780, 6537, 2294, 490, 8135, 6390, 2070, 6970, 5047, 2309, 626, 5433, 615, 1628, 8368, 3042, 2718, 6534, 5331, 8578, 6250, 5911, 3908, 4164, 4786, 1193, 5171, 4163, 5579, 3104, 4787, 8044, 5347, 8490, 7279, 8519, 5688, 4366, 8403, 8017, 5297, 8818, 5879, 8413, 4958, 3869, 8494, 2517, 9101, 7907, 2515, 2166, 4047, 2122, 5923, 2778, 237, 610, 198, 409, 1486, 6621, 6723, 5977, 6275, 7935, 9000, 4262, 1665, 3446, 1377, 8121, 2866, 879, 7342, 3134, 7262, 8422, 2534, 6315, 8995, 2703, 5082, 5790, 146, 9079, 2781, 8146, 955, 4935, 2826, 5667, 8251, 1528, 6299, 3251, 2692, 2612, 2339, 1526, 5569, 5691, 6345, 452, 7924, 1902, 8895, 299, 9109, 5181, 8168, 3048, 6557, 9080, 295, 7615, 6191, 8036, 6740, 5128, 6387, 6710, 3071, 8216, 2856, 7909, 3413, 6805, 7871, 1262, 5649, 8746, 7193, 7599, 4270, 4953, 3645, 5127, 1468, 8651, 3216, 1424, 4292, 7858, 1436, 2876, 4951, 4854, 2234, 5343, 8964, 202, 3014, 2798, 694, 862, 625, 2749, 597, 7934, 7555, 1934, 2066, 3172, 5898, 6633, 6160, 1751, 3077, 7809, 4237, 5573, 6253, 4902, 7637, 2478, 2201, 3382, 1590, 6014, 2207, 5801, 1806, 1430, 7853, 252, 261, 3653, 618, 373, 386, 7414, 9075, 4679, 6939, 5301, 4290, 4398, 762, 4034, 375, 6640, 8105, 1155, 6854, 8579, 3253, 1582, 4534, 3835, 2001, 1077, 5336, 1480, 5865, 1907, 9121, 3101, 6320, 5845, 4000, 3999, 1596, 5240, 6117, 7001, 6616, 5182, 4576, 4551, 4701, 5886, 5902, 4727, 5226, 4416, 2921, 6463, 5611, 7301, 4348, 5261, 5666, 3076, 4358, 7923, 5938, 8349, 3742, 8327, 2904, 7117, 7554, 8971, 2547, 7820, 1581, 8076, 7519, 3147, 4952, 2619, 2205, 6966, 4284, 1647, 9143, 4617, 229, 709, 3566, 6848, 2202, 5258, 583, 1635, 3143, 9147, 8084, 7389, 5382, 647, 4442, 1891, 2941, 8587, 7012, 5170, 1627, 58, 6349, 7679, 3127, 8150, 1184, 4481, 6811, 305, 693, 5936, 3022, 1761, 7250, 917, 104, 6726, 7461, 6009, 5715, 2890, 7071, 158, 1978, 3508, 5339, 251, 4076, 1426, 6150, 2246, 2670, 4361, 8809, 6158, 7734, 2567, 5478, 1053, 8131, 4320, 5832, 6648, 8412, 5275, 793, 670, 2751, 308, 510, 7394, 812, 7768, 109, 4836, 5538, 2041, 5965, 3467, 330, 6488, 2102, 5383, 5007, 9170, 1491, 9179, 4562, 4090, 6422, 4310, 1893, 5837, 2149, 6721, 8570, 2783, 1175, 8285, 2077, 1358, 5589, 1416, 5991, 4714, 4928, 3725, 968, 8779, 4975, 9033, 8780, 1831, 6008, 6812, 4460, 8824, 6001, 5778, 4874, 1606, 3194, 5834, 5941, 5248, 1298, 3424, 2169, 1496, 8991, 4674, 4776, 34, 5718, 1098, 1058, 2898, 8681, 8620, 362, 5952, 1818, 697, 221, 4254, 1819, 7103, 6445, 8908, 4436, 8851, 6813, 6789, 3594, 5031, 6079, 4729, 8561, 2073, 1453, 228, 8825, 8431, 8486, 8468, 339, 913, 6436, 2189, 5329, 7148, 1434, 9105, 2962, 3882, 7723, 3312, 5623, 7881, 2143, 746, 1259, 5469, 3201, 1257, 3681, 8861, 352, 5309, 6237, 650, 770, 2957, 5739, 8155, 1272, 4657, 1986, 2084, 1633, 6243, 1300, 6476, 1887, 5712, 6165, 6736, 8730, 7587, 6283, 7803, 724, 7235, 8046, 7046, 7595, 9009, 5822, 8378, 3541, 566, 3641, 317, 421, 6356, 4980, 2805, 1221, 1935, 6470, 4462, 8000, 2510, 5107, 8723, 7593, 6484, 3865, 5497, 9214, 2236, 3447, 816, 7011, 3061, 1005, 124, 987, 8907, 459, 5440, 6965, 4588, 226, 4560, 508, 4453, 3497, 3578, 1616, 4127, 5271, 847, 5817, 7911, 4920, 4781, 3336, 5561, 7179, 8879, 7178, 5562, 1425, 1014, 4017, 8563, 814, 9055, 8773, 3762, 4414, 5828, 444, 7220, 5268, 2433, 6101, 5552, 4419, 2714, 7265, 8375, 7725, 5109, 45, 3203, 8451, 6179, 2634, 1144, 3189, 5631, 4769, 4716, 4138, 4143, 314, 502, 2533, 2135, 5987, 2447, 8656, 3200, 1622, 1750, 3030, 4425, 3833, 4718, 1638, 5989, 5161, 4477, 1792, 4989, 1374, 4300, 3575, 1512, 4019, 8975, 3381, 9195, 8236, 4276, 9088, 4932, 2839, 8597, 3091, 8443, 5546, 5021, 59, 6647, 992, 7346, 2788, 8127, 8894, 1608, 5585, 4251, 5353, 480, 4074, 3409, 7876, 8710, 2931, 2934, 4841, 8631, 7139, 1369, 6057, 3810, 4843, 5335, 6741, 8850, 3558, 3935, 5415, 6274, 7390, 759, 1267, 3572, 1508, 6492, 950, 8584, 5075, 4832, 2513, 7440, 1955, 1166, 5017, 8025, 7267, 3205, 8600, 5111, 168, 2129, 7538, 2946, 5809, 1624, 4269, 9157, 6105, 3214, 4023, 4670, 4196, 5494, 8424, 5679, 1476, 6877, 8544, 6316, 4566, 9081, 296, 8386, 569, 8549, 8885, 1237, 6930, 4105, 2040, 7511, 8455, 5647, 8925, 4306, 2361, 8737, 9018, 3679, 3244, 3223, 4514, 742, 2700, 9019, 7914, 8465, 6607, 1992, 2880, 8010, 2432, 8593, 2332, 4325, 7677, 8330, 479, 411, 2218, 7884, 7187, 4246, 7492, 3839, 6098, 6313, 3800, 8547, 5979, 7647, 3564, 3658, 7684, 3796, 250, 6963, 9139, 8936, 3082, 8159, 5364, 501, 1813, 5536, 820, 604, 771, 4415, 206, 3479, 6969, 3672, 7686, 7726, 8125, 1493, 461, 193, 5449, 6208, 1405, 2746, 6982, 2780, 1698, 8864, 3683, 8374, 7041, 7351, 4626, 8792, 163, 5626, 3509, 1671, 8915, 7093, 5726, 7450, 5907, 6185, 1696, 1429, 2554, 6719, 3761, 8803, 1947, 264, 4692, 397, 6829, 3682, 1513, 3816, 8642, 853, 8190, 1888, 6337, 5985, 3899, 6506, 3060, 7287, 7136, 6103, 6703, 7456, 3879, 1823, 2422, 5783, 256, 593, 9191, 7585, 4503, 1980, 5073, 1771, 6542, 1525, 787, 3780, 3853, 6040, 8202, 9185, 2244, 7757, 3395, 1291, 7659, 1357, 7368, 6917, 6799, 4830, 4615, 1642, 9205, 798, 7691, 192, 2216, 4258, 8874, 8938, 447, 633, 443, 4665, 9083, 2585, 2229, 6543, 4067, 3165, 7406, 3699, 9122, 8067, 4195, 3570, 6388, 5551, 3057, 7140, 8559, 1109, 2742, 4232, 1195, 6775, 6414, 5706, 3947, 4253, 7343, 7938, 7592, 2024, 1532, 7661, 2093, 4964, 4117, 266, 214, 517, 2702, 6594, 6498, 8234, 7253, 6564, 7780, 3519, 5318, 3913, 3102, 1862, 6549, 2953, 1579, 3826, 8774, 6153, 2090, 6682, 5709, 5753, 2026, 5986, 7503, 6260, 3948, 6599, 2757, 1341, 8255, 3426, 7116, 2460, 3917, 3804, 1625, 1858, 769, 5713, 6340, 3910, 1172, 5400, 7096, 8478, 87, 1032, 4844, 3348, 3088, 598, 267, 4070, 2737, 2922, 810, 7111, 1477, 2159, 6680, 2995, 1966, 1812, 6874, 930, 5630, 5690, 4667, 5603, 3229, 2902, 7795, 5719, 2462, 4230, 189, 861, 1959, 4837, 145, 3149, 3427, 4382, 4112, 6013, 792, 8114, 5766, 3226, 8292, 8605, 2346, 8323, 3087, 3877, 5912, 1170, 1202, 4189, 2813, 2015, 8466, 7513, 2037, 6635, 5163, 1604, 5887, 5211, 8325, 8959, 4191, 6056, 8116, 304, 3495, 6231, 2103, 4997, 2276, 9082, 7636, 4391, 5504, 2664, 8156, 8934, 9113, 4094, 4555, 4795, 8546, 8338, 5740, 3218, 1096, 141, 4813, 587, 5841, 6473, 7122, 7733, 3180, 4699, 2343, 7580, 285, 857, 7956, 6167, 634, 4715, 5208, 1984, 5788, 186, 1131, 4014, 5640, 7290, 8621, 7019, 3708, 7396, 6748, 4108, 8165, 81, 177, 2697, 5549, 6145, 2914, 3481, 5013, 5422, 8439, 3125, 8889, 8567, 1080, 1337, 6676, 9217, 3259, 5435, 6435, 3925, 3778, 5327, 5900, 5423, 167, 1460, 134, 1029, 274, 4638, 7350, 4970, 2124, 3132, 7258, 379, 4149, 2059, 1299, 7144, 6409, 4709, 5296, 1393, 6048, 7561, 3576, 1258, 6233, 6151, 5998, 6687, 9224, 998, 3357, 2772, 4429, 7312, 1607, 1056, 1564, 2022, 7228, 4763, 4190, 1282, 6729, 6772, 8498, 7756, 5620, 6553, 6174, 2473, 2707, 4264, 3940, 4592, 4637, 3512, 4122, 6922, 8207, 7969, 7869, 540, 5403, 279, 710, 6285, 545, 3745, 8568, 8203, 4612, 3633, 2329, 7671, 6787, 2695, 5123, 3178, 80, 6452, 4739, 5286, 3890, 5342, 56, 1503, 5582, 8366, 5379, 3260, 7558, 5357, 6860, 7785, 6598, 3099, 2563, 2314, 7356, 1849, 4301, 2988, 4424, 632, 3721, 7169, 1406, 3268, 3222, 4875, 1767, 8410, 473, 645, 6329, 5140, 7125, 3866, 6780, 5057, 2099, 3601, 5592, 5027, 6087, 5351, 2033, 1828, 2320, 4613, 1905, 2752, 3393, 3884, 1657, 5124, 3676, 546, 7947, 8790, 3976, 5608, 5737, 2384, 1461, 3896, 2522, 1672, 2730, 7673, 3664, 8196, 691, 1677, 5628, 695, 9061, 1481, 1499, 1601, 5518, 5067, 7556, 3975, 5369, 1522, 6513, 7031, 7807, 5064, 1511, 6749, 6289, 5505, 7194, 1929, 7546, 2082, 1979, 5503, 4768, 7718, 361, 4353, 5873, 155, 8081, 1330, 5244, 1087, 8960, 1539, 6076, 5175, 1765, 4629, 1554, 8534, 5045, 4085, 7205, 7875, 3793, 6428, 2083, 1660, 7729, 477, 8331, 3265, 4029, 5460, 8615, 3732, 3028, 4218, 3973, 1915, 271, 6307, 446, 463, 4888, 453, 448, 1842, 6462, 4998, 8749, 2886, 7428, 4872, 5217, 7062, 7666, 8308, 4180, 4447, 6709, 3202, 5338, 4663, 3628, 8686, 1867, 5772, 3245, 8217, 4144, 78, 4087, 5106, 5728, 8019, 4205, 741, 2021, 4590, 241, 3294, 3151, 3152, 3026, 8969, 6389, 8401, 8402, 8414, 6998, 6069, 4272, 7861, 5215, 5247, 4499, 4838, 1834, 1631, 924, 1082, 2446, 3573, 8232, 6771, 9036, 1762, 9064, 6304, 631, 8670, 829, 5259, 7910, 3100, 1311, 4032, 6491, 2572, 885, 7435, 2272, 6708, 349, 1572, 4356, 1011, 7239, 1090, 6978, 4871, 8639, 2403, 3096, 9197, 6563, 1949, 7834, 7765, 8808, 4942, 2475, 2469, 8526, 8157, 7134, 6007, 4056, 1153, 4478, 3320, 3817, 4377, 7352, 3361, 1743, 5976, 7578, 8744, 2374, 6583, 779, 9021, 2335, 4315, 3621, 5341, 2609, 6919, 564, 3511, 7426, 6880, 3885, 3496, 4850, 2764, 2945, 3421, 4668, 5835, 8506, 2738, 5221, 2935, 8163, 6080, 7827, 1409, 8417, 217, 5354, 969, 4912, 1709, 7747, 8632, 3931, 7226, 1575, 2603, 7922, 8714, 8815, 7419, 3107, 3310, 7092, 44, 747, 3217, 8034, 4489, 5138, 5686, 8476, 7474, 8571, 2734, 8448, 3758, 8213, 7879, 4741, 4762, 5932, 2811, 4825, 3630, 7525, 5054, 8727, 8189, 2069, 4044, 7466, 8258, 3880, 6065, 6512, 5758, 340, 6348, 869, 3922, 4971, 1246, 2720, 8899, 994, 6907, 3873, 1145, 2484, 1263, 5779, 803, 678, 2304, 8040, 3937, 4268, 973, 7717, 3062, 5972, 851, 4812, 874, 3701, 1732, 1928, 8702, 7164, 2869, 966, 7987, 6091, 2466, 3897, 8516, 2334, 7400, 3050, 6396, 8676, 739, 8521, 511, 1742, 8555, 7841, 7883, 6644, 6663, 1586, 1083, 1180, 1540, 2256, 5032, 961, 684, 8669, 839, 381, 6582, 7054, 6464, 2596, 7023, 717, 6518, 5102, 6330, 357, 315, 600, 420, 6921, 5436, 3170, 3484, 5730, 8619, 7781, 5260, 2180, 2264, 5754, 3475, 7568, 8732, 4069, 1384, 7799, 943, 828, 644, 8387, 4204, 1293, 4543, 8241, 4876, 1688, 5071, 4137, 5206, 6022, 6815, 6901, 663, 6704, 2074, 2080, 1524, 5521, 7270, 1122, 8502, 2146, 6417, 1667, 5396, 4598, 4518, 5662, 6379, 7429, 6378, 3181, 5434, 4520, 1821, 859, 860, 3474, 8617, 1354, 6878, 9035, 191, 4736, 1963, 2709, 3863, 3300, 5100, 2622, 310, 7551, 6383, 3232, 210, 713, 495, 1398, 3488, 2457, 3754, 6889, 6439, 5996, 7515, 4373, 5560, 3616, 7462, 60, 989, 2258, 8830, 404, 4511, 515, 394, 2012, 4155, 7837, 73, 144, 2940, 5432, 7437, 2459, 8856, 3212, 4060, 534, 7063, 1629, 5399, 7365, 7094, 2302, 6133, 7940, 6636, 3829, 1126, 8007, 8072, 5387, 7217, 6199, 6892, 1457, 9089, 7215, 5853, 3052, 8623, 6011, 656, 8943, 6665, 5962, 4124, 7091, 5598, 7484, 2482, 3651, 1229, 3324, 2119, 9034, 2078, 7712, 1142, 2464, 6415, 9219, 407, 440, 6269, 7825, 1475, 8845, 380, 1976, 5044, 5074, 5324, 3700, 2395, 2758, 5373, 5420, 4250, 8994, 313, 5937, 4072, 2944, 6111, 7859, 7003, 318, 605, 9056, 5398, 6569, 5672, 3470, 4967, 1059, 76, 212, 53, 5867, 6319, 6536, 1900, 4752, 6393, 7339, 5056, 7392, 2079, 8612, 7418, 3423, 3422, 164, 2731, 1149, 2209, 2224, 6166, 6207, 7177, 5154, 6632, 8063, 6205, 5205, 178, 687, 531, 7244, 8244, 4457, 1458, 6962, 4413, 8877, 8243, 5763, 2107, 8018, 3893, 1841, 1913, 6362, 8765, 5094, 2621, 2290, 4996, 5053, 2507, 2150, 7855, 751, 788, 844, 881, 984, 4639, 2862, 3743, 427, 5810, 5137, 988, 9060, 8978, 4008, 2182, 2840, 4995, 8390, 1345, 1066, 3958, 4430, 837, 3313, 2194, 2802, 1674, 8536, 3950, 9001, 3663, 7928, 5978, 7912, 491, 5789, 875, 706, 6883, 3528, 8724, 915, 2353, 3370, 7856, 1047, 5529, 661, 1043, 5523, 7451, 5697, 1863, 532, 8005, 4410, 2762, 4097, 9119, 1731, 5228, 863, 6072, 4536, 2239, 8460, 5750, 4192, 8194, 7566, 3892, 4774, 2763, 4064, 9111, 8263, 4202, 7331, 7168, 4986, 7633, 2438, 2525, 2178, 3656, 5509, 2727, 5187, 8575, 5322, 2092, 7095, 6085, 3371, 867, 5967, 7112, 8288, 1167, 2814, 672, 8963, 7745, 1210, 983, 2857, 3303, 9073, 4697, 244, 2949, 476, 8458, 1462, 8346, 2875, 3680, 941, 2328, 4213, 2355, 2607, 4568, 6115, 1626, 8097, 2658, 3828, 529, 858, 9059, 6952, 2512, 6202, 396, 5878, 2008, 8781, 5999, 1156, 582, 3654, 1961, 6182, 4158, 1602, 6538, 1559, 8307, 391, 3609, 9092, 8280, 2061, 5888, 5365, 4686, 4834, 2322, 5802, 4337, 1112, 1290, 6769, 5510, 172, 5824, 6539, 5741, 7008, 5308, 181, 743, 402, 2571, 2726, 2663, 322, 4411, 1158, 1394, 3035, 6175, 7613, 2222, 2288, 6407, 5627, 433, 9062, 9169, 8705, 120, 5002, 4156, 5924, 3943, 8740, 5040, 7359, 2643, 5916, 5541, 5556, 912, 801, 703, 1101, 5578, 428, 6610, 6626, 776, 7751, 6176, 7388, 5543, 300, 2872, 1187, 1561, 1650, 8643, 8405, 3405, 7227, 1241, 8050, 3858, 736, 5981, 3667, 2804, 6674, 2961, 1485, 7626, 3131, 6706, 5502, 4142, 3135, 8980, 7784, 3055, 1312, 8628, 3824, 7189, 4106, 3279, 8441, 2816, 7743, 2860, 4688, 4794, 6055, 7787, 9198, 1588, 4193, 8706, 6804, 6572, 2623, 4026, 1313, 4030, 3372, 1788, 5038, 719, 6822, 183, 8581, 4279, 6678, 1469, 8209, 1691, 5550, 1233, 5548, 5183, 69, 3196, 8197, 4363, 8315, 5884, 4326, 1140, 9200, 7032, 3821, 6156, 7076, 4634, 3909, 6528, 3595, 1730, 2176, 2818, 6015, 8471, 6110, 8361, 4081, 6437, 8461, 3719, 1977, 7100, 622, 7061, 3809, 5780, 8813, 7608, 8293, 8602, 2365, 1651, 3343, 3341, 8590, 7327, 3333, 4711, 1829, 6991, 8996, 5028, 3755, 4383, 3691, 6989, 8501, 9006, 6714, 2393, 1552, 7564, 4903, 5576, 6005, 9065, 4121, 3724, 6783, 6713, 4965, 4365, 4687, 3539, 2273, 6327, 7660, 7746, 4681, 1833, 2916, 7557, 6646, 179, 683, 518, 8552, 6562, 1473, 7459, 283, 8179, 7992, 3463, 259, 5142, 3038, 7736, 1352, 8310, 2539, 1081, 5699, 3010, 7852, 6988, 4077, 7211, 1455, 4086, 4831, 4690, 3586, 275, 5416, 581, 3747, 466, 6836, 6673, 8314, 8309, 5557, 1694, 8069, 1154, 3387, 6024, 7014, 6943, 5224, 2496, 1231, 7243, 6561, 4422, 5803, 3704, 1881, 3705, 4071, 6232, 1403, 590, 7668, 8871, 7665, 6814, 3113, 4570, 3998, 8837, 2226, 6433, 3920, 7742, 2505, 4606, 7676, 8024, 3535, 7770, 5927, 8492, 3928, 1871, 1303, 1484, 6957, 7361, 3574, 5332, 6149, 324, 3210, 3089, 2773, 403, 190, 2349, 6999, 4091, 4886, 426, 6116, 3870, 953, 6517, 8929, 4252, 9044, 7518, 8771, 42, 7600, 5283, 5191, 2991, 8110, 7792, 4093, 3567, 1226, 5920, 9180, 1456, 2519, 5860, 6817, 1747, 2106, 7141, 9231, 9229, 9230, 1938, 3596, 6485, 7886, 775, 3399, 7277, 7318, 8606, 4525, 6288, 8944, 563, 1940, 6617, 3587, 7943, 3499, 246, 429, 1505, 8177, 1770, 3526, 9166, 8966, 3555, 7276, 716, 613, 84, 4905, 3108, 7242, 6142, 8210, 7681, 2488, 4265, 5638, 2263, 6798, 3941, 2232, 1846, 6847, 7527, 1909, 702, 33, 9057, 3959, 1720, 9042, 8311, 8188, 904, 9215, 225, 5559, 6336, 5664, 4157, 8174, 2380, 7711, 4166, 284, 4930, 4900, 6781, 9134, 5507, 6856, 1843, 5848, 572, 108, 6249, 5241, 8419, 7553, 7552, 918, 975, 7930, 8164, 72, 219, 675, 54, 4343, 4963, 1874, 3161, 6679, 9168, 6718, 5312, 6979, 2351, 2231, 2719, 714, 519, 2874, 4517, 7933, 2407, 1163, 2235, 3924, 520, 8755, 658, 649, 2196, 4403, 7153, 4807, 1595, 5511, 2784, 2241, 4671, 4027, 1724, 2562, 7560, 1630, 7779, 4432, 4706, 7278, 6516, 8464, 1092, 744, 2760, 5731, 3040, 4061, 5098, 6987, 203, 6235, 7793, 1781])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fe0dbf8d5f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '!'),\n",
       " (1, '\"'),\n",
       " (2, '#'),\n",
       " (3, '#150'),\n",
       " (4, '#5000'),\n",
       " (5, '$'),\n",
       " (6, '%'),\n",
       " (7, '&'),\n",
       " (8, \"'\"),\n",
       " (9, '('),\n",
       " (10, ')'),\n",
       " (11, '*'),\n",
       " (12, '+'),\n",
       " (13, ','),\n",
       " (14, '-'),\n",
       " (15, '.'),\n",
       " (16, '. .'),\n",
       " (17, '. . .'),\n",
       " (18, '. . . .'),\n",
       " (19, '. . . . .'),\n",
       " (20, '. ..'),\n",
       " (21, '..'),\n",
       " (22, '.. .'),\n",
       " (23, '.. . . .'),\n",
       " (24, '.. ... ...'),\n",
       " (25, '...'),\n",
       " (26, '... . . . .'),\n",
       " (27, '/'),\n",
       " (28, '0'),\n",
       " (29, '00'),\n",
       " (30, '00870405040'),\n",
       " (31, '0089'),\n",
       " (32, '01'),\n",
       " (33, '0121 2025050'),\n",
       " (34, '01223585236'),\n",
       " (35, '01223585334'),\n",
       " (36, '01256987'),\n",
       " (37, '02'),\n",
       " (38, '02/06'),\n",
       " (39, '02/09'),\n",
       " (40, '0207 153 9153'),\n",
       " (41, '0207 153 9996'),\n",
       " (42, '0207-083-6089'),\n",
       " (43, '02072069400'),\n",
       " (44, '02073162414'),\n",
       " (45, '02085076972'),\n",
       " (46, '03'),\n",
       " (47, '03530150'),\n",
       " (48, '04'),\n",
       " (49, '04/09'),\n",
       " (50, '05'),\n",
       " (51, '050703'),\n",
       " (52, '06'),\n",
       " (53, '06.05'),\n",
       " (54, '06/11'),\n",
       " (55, '07/11'),\n",
       " (56, '07008009200'),\n",
       " (57, '07046744435'),\n",
       " (58, '07090201529'),\n",
       " (59, '07090298926'),\n",
       " (60, '07099833605'),\n",
       " (61, '07123456789'),\n",
       " (62, '07732584351'),\n",
       " (63, '07734396839'),\n",
       " (64, '07742676969'),\n",
       " (65, '07753741225'),\n",
       " (66, '0776xxxxxxx'),\n",
       " (67, '07786200117'),\n",
       " (68, '077xxx'),\n",
       " (69, '078'),\n",
       " (70, '07801543489'),\n",
       " (71, '07808'),\n",
       " (72, '07808247860'),\n",
       " (73, '07808726822'),\n",
       " (74, '07815296484'),\n",
       " (75, '07821230901'),\n",
       " (76, '078498'),\n",
       " (77, '07880867867'),\n",
       " (78, '0789xxxxxxx'),\n",
       " (79, '07946746291'),\n",
       " (80, '0796xxxxxx'),\n",
       " (81, '07973788240'),\n",
       " (82, '07xxxxxxxxx'),\n",
       " (83, '08'),\n",
       " (84, '0800'),\n",
       " (85, '0800 0721072'),\n",
       " (86, '0800 169 6031'),\n",
       " (87, '0800 195 6669'),\n",
       " (88, '0800 1956669'),\n",
       " (89, '0800 5050'),\n",
       " (90, '0800 542 0578'),\n",
       " (91, '0800 542 0825'),\n",
       " (92, '08000407165'),\n",
       " (93, '08000776320'),\n",
       " (94, '08000839402'),\n",
       " (95, '08000930705'),\n",
       " (96, '08000938767'),\n",
       " (97, '08001950382'),\n",
       " (98, '08002888812'),\n",
       " (99, '08002986030'),\n",
       " (100, '08002986906'),\n",
       " (101, '08002988890'),\n",
       " (102, '08006344447'),\n",
       " (103, '0808 145 4742'),\n",
       " (104, '08081263000'),\n",
       " (105, '08081560665'),\n",
       " (106, '0819'),\n",
       " (107, '0844'),\n",
       " (108, '08448350055'),\n",
       " (109, '08448714184'),\n",
       " (110, '0845 021 3680'),\n",
       " (111, '0845 2814032'),\n",
       " (112, '08450542832'),\n",
       " (113, '08452810071'),\n",
       " (114, '08452810073'),\n",
       " (115, '08452810075'),\n",
       " (116, '0870'),\n",
       " (117, '08700435505'),\n",
       " (118, '08700469649'),\n",
       " (119, '08700621170'),\n",
       " (120, '08701213186'),\n",
       " (121, '08701237397'),\n",
       " (122, '08701417012'),\n",
       " (123, '08701624'),\n",
       " (124, '08701752560'),\n",
       " (125, '08701872873'),\n",
       " (126, '08702411827'),\n",
       " (127, '08702490080'),\n",
       " (128, '08702840625'),\n",
       " (129, '08702840625.comuk'),\n",
       " (130, '08704050406'),\n",
       " (131, '08704439680'),\n",
       " (132, '08706091795'),\n",
       " (133, '08707379102'),\n",
       " (134, '08707500020'),\n",
       " (135, '08707509020'),\n",
       " (136, '08707533310'),\n",
       " (137, '08707808226'),\n",
       " (138, '08708034412'),\n",
       " (139, '08708800282'),\n",
       " (140, '08709222922'),\n",
       " (141, '08709501522'),\n",
       " (142, '0871-4719'),\n",
       " (143, '0871-872-9755'),\n",
       " (144, '0871-872-9758'),\n",
       " (145, '08710471114'),\n",
       " (146, '08712101358'),\n",
       " (147, '08712103738'),\n",
       " (148, '08712120250'),\n",
       " (149, '08712300220'),\n",
       " (150, '08712317606'),\n",
       " (151, '08712400200'),\n",
       " (152, '08712400602'),\n",
       " (153, '08712400603'),\n",
       " (154, '08712402050'),\n",
       " (155, '08712402578'),\n",
       " (156, '08712402779'),\n",
       " (157, '08712402902'),\n",
       " (158, '08712402972'),\n",
       " (159, '08712404000'),\n",
       " (160, '08712405020'),\n",
       " (161, '08712405022'),\n",
       " (162, '08712460324'),\n",
       " (163, '08712466669'),\n",
       " (164, '08712778107'),\n",
       " (165, '08712778108'),\n",
       " (166, '08712778109'),\n",
       " (167, '08714342399'),\n",
       " (168, '08714712377'),\n",
       " (169, '08714712379'),\n",
       " (170, '08714712388'),\n",
       " (171, '08714712394'),\n",
       " (172, '08714712412'),\n",
       " (173, '08714714011'),\n",
       " (174, '08714740323'),\n",
       " (175, '08714742804'),\n",
       " (176, '08715203028'),\n",
       " (177, '08715203649'),\n",
       " (178, '08715203652'),\n",
       " (179, '08715203656'),\n",
       " (180, '08715203677'),\n",
       " (181, '08715203685'),\n",
       " (182, '08715203694'),\n",
       " (183, '08715205273'),\n",
       " (184, '08715500022'),\n",
       " (185, '08715705022'),\n",
       " (186, '08717111821'),\n",
       " (187, '08717168528'),\n",
       " (188, '08717205546'),\n",
       " (189, '0871750'),\n",
       " (190, '08717507382'),\n",
       " (191, '08717509990'),\n",
       " (192, '08717890890'),\n",
       " (193, '08717895698'),\n",
       " (194, '08717898035'),\n",
       " (195, '08718711108'),\n",
       " (196, '08718720201'),\n",
       " (197, '08718723815'),\n",
       " (198, '08718725756'),\n",
       " (199, '08718726270'),\n",
       " (200, '08718726970'),\n",
       " (201, '08718726971'),\n",
       " (202, '08718726978'),\n",
       " (203, '08718727200'),\n",
       " (204, '08718727868'),\n",
       " (205, '08718727870'),\n",
       " (206, '08718728876'),\n",
       " (207, '08718730555'),\n",
       " (208, '08718730666'),\n",
       " (209, '08718738001'),\n",
       " (210, '08718738002'),\n",
       " (211, '08718738034'),\n",
       " (212, '08719180219'),\n",
       " (213, '08719180248'),\n",
       " (214, '08719181259'),\n",
       " (215, '08719181503'),\n",
       " (216, '08719181513'),\n",
       " (217, '08719839835'),\n",
       " (218, '08719899217'),\n",
       " (219, '08719899229'),\n",
       " (220, '08719899230'),\n",
       " (221, '09'),\n",
       " (222, '09041940223'),\n",
       " (223, '09050000301'),\n",
       " (224, '09050000327'),\n",
       " (225, '09050000332'),\n",
       " (226, '09050000460'),\n",
       " (227, '09050000555'),\n",
       " (228, '09050000878'),\n",
       " (229, '09050000928'),\n",
       " (230, '09050001295'),\n",
       " (231, '09050001808'),\n",
       " (232, '09050002311'),\n",
       " (233, '09050003091'),\n",
       " (234, '09050005321'),\n",
       " (235, '09050090044'),\n",
       " (236, '09050280520'),\n",
       " (237, '09053750005'),\n",
       " (238, '09056242159'),\n",
       " (239, '09057039994'),\n",
       " (240, '09058091854'),\n",
       " (241, '09058091870'),\n",
       " (242, '09058094454'),\n",
       " (243, '09058094455'),\n",
       " (244, '09058094507'),\n",
       " (245, '09058094565'),\n",
       " (246, '09058094583'),\n",
       " (247, '09058094594'),\n",
       " (248, '09058094597'),\n",
       " (249, '09058094599'),\n",
       " (250, '09058095107'),\n",
       " (251, '09058095201'),\n",
       " (252, '09058097189'),\n",
       " (253, '09058097218'),\n",
       " (254, '09058098002'),\n",
       " (255, '09058099801'),\n",
       " (256, '09061104276'),\n",
       " (257, '09061104283'),\n",
       " (258, '09061209465'),\n",
       " (259, '09061213237'),\n",
       " (260, '09061221061'),\n",
       " (261, '09061221066'),\n",
       " (262, '09061701444'),\n",
       " (263, '09061701461'),\n",
       " (264, '09061701851'),\n",
       " (265, '09061701939'),\n",
       " (266, '09061702893'),\n",
       " (267, '09061743386'),\n",
       " (268, '09061743806'),\n",
       " (269, '09061743810'),\n",
       " (270, '09061743811'),\n",
       " (271, '09061744553'),\n",
       " (272, '09061749602'),\n",
       " (273, '09061790121'),\n",
       " (274, '09061790125'),\n",
       " (275, '09061790126'),\n",
       " (276, '09063440451'),\n",
       " (277, '09063442151'),\n",
       " (278, '09063458130'),\n",
       " (279, '09063463'),\n",
       " (280, '09064011000'),\n",
       " (281, '09064012103'),\n",
       " (282, '09064012160'),\n",
       " (283, '09064015307'),\n",
       " (284, '09064017295'),\n",
       " (285, '09064017305'),\n",
       " (286, '09064018838'),\n",
       " (287, '09064019014'),\n",
       " (288, '09064019788'),\n",
       " (289, '09065069120'),\n",
       " (290, '09065069154'),\n",
       " (291, '09065171142'),\n",
       " (292, '09065174042'),\n",
       " (293, '09065394514'),\n",
       " (294, '09065394973'),\n",
       " (295, '09065989180'),\n",
       " (296, '09065989182'),\n",
       " (297, '09066350750'),\n",
       " (298, '09066358152'),\n",
       " (299, '09066358361'),\n",
       " (300, '09066361921'),\n",
       " (301, '09066362206'),\n",
       " (302, '09066362220'),\n",
       " (303, '09066362231'),\n",
       " (304, '09066364311'),\n",
       " (305, '09066364349'),\n",
       " (306, '09066364589'),\n",
       " (307, '09066368327'),\n",
       " (308, '09066368470'),\n",
       " (309, '09066368753'),\n",
       " (310, '09066380611'),\n",
       " (311, '09066382422'),\n",
       " (312, '09066612661'),\n",
       " (313, '09066649731'),\n",
       " (314, '09066660100'),\n",
       " (315, '09071512432'),\n",
       " (316, '09071512433'),\n",
       " (317, '09071517866'),\n",
       " (318, '09077818151'),\n",
       " (319, '09090204448'),\n",
       " (320, '09090900040'),\n",
       " (321, '09094100151'),\n",
       " (322, '09094646631'),\n",
       " (323, '09094646899'),\n",
       " (324, '09095350301'),\n",
       " (325, '09096102316'),\n",
       " (326, '09099725823'),\n",
       " (327, '09099726395'),\n",
       " (328, '09099726429'),\n",
       " (329, '09099726481'),\n",
       " (330, '09099726553'),\n",
       " (331, '09111030116'),\n",
       " (332, '09111032124'),\n",
       " (333, '09701213186'),\n",
       " (334, '0a'),\n",
       " (335, '0p'),\n",
       " (336, '0quit'),\n",
       " (337, '1'),\n",
       " (338, '1,000'),\n",
       " (339, '1,2'),\n",
       " (340, '1,50'),\n",
       " (341, '1,500'),\n",
       " (342, '1.20'),\n",
       " (343, '1.5'),\n",
       " (344, '1.50'),\n",
       " (345, '1.childish'),\n",
       " (346, '1/08'),\n",
       " (347, '1/1'),\n",
       " (348, '1/2'),\n",
       " (349, '1/3'),\n",
       " (350, '10'),\n",
       " (351, '10,000'),\n",
       " (352, '10.1'),\n",
       " (353, '10/06'),\n",
       " (354, '100'),\n",
       " (355, '100,000'),\n",
       " (356, '1000'),\n",
       " (357, '1000call'),\n",
       " (358, '1000s'),\n",
       " (359, '100p'),\n",
       " (360, '100txt'),\n",
       " (361, '1013'),\n",
       " (362, '1030'),\n",
       " (363, '10:10'),\n",
       " (364, '10:30'),\n",
       " (365, '10am'),\n",
       " (366, '10k'),\n",
       " (367, '10mins'),\n",
       " (368, '10p'),\n",
       " (369, '10ppm'),\n",
       " (370, '10th'),\n",
       " (371, '11'),\n",
       " (372, '11.48'),\n",
       " (373, '1120'),\n",
       " (374, '113'),\n",
       " (375, '1131'),\n",
       " (376, '114/14'),\n",
       " (377, '1146'),\n",
       " (378, '1151'),\n",
       " (379, '116'),\n",
       " (380, '1172'),\n",
       " (381, '118p'),\n",
       " (382, '11mths'),\n",
       " (383, '11pm'),\n",
       " (384, '12'),\n",
       " (385, '12,000'),\n",
       " (386, '1205'),\n",
       " (387, '120p'),\n",
       " (388, '121'),\n",
       " (389, '1225'),\n",
       " (390, '123'),\n",
       " (391, '125'),\n",
       " (392, '1250'),\n",
       " (393, '125gift'),\n",
       " (394, '128'),\n",
       " (395, '1282essexcm61xn'),\n",
       " (396, '12:30'),\n",
       " (397, '12hours'),\n",
       " (398, '12hrs'),\n",
       " (399, '12mths'),\n",
       " (400, '12n146tf15'),\n",
       " (401, '12n146tf150p'),\n",
       " (402, '13/10'),\n",
       " (403, '13/4'),\n",
       " (404, '130'),\n",
       " (405, '1327'),\n",
       " (406, '139'),\n",
       " (407, '140'),\n",
       " (408, '1405'),\n",
       " (409, '140ppm'),\n",
       " (410, '1450'),\n",
       " (411, '146tf150p'),\n",
       " (412, '14thmarch'),\n",
       " (413, '150'),\n",
       " (414, '1500'),\n",
       " (415, '150p'),\n",
       " (416, '150p16'),\n",
       " (417, '150pm'),\n",
       " (418, '150ppermesssubscription'),\n",
       " (419, '150ppm'),\n",
       " (420, '150ppmmobilesvary'),\n",
       " (421, '150ppmpobox10183bhamb64xe'),\n",
       " (422, '150ppmsg'),\n",
       " (423, '150ppmx3age16'),\n",
       " (424, '150pw'),\n",
       " (425, '150x3'),\n",
       " (426, '151'),\n",
       " (427, '1510'),\n",
       " (428, '15541'),\n",
       " (429, '15:26'),\n",
       " (430, '15h'),\n",
       " (431, '16'),\n",
       " (432, '16.150'),\n",
       " (433, '165'),\n",
       " (434, '1680'),\n",
       " (435, '16yrs'),\n",
       " (436, '177'),\n",
       " (437, '177hp51fl'),\n",
       " (438, '18'),\n",
       " (439, '18/11'),\n",
       " (440, '180'),\n",
       " (441, '1843'),\n",
       " (442, '1896wc1n3xx'),\n",
       " (443, '18:0430-'),\n",
       " (444, '18p'),\n",
       " (445, '18yrs'),\n",
       " (446, '1apple'),\n",
       " (447, '1b6a5ecef91ff9'),\n",
       " (448, '1cup'),\n",
       " (449, '1da'),\n",
       " (450, '1er'),\n",
       " (451, '1hr'),\n",
       " (452, '1im'),\n",
       " (453, '1lemon'),\n",
       " (454, '1million'),\n",
       " (455, '1more'),\n",
       " (456, '1n3xx'),\n",
       " (457, '1pm'),\n",
       " (458, '1st'),\n",
       " (459, '1st4terms'),\n",
       " (460, '1stchoice.co.uk'),\n",
       " (461, '1stone'),\n",
       " (462, '1thing'),\n",
       " (463, '1tulsi'),\n",
       " (464, '1win150ppmx3'),\n",
       " (465, '1win150ppmx3age16'),\n",
       " (466, '1win150ppmx3age16subscription'),\n",
       " (467, '1winaweek'),\n",
       " (468, '1winawk'),\n",
       " (469, '1x150p'),\n",
       " (470, '1yf'),\n",
       " (471, '2'),\n",
       " (472, '2,000'),\n",
       " (473, '2-4-'),\n",
       " (474, '2.15'),\n",
       " (475, '2.30'),\n",
       " (476, '2.50'),\n",
       " (477, '2.im'),\n",
       " (478, '2.naughty'),\n",
       " (479, '2/2'),\n",
       " (480, '2/3'),\n",
       " (481, '20'),\n",
       " (482, '20,000'),\n",
       " (483, '200'),\n",
       " (484, '2000'),\n",
       " (485, '2003'),\n",
       " (486, '2004'),\n",
       " (487, '2005'),\n",
       " (488, '2006'),\n",
       " (489, '2007'),\n",
       " (490, '200p'),\n",
       " (491, '202'),\n",
       " (492, '20m12aq'),\n",
       " (493, '20p'),\n",
       " (494, '21'),\n",
       " (495, '21/11'),\n",
       " (496, '2187000'),\n",
       " (497, '21st'),\n",
       " (498, '22'),\n",
       " (499, '220'),\n",
       " (500, '220cm2'),\n",
       " (501, '23'),\n",
       " (502, '2309'),\n",
       " (503, '23f'),\n",
       " (504, '23g'),\n",
       " (505, '24'),\n",
       " (506, '24/10'),\n",
       " (507, '24/7'),\n",
       " (508, '245c2150pm'),\n",
       " (509, '24hrs'),\n",
       " (510, '24m'),\n",
       " (511, '24th'),\n",
       " (512, '25'),\n",
       " (513, '250'),\n",
       " (514, '250k'),\n",
       " (515, '255'),\n",
       " (516, '25p'),\n",
       " (517, '26.03'),\n",
       " (518, '26/10'),\n",
       " (519, '26/11'),\n",
       " (520, '2667'),\n",
       " (521, '26th'),\n",
       " (522, '27/03'),\n",
       " (523, '27/6'),\n",
       " (524, '28'),\n",
       " (525, '28/5'),\n",
       " (526, '28days'),\n",
       " (527, '28th'),\n",
       " (528, '28thfeb'),\n",
       " (529, '29'),\n",
       " (530, '29/03'),\n",
       " (531, '29/10'),\n",
       " (532, '2b'),\n",
       " (533, '2bed'),\n",
       " (534, '2bold'),\n",
       " (535, '2bremoved'),\n",
       " (536, '2c'),\n",
       " (537, '2channel'),\n",
       " (538, '2come'),\n",
       " (539, '2day'),\n",
       " (540, '2day.love'),\n",
       " (541, '2die'),\n",
       " (542, '2docd.please'),\n",
       " (543, '2end'),\n",
       " (544, '2exit'),\n",
       " (545, '2ez'),\n",
       " (546, '2find'),\n",
       " (547, '2getha'),\n",
       " (548, '2geva'),\n",
       " (549, '2go'),\n",
       " (550, '2go.did'),\n",
       " (551, '2gthr'),\n",
       " (552, '2hear'),\n",
       " (553, '2hook'),\n",
       " (554, '2hrs'),\n",
       " (555, '2i'),\n",
       " (556, '2kbsubject'),\n",
       " (557, '2marrow'),\n",
       " (558, '2mobile'),\n",
       " (559, '2moro'),\n",
       " (560, '2morow'),\n",
       " (561, '2morro'),\n",
       " (562, '2morrow'),\n",
       " (563, '2morrowxxxx'),\n",
       " (564, '2mro'),\n",
       " (565, '2mrw'),\n",
       " (566, '2mwen'),\n",
       " (567, '2nd'),\n",
       " (568, '2nhite'),\n",
       " (569, '2nights'),\n",
       " (570, '2nite'),\n",
       " (571, '2optout'),\n",
       " (572, '2p'),\n",
       " (573, '2px'),\n",
       " (574, '2rcv'),\n",
       " (575, '2stop'),\n",
       " (576, '2stoptx'),\n",
       " (577, '2stoptxt'),\n",
       " (578, '2tell'),\n",
       " (579, '2the'),\n",
       " (580, '2u'),\n",
       " (581, '2u2'),\n",
       " (582, '2watershd'),\n",
       " (583, '2waxsto'),\n",
       " (584, '2wks'),\n",
       " (585, '2worzels'),\n",
       " (586, '2wt'),\n",
       " (587, '2wu'),\n",
       " (588, '2years'),\n",
       " (589, '2yr'),\n",
       " (590, '2yrs'),\n",
       " (591, '3'),\n",
       " (592, '3.00'),\n",
       " (593, '3.75'),\n",
       " (594, '3.99'),\n",
       " (595, '3.sentiment'),\n",
       " (596, '30'),\n",
       " (597, '300'),\n",
       " (598, '3000'),\n",
       " (599, '300603'),\n",
       " (600, '300603t'),\n",
       " (601, '300p'),\n",
       " (602, '3030'),\n",
       " (603, '30apr'),\n",
       " (604, '30pp'),\n",
       " (605, '30s'),\n",
       " (606, '30th'),\n",
       " (607, '31'),\n",
       " (608, '31/10'),\n",
       " (609, '3100'),\n",
       " (610, '310303'),\n",
       " (611, '31p'),\n",
       " (612, '32'),\n",
       " (613, '32000'),\n",
       " (614, '3230'),\n",
       " (615, '32323'),\n",
       " (616, '326'),\n",
       " (617, '33.65'),\n",
       " (618, '330'),\n",
       " (619, '334'),\n",
       " (620, '334sk38ch'),\n",
       " (621, '3355'),\n",
       " (622, '33:50'),\n",
       " (623, '342/2'),\n",
       " (624, '350'),\n",
       " (625, '3510i'),\n",
       " (626, '35p'),\n",
       " (627, '3650'),\n",
       " (628, '36504'),\n",
       " (629, '36504w45wq'),\n",
       " (630, '365o4w45wq'),\n",
       " (631, '373'),\n",
       " (632, '3750'),\n",
       " (633, '37819'),\n",
       " (634, '38'),\n",
       " (635, '385'),\n",
       " (636, '391784'),\n",
       " (637, '39822'),\n",
       " (638, '3aj'),\n",
       " (639, '3cktz8r7'),\n",
       " (640, '3d'),\n",
       " (641, '3days'),\n",
       " (642, '3g'),\n",
       " (643, '3gbp'),\n",
       " (644, '3hrs'),\n",
       " (645, '3lions'),\n",
       " (646, '3lp'),\n",
       " (647, '3miles'),\n",
       " (648, '3mins'),\n",
       " (649, '3mobile'),\n",
       " (650, '3optical'),\n",
       " (651, '3pound'),\n",
       " (652, '3qxj9'),\n",
       " (653, '3rd'),\n",
       " (654, '3ss'),\n",
       " (655, '3uz'),\n",
       " (656, '3wks'),\n",
       " (657, '3x'),\n",
       " (658, '3xx'),\n",
       " (659, '4'),\n",
       " (660, '4-6'),\n",
       " (661, '4-7'),\n",
       " (662, '4.15'),\n",
       " (663, '4.30'),\n",
       " (664, '4.47'),\n",
       " (665, '4.49'),\n",
       " (666, '4.50'),\n",
       " (667, '4.cook'),\n",
       " (668, '4.rowdy'),\n",
       " (669, '40'),\n",
       " (670, '400'),\n",
       " (671, '400mins'),\n",
       " (672, '402'),\n",
       " (673, '403'),\n",
       " (674, '4041'),\n",
       " (675, '40411'),\n",
       " (676, '40533'),\n",
       " (677, '40gb'),\n",
       " (678, '40mph'),\n",
       " (679, '41'),\n",
       " (680, '41685'),\n",
       " (681, '41782'),\n",
       " (682, '420'),\n",
       " (683, '42049'),\n",
       " (684, '4217'),\n",
       " (685, '4235wc1n3xx'),\n",
       " (686, '42478'),\n",
       " (687, '42810'),\n",
       " (688, '4284'),\n",
       " (689, '42moro'),\n",
       " (690, '42wr29c'),\n",
       " (691, '430'),\n",
       " (692, '434'),\n",
       " (693, '434sk38wp150ppm18'),\n",
       " (694, '44'),\n",
       " (695, '440'),\n",
       " (696, '4403ldnw1a7rw18'),\n",
       " (697, '4477977060'),\n",
       " (698, '4478012592'),\n",
       " (699, '4487124040'),\n",
       " (700, '4490500003'),\n",
       " (701, '4490715124'),\n",
       " (702, '45'),\n",
       " (703, '450'),\n",
       " (704, '450p'),\n",
       " (705, '450ppw'),\n",
       " (706, '450pw'),\n",
       " (707, '45239'),\n",
       " (708, '45po139wa'),\n",
       " (709, '45w2tg150p'),\n",
       " (710, '47'),\n",
       " (711, '48'),\n",
       " (712, '4882'),\n",
       " (713, '48922'),\n",
       " (714, '49557'),\n",
       " (715, '4a'),\n",
       " (716, '4an18th'),\n",
       " (717, '4brekkie'),\n",
       " (718, '4d'),\n",
       " (719, '4eva'),\n",
       " (720, '4few'),\n",
       " (721, '4fil'),\n",
       " (722, '4get'),\n",
       " (723, '4get2text'),\n",
       " (724, '4give'),\n",
       " (725, '4got'),\n",
       " (726, '4goten'),\n",
       " (727, '4info'),\n",
       " (728, '4jx'),\n",
       " (729, '4msgs'),\n",
       " (730, '4mths'),\n",
       " (731, '4my'),\n",
       " (732, '4qf2'),\n",
       " (733, '4t'),\n",
       " (734, '4th'),\n",
       " (735, '4the'),\n",
       " (736, '4thnov.behind'),\n",
       " (737, '4txt'),\n",
       " (738, '4u'),\n",
       " (739, '4utxt'),\n",
       " (740, '4w'),\n",
       " (741, '4ward'),\n",
       " (742, '4wrd'),\n",
       " (743, '4xx26'),\n",
       " (744, '4years'),\n",
       " (745, '5'),\n",
       " (746, '5.00'),\n",
       " (747, '5.15'),\n",
       " (748, '5.30'),\n",
       " (749, '5.ful'),\n",
       " (750, '5.gardener'),\n",
       " (751, '5.terror'),\n",
       " (752, '5/9'),\n",
       " (753, '50'),\n",
       " (754, '500'),\n",
       " (755, '5000'),\n",
       " (756, '5000.00'),\n",
       " (757, '50award'),\n",
       " (758, '50p'),\n",
       " (759, '50s'),\n",
       " (760, '5120'),\n",
       " (761, '515'),\n",
       " (762, '5226'),\n",
       " (763, '523'),\n",
       " (764, '5249'),\n",
       " (765, '526'),\n",
       " (766, '528'),\n",
       " (767, '530'),\n",
       " (768, '54'),\n",
       " (769, '545'),\n",
       " (770, '5digital'),\n",
       " (771, '5free'),\n",
       " (772, '5ish'),\n",
       " (773, '5k'),\n",
       " (774, '5min'),\n",
       " (775, '5mls'),\n",
       " (776, '5p'),\n",
       " (777, '5pm'),\n",
       " (778, '5th'),\n",
       " (779, '5times'),\n",
       " (780, '5wb'),\n",
       " (781, '5we'),\n",
       " (782, '5wkg'),\n",
       " (783, '5wq'),\n",
       " (784, '5years'),\n",
       " (785, '6'),\n",
       " (786, '6.30'),\n",
       " (787, '6.45'),\n",
       " (788, '6.cruel'),\n",
       " (789, '6.house'),\n",
       " (790, '6.romantic'),\n",
       " (791, '60'),\n",
       " (792, '60,400'),\n",
       " (793, '600'),\n",
       " (794, '60p'),\n",
       " (795, '61'),\n",
       " (796, '61200'),\n",
       " (797, '61610'),\n",
       " (798, '62220cncl'),\n",
       " (799, '6230'),\n",
       " (800, '62468'),\n",
       " (801, '62735'),\n",
       " (802, '630'),\n",
       " (803, '63miles'),\n",
       " (804, '645'),\n",
       " (805, '65,61'),\n",
       " (806, '650'),\n",
       " (807, '66,382'),\n",
       " (808, '6600'),\n",
       " (809, '6650'),\n",
       " (810, '674'),\n",
       " (811, '6744123'),\n",
       " (812, '68866'),\n",
       " (813, '69'),\n",
       " (814, '69101'),\n",
       " (815, '69200'),\n",
       " (816, '69669'),\n",
       " (817, '69696'),\n",
       " (818, '69698'),\n",
       " (819, '69855'),\n",
       " (820, '69866.18'),\n",
       " (821, '69876'),\n",
       " (822, '69888'),\n",
       " (823, '69888nyt'),\n",
       " (824, '69911'),\n",
       " (825, '69969'),\n",
       " (826, '69988'),\n",
       " (827, '6days'),\n",
       " (828, '6gbp'),\n",
       " (829, '6hl'),\n",
       " (830, '6hrs'),\n",
       " (831, '6ish'),\n",
       " (832, '6missed'),\n",
       " (833, '6months'),\n",
       " (834, '6ph'),\n",
       " (835, '6pm'),\n",
       " (836, '6th'),\n",
       " (837, '6times'),\n",
       " (838, '6wu'),\n",
       " (839, '6zf'),\n",
       " (840, '7'),\n",
       " (841, '7.30'),\n",
       " (842, '7.8'),\n",
       " (843, '7.children'),\n",
       " (844, '7.romantic'),\n",
       " (845, '7.shy'),\n",
       " (846, '700'),\n",
       " (847, '71'),\n",
       " (848, '7250'),\n",
       " (849, '7250i'),\n",
       " (850, '730'),\n",
       " (851, '731'),\n",
       " (852, '734ls27yf'),\n",
       " (853, '74355'),\n",
       " (854, '75,000'),\n",
       " (855, '750'),\n",
       " (856, '7548'),\n",
       " (857, '75ldns7'),\n",
       " (858, '762'),\n",
       " (859, '7634'),\n",
       " (860, '7684'),\n",
       " (861, '77.11'),\n",
       " (862, '7732584351'),\n",
       " (863, '78'),\n",
       " (864, '786'),\n",
       " (865, '7876150'),\n",
       " (866, '79'),\n",
       " (867, '7:30'),\n",
       " (868, '7am'),\n",
       " (869, '7cfca1a'),\n",
       " (870, '7ish'),\n",
       " (871, '7oz'),\n",
       " (872, '7pm'),\n",
       " (873, '7th'),\n",
       " (874, '7ws'),\n",
       " (875, '7zs'),\n",
       " (876, '8'),\n",
       " (877, '8,22'),\n",
       " (878, '8-8'),\n",
       " (879, '8.30'),\n",
       " (880, '8.attractive'),\n",
       " (881, '8.lovable'),\n",
       " (882, '8.neighbour'),\n",
       " (883, '80'),\n",
       " (884, '800'),\n",
       " (885, '8000930705'),\n",
       " (886, '80062'),\n",
       " (887, '8007'),\n",
       " (888, '80082'),\n",
       " (889, '80086'),\n",
       " (890, '8012230'),\n",
       " (891, '80155'),\n",
       " (892, '80160'),\n",
       " (893, '80182'),\n",
       " (894, '8027'),\n",
       " (895, '80488'),\n",
       " (896, '80488.biz'),\n",
       " (897, '80608'),\n",
       " (898, '8077'),\n",
       " (899, '80878'),\n",
       " (900, '81010'),\n",
       " (901, '81151'),\n",
       " (902, '81303'),\n",
       " (903, '81618'),\n",
       " (904, '820554ad0a1705572711'),\n",
       " (905, '82228'),\n",
       " (906, '82242'),\n",
       " (907, '82277'),\n",
       " (908, '82277.unsub'),\n",
       " (909, '82324'),\n",
       " (910, '82468'),\n",
       " (911, '83021'),\n",
       " (912, '83039'),\n",
       " (913, '83049'),\n",
       " (914, '83110'),\n",
       " (915, '83118'),\n",
       " (916, '83222'),\n",
       " (917, '83332.please'),\n",
       " (918, '83338'),\n",
       " (919, '83355'),\n",
       " (920, '83370'),\n",
       " (921, '83383'),\n",
       " (922, '83435'),\n",
       " (923, '83600'),\n",
       " (924, '83738'),\n",
       " (925, '84'),\n",
       " (926, '84025'),\n",
       " (927, '84122'),\n",
       " (928, '84128'),\n",
       " (929, '84199'),\n",
       " (930, '84484'),\n",
       " (931, '85'),\n",
       " (932, '850'),\n",
       " (933, '85023'),\n",
       " (934, '85069'),\n",
       " (935, '85222'),\n",
       " (936, '85233'),\n",
       " (937, '8552'),\n",
       " (938, '85555'),\n",
       " (939, '86021'),\n",
       " (940, '861'),\n",
       " (941, '864233'),\n",
       " (942, '86688'),\n",
       " (943, '86888'),\n",
       " (944, '87021'),\n",
       " (945, '87066'),\n",
       " (946, '87070'),\n",
       " (947, '87077'),\n",
       " (948, '87121'),\n",
       " (949, '87131'),\n",
       " (950, '8714714'),\n",
       " (951, '87239'),\n",
       " (952, '87575'),\n",
       " (953, '8800'),\n",
       " (954, '88039'),\n",
       " (955, '88039.skilgme'),\n",
       " (956, '88066'),\n",
       " (957, '88088'),\n",
       " (958, '88222'),\n",
       " (959, '88600'),\n",
       " (960, '88800'),\n",
       " (961, '8883'),\n",
       " (962, '88877'),\n",
       " (963, '88888'),\n",
       " (964, '89'),\n",
       " (965, '89034'),\n",
       " (966, '89070'),\n",
       " (967, '89080'),\n",
       " (968, '89105'),\n",
       " (969, '89123'),\n",
       " (970, '89545'),\n",
       " (971, '89555'),\n",
       " (972, '89693'),\n",
       " (973, '89938'),\n",
       " (974, '8am'),\n",
       " (975, '8ball'),\n",
       " (976, '8i'),\n",
       " (977, '8lb'),\n",
       " (978, '8p'),\n",
       " (979, '8r'),\n",
       " (980, '8th'),\n",
       " (981, '8wp'),\n",
       " (982, '9'),\n",
       " (983, '9-6'),\n",
       " (984, '9.decent'),\n",
       " (985, '9.funny'),\n",
       " (986, '900'),\n",
       " (987, '9061100010'),\n",
       " (988, '910'),\n",
       " (989, '9280114'),\n",
       " (990, '92h'),\n",
       " (991, '930'),\n",
       " (992, '9307622'),\n",
       " (993, '945'),\n",
       " (994, '946'),\n",
       " (995, '95'),\n",
       " (996, '95qu'),\n",
       " (997, '97n7qp'),\n",
       " (998, '9832156'),\n",
       " (999, '9ae'),\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_nums, terms = zip(*sorted(zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('!',\n",
       " '\"',\n",
       " '#',\n",
       " '#150',\n",
       " '#5000',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '. .',\n",
       " '. . .',\n",
       " '. . . .',\n",
       " '. . . . .',\n",
       " '. ..',\n",
       " '..',\n",
       " '.. .',\n",
       " '.. . . .',\n",
       " '.. ... ...',\n",
       " '...',\n",
       " '... . . . .',\n",
       " '/',\n",
       " '0',\n",
       " '00',\n",
       " '00870405040',\n",
       " '0089',\n",
       " '01',\n",
       " '0121 2025050',\n",
       " '01223585236',\n",
       " '01223585334',\n",
       " '01256987',\n",
       " '02',\n",
       " '02/06',\n",
       " '02/09',\n",
       " '0207 153 9153',\n",
       " '0207 153 9996',\n",
       " '0207-083-6089',\n",
       " '02072069400',\n",
       " '02073162414',\n",
       " '02085076972',\n",
       " '03',\n",
       " '03530150',\n",
       " '04',\n",
       " '04/09',\n",
       " '05',\n",
       " '050703',\n",
       " '06',\n",
       " '06.05',\n",
       " '06/11',\n",
       " '07/11',\n",
       " '07008009200',\n",
       " '07046744435',\n",
       " '07090201529',\n",
       " '07090298926',\n",
       " '07099833605',\n",
       " '07123456789',\n",
       " '07732584351',\n",
       " '07734396839',\n",
       " '07742676969',\n",
       " '07753741225',\n",
       " '0776xxxxxxx',\n",
       " '07786200117',\n",
       " '077xxx',\n",
       " '078',\n",
       " '07801543489',\n",
       " '07808',\n",
       " '07808247860',\n",
       " '07808726822',\n",
       " '07815296484',\n",
       " '07821230901',\n",
       " '078498',\n",
       " '07880867867',\n",
       " '0789xxxxxxx',\n",
       " '07946746291',\n",
       " '0796xxxxxx',\n",
       " '07973788240',\n",
       " '07xxxxxxxxx',\n",
       " '08',\n",
       " '0800',\n",
       " '0800 0721072',\n",
       " '0800 169 6031',\n",
       " '0800 195 6669',\n",
       " '0800 1956669',\n",
       " '0800 5050',\n",
       " '0800 542 0578',\n",
       " '0800 542 0825',\n",
       " '08000407165',\n",
       " '08000776320',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '08000938767',\n",
       " '08001950382',\n",
       " '08002888812',\n",
       " '08002986030',\n",
       " '08002986906',\n",
       " '08002988890',\n",
       " '08006344447',\n",
       " '0808 145 4742',\n",
       " '08081263000',\n",
       " '08081560665',\n",
       " '0819',\n",
       " '0844',\n",
       " '08448350055',\n",
       " '08448714184',\n",
       " '0845 021 3680',\n",
       " '0845 2814032',\n",
       " '08450542832',\n",
       " '08452810071',\n",
       " '08452810073',\n",
       " '08452810075',\n",
       " '0870',\n",
       " '08700435505',\n",
       " '08700469649',\n",
       " '08700621170',\n",
       " '08701213186',\n",
       " '08701237397',\n",
       " '08701417012',\n",
       " '08701624',\n",
       " '08701752560',\n",
       " '08701872873',\n",
       " '08702411827',\n",
       " '08702490080',\n",
       " '08702840625',\n",
       " '08702840625.comuk',\n",
       " '08704050406',\n",
       " '08704439680',\n",
       " '08706091795',\n",
       " '08707379102',\n",
       " '08707500020',\n",
       " '08707509020',\n",
       " '08707533310',\n",
       " '08707808226',\n",
       " '08708034412',\n",
       " '08708800282',\n",
       " '08709222922',\n",
       " '08709501522',\n",
       " '0871-4719',\n",
       " '0871-872-9755',\n",
       " '0871-872-9758',\n",
       " '08710471114',\n",
       " '08712101358',\n",
       " '08712103738',\n",
       " '08712120250',\n",
       " '08712300220',\n",
       " '08712317606',\n",
       " '08712400200',\n",
       " '08712400602',\n",
       " '08712400603',\n",
       " '08712402050',\n",
       " '08712402578',\n",
       " '08712402779',\n",
       " '08712402902',\n",
       " '08712402972',\n",
       " '08712404000',\n",
       " '08712405020',\n",
       " '08712405022',\n",
       " '08712460324',\n",
       " '08712466669',\n",
       " '08712778107',\n",
       " '08712778108',\n",
       " '08712778109',\n",
       " '08714342399',\n",
       " '08714712377',\n",
       " '08714712379',\n",
       " '08714712388',\n",
       " '08714712394',\n",
       " '08714712412',\n",
       " '08714714011',\n",
       " '08714740323',\n",
       " '08714742804',\n",
       " '08715203028',\n",
       " '08715203649',\n",
       " '08715203652',\n",
       " '08715203656',\n",
       " '08715203677',\n",
       " '08715203685',\n",
       " '08715203694',\n",
       " '08715205273',\n",
       " '08715500022',\n",
       " '08715705022',\n",
       " '08717111821',\n",
       " '08717168528',\n",
       " '08717205546',\n",
       " '0871750',\n",
       " '08717507382',\n",
       " '08717509990',\n",
       " '08717890890',\n",
       " '08717895698',\n",
       " '08717898035',\n",
       " '08718711108',\n",
       " '08718720201',\n",
       " '08718723815',\n",
       " '08718725756',\n",
       " '08718726270',\n",
       " '08718726970',\n",
       " '08718726971',\n",
       " '08718726978',\n",
       " '08718727200',\n",
       " '08718727868',\n",
       " '08718727870',\n",
       " '08718728876',\n",
       " '08718730555',\n",
       " '08718730666',\n",
       " '08718738001',\n",
       " '08718738002',\n",
       " '08718738034',\n",
       " '08719180219',\n",
       " '08719180248',\n",
       " '08719181259',\n",
       " '08719181503',\n",
       " '08719181513',\n",
       " '08719839835',\n",
       " '08719899217',\n",
       " '08719899229',\n",
       " '08719899230',\n",
       " '09',\n",
       " '09041940223',\n",
       " '09050000301',\n",
       " '09050000327',\n",
       " '09050000332',\n",
       " '09050000460',\n",
       " '09050000555',\n",
       " '09050000878',\n",
       " '09050000928',\n",
       " '09050001295',\n",
       " '09050001808',\n",
       " '09050002311',\n",
       " '09050003091',\n",
       " '09050005321',\n",
       " '09050090044',\n",
       " '09050280520',\n",
       " '09053750005',\n",
       " '09056242159',\n",
       " '09057039994',\n",
       " '09058091854',\n",
       " '09058091870',\n",
       " '09058094454',\n",
       " '09058094455',\n",
       " '09058094507',\n",
       " '09058094565',\n",
       " '09058094583',\n",
       " '09058094594',\n",
       " '09058094597',\n",
       " '09058094599',\n",
       " '09058095107',\n",
       " '09058095201',\n",
       " '09058097189',\n",
       " '09058097218',\n",
       " '09058098002',\n",
       " '09058099801',\n",
       " '09061104276',\n",
       " '09061104283',\n",
       " '09061209465',\n",
       " '09061213237',\n",
       " '09061221061',\n",
       " '09061221066',\n",
       " '09061701444',\n",
       " '09061701461',\n",
       " '09061701851',\n",
       " '09061701939',\n",
       " '09061702893',\n",
       " '09061743386',\n",
       " '09061743806',\n",
       " '09061743810',\n",
       " '09061743811',\n",
       " '09061744553',\n",
       " '09061749602',\n",
       " '09061790121',\n",
       " '09061790125',\n",
       " '09061790126',\n",
       " '09063440451',\n",
       " '09063442151',\n",
       " '09063458130',\n",
       " '09063463',\n",
       " '09064011000',\n",
       " '09064012103',\n",
       " '09064012160',\n",
       " '09064015307',\n",
       " '09064017295',\n",
       " '09064017305',\n",
       " '09064018838',\n",
       " '09064019014',\n",
       " '09064019788',\n",
       " '09065069120',\n",
       " '09065069154',\n",
       " '09065171142',\n",
       " '09065174042',\n",
       " '09065394514',\n",
       " '09065394973',\n",
       " '09065989180',\n",
       " '09065989182',\n",
       " '09066350750',\n",
       " '09066358152',\n",
       " '09066358361',\n",
       " '09066361921',\n",
       " '09066362206',\n",
       " '09066362220',\n",
       " '09066362231',\n",
       " '09066364311',\n",
       " '09066364349',\n",
       " '09066364589',\n",
       " '09066368327',\n",
       " '09066368470',\n",
       " '09066368753',\n",
       " '09066380611',\n",
       " '09066382422',\n",
       " '09066612661',\n",
       " '09066649731',\n",
       " '09066660100',\n",
       " '09071512432',\n",
       " '09071512433',\n",
       " '09071517866',\n",
       " '09077818151',\n",
       " '09090204448',\n",
       " '09090900040',\n",
       " '09094100151',\n",
       " '09094646631',\n",
       " '09094646899',\n",
       " '09095350301',\n",
       " '09096102316',\n",
       " '09099725823',\n",
       " '09099726395',\n",
       " '09099726429',\n",
       " '09099726481',\n",
       " '09099726553',\n",
       " '09111030116',\n",
       " '09111032124',\n",
       " '09701213186',\n",
       " '0a',\n",
       " '0p',\n",
       " '0quit',\n",
       " '1',\n",
       " '1,000',\n",
       " '1,2',\n",
       " '1,50',\n",
       " '1,500',\n",
       " '1.20',\n",
       " '1.5',\n",
       " '1.50',\n",
       " '1.childish',\n",
       " '1/08',\n",
       " '1/1',\n",
       " '1/2',\n",
       " '1/3',\n",
       " '10',\n",
       " '10,000',\n",
       " '10.1',\n",
       " '10/06',\n",
       " '100',\n",
       " '100,000',\n",
       " '1000',\n",
       " '1000call',\n",
       " '1000s',\n",
       " '100p',\n",
       " '100txt',\n",
       " '1013',\n",
       " '1030',\n",
       " '10:10',\n",
       " '10:30',\n",
       " '10am',\n",
       " '10k',\n",
       " '10mins',\n",
       " '10p',\n",
       " '10ppm',\n",
       " '10th',\n",
       " '11',\n",
       " '11.48',\n",
       " '1120',\n",
       " '113',\n",
       " '1131',\n",
       " '114/14',\n",
       " '1146',\n",
       " '1151',\n",
       " '116',\n",
       " '1172',\n",
       " '118p',\n",
       " '11mths',\n",
       " '11pm',\n",
       " '12',\n",
       " '12,000',\n",
       " '1205',\n",
       " '120p',\n",
       " '121',\n",
       " '1225',\n",
       " '123',\n",
       " '125',\n",
       " '1250',\n",
       " '125gift',\n",
       " '128',\n",
       " '1282essexcm61xn',\n",
       " '12:30',\n",
       " '12hours',\n",
       " '12hrs',\n",
       " '12mths',\n",
       " '12n146tf15',\n",
       " '12n146tf150p',\n",
       " '13/10',\n",
       " '13/4',\n",
       " '130',\n",
       " '1327',\n",
       " '139',\n",
       " '140',\n",
       " '1405',\n",
       " '140ppm',\n",
       " '1450',\n",
       " '146tf150p',\n",
       " '14thmarch',\n",
       " '150',\n",
       " '1500',\n",
       " '150p',\n",
       " '150p16',\n",
       " '150pm',\n",
       " '150ppermesssubscription',\n",
       " '150ppm',\n",
       " '150ppmmobilesvary',\n",
       " '150ppmpobox10183bhamb64xe',\n",
       " '150ppmsg',\n",
       " '150ppmx3age16',\n",
       " '150pw',\n",
       " '150x3',\n",
       " '151',\n",
       " '1510',\n",
       " '15541',\n",
       " '15:26',\n",
       " '15h',\n",
       " '16',\n",
       " '16.150',\n",
       " '165',\n",
       " '1680',\n",
       " '16yrs',\n",
       " '177',\n",
       " '177hp51fl',\n",
       " '18',\n",
       " '18/11',\n",
       " '180',\n",
       " '1843',\n",
       " '1896wc1n3xx',\n",
       " '18:0430-',\n",
       " '18p',\n",
       " '18yrs',\n",
       " '1apple',\n",
       " '1b6a5ecef91ff9',\n",
       " '1cup',\n",
       " '1da',\n",
       " '1er',\n",
       " '1hr',\n",
       " '1im',\n",
       " '1lemon',\n",
       " '1million',\n",
       " '1more',\n",
       " '1n3xx',\n",
       " '1pm',\n",
       " '1st',\n",
       " '1st4terms',\n",
       " '1stchoice.co.uk',\n",
       " '1stone',\n",
       " '1thing',\n",
       " '1tulsi',\n",
       " '1win150ppmx3',\n",
       " '1win150ppmx3age16',\n",
       " '1win150ppmx3age16subscription',\n",
       " '1winaweek',\n",
       " '1winawk',\n",
       " '1x150p',\n",
       " '1yf',\n",
       " '2',\n",
       " '2,000',\n",
       " '2-4-',\n",
       " '2.15',\n",
       " '2.30',\n",
       " '2.50',\n",
       " '2.im',\n",
       " '2.naughty',\n",
       " '2/2',\n",
       " '2/3',\n",
       " '20',\n",
       " '20,000',\n",
       " '200',\n",
       " '2000',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '200p',\n",
       " '202',\n",
       " '20m12aq',\n",
       " '20p',\n",
       " '21',\n",
       " '21/11',\n",
       " '2187000',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '220cm2',\n",
       " '23',\n",
       " '2309',\n",
       " '23f',\n",
       " '23g',\n",
       " '24',\n",
       " '24/10',\n",
       " '24/7',\n",
       " '245c2150pm',\n",
       " '24hrs',\n",
       " '24m',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '250k',\n",
       " '255',\n",
       " '25p',\n",
       " '26.03',\n",
       " '26/10',\n",
       " '26/11',\n",
       " '2667',\n",
       " '26th',\n",
       " '27/03',\n",
       " '27/6',\n",
       " '28',\n",
       " '28/5',\n",
       " '28days',\n",
       " '28th',\n",
       " '28thfeb',\n",
       " '29',\n",
       " '29/03',\n",
       " '29/10',\n",
       " '2b',\n",
       " '2bed',\n",
       " '2bold',\n",
       " '2bremoved',\n",
       " '2c',\n",
       " '2channel',\n",
       " '2come',\n",
       " '2day',\n",
       " '2day.love',\n",
       " '2die',\n",
       " '2docd.please',\n",
       " '2end',\n",
       " '2exit',\n",
       " '2ez',\n",
       " '2find',\n",
       " '2getha',\n",
       " '2geva',\n",
       " '2go',\n",
       " '2go.did',\n",
       " '2gthr',\n",
       " '2hear',\n",
       " '2hook',\n",
       " '2hrs',\n",
       " '2i',\n",
       " '2kbsubject',\n",
       " '2marrow',\n",
       " '2mobile',\n",
       " '2moro',\n",
       " '2morow',\n",
       " '2morro',\n",
       " '2morrow',\n",
       " '2morrowxxxx',\n",
       " '2mro',\n",
       " '2mrw',\n",
       " '2mwen',\n",
       " '2nd',\n",
       " '2nhite',\n",
       " '2nights',\n",
       " '2nite',\n",
       " '2optout',\n",
       " '2p',\n",
       " '2px',\n",
       " '2rcv',\n",
       " '2stop',\n",
       " '2stoptx',\n",
       " '2stoptxt',\n",
       " '2tell',\n",
       " '2the',\n",
       " '2u',\n",
       " '2u2',\n",
       " '2watershd',\n",
       " '2waxsto',\n",
       " '2wks',\n",
       " '2worzels',\n",
       " '2wt',\n",
       " '2wu',\n",
       " '2years',\n",
       " '2yr',\n",
       " '2yrs',\n",
       " '3',\n",
       " '3.00',\n",
       " '3.75',\n",
       " '3.99',\n",
       " '3.sentiment',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300603',\n",
       " '300603t',\n",
       " '300p',\n",
       " '3030',\n",
       " '30apr',\n",
       " '30pp',\n",
       " '30s',\n",
       " '30th',\n",
       " '31',\n",
       " '31/10',\n",
       " '3100',\n",
       " '310303',\n",
       " '31p',\n",
       " '32',\n",
       " '32000',\n",
       " '3230',\n",
       " '32323',\n",
       " '326',\n",
       " '33.65',\n",
       " '330',\n",
       " '334',\n",
       " '334sk38ch',\n",
       " '3355',\n",
       " '33:50',\n",
       " '342/2',\n",
       " '350',\n",
       " '3510i',\n",
       " '35p',\n",
       " '3650',\n",
       " '36504',\n",
       " '36504w45wq',\n",
       " '365o4w45wq',\n",
       " '373',\n",
       " '3750',\n",
       " '37819',\n",
       " '38',\n",
       " '385',\n",
       " '391784',\n",
       " '39822',\n",
       " '3aj',\n",
       " '3cktz8r7',\n",
       " '3d',\n",
       " '3days',\n",
       " '3g',\n",
       " '3gbp',\n",
       " '3hrs',\n",
       " '3lions',\n",
       " '3lp',\n",
       " '3miles',\n",
       " '3mins',\n",
       " '3mobile',\n",
       " '3optical',\n",
       " '3pound',\n",
       " '3qxj9',\n",
       " '3rd',\n",
       " '3ss',\n",
       " '3uz',\n",
       " '3wks',\n",
       " '3x',\n",
       " '3xx',\n",
       " '4',\n",
       " '4-6',\n",
       " '4-7',\n",
       " '4.15',\n",
       " '4.30',\n",
       " '4.47',\n",
       " '4.49',\n",
       " '4.50',\n",
       " '4.cook',\n",
       " '4.rowdy',\n",
       " '40',\n",
       " '400',\n",
       " '400mins',\n",
       " '402',\n",
       " '403',\n",
       " '4041',\n",
       " '40411',\n",
       " '40533',\n",
       " '40gb',\n",
       " '40mph',\n",
       " '41',\n",
       " '41685',\n",
       " '41782',\n",
       " '420',\n",
       " '42049',\n",
       " '4217',\n",
       " '4235wc1n3xx',\n",
       " '42478',\n",
       " '42810',\n",
       " '4284',\n",
       " '42moro',\n",
       " '42wr29c',\n",
       " '430',\n",
       " '434',\n",
       " '434sk38wp150ppm18',\n",
       " '44',\n",
       " '440',\n",
       " '4403ldnw1a7rw18',\n",
       " '4477977060',\n",
       " '4478012592',\n",
       " '4487124040',\n",
       " '4490500003',\n",
       " '4490715124',\n",
       " '45',\n",
       " '450',\n",
       " '450p',\n",
       " '450ppw',\n",
       " '450pw',\n",
       " '45239',\n",
       " '45po139wa',\n",
       " '45w2tg150p',\n",
       " '47',\n",
       " '48',\n",
       " '4882',\n",
       " '48922',\n",
       " '49557',\n",
       " '4a',\n",
       " '4an18th',\n",
       " '4brekkie',\n",
       " '4d',\n",
       " '4eva',\n",
       " '4few',\n",
       " '4fil',\n",
       " '4get',\n",
       " '4get2text',\n",
       " '4give',\n",
       " '4got',\n",
       " '4goten',\n",
       " '4info',\n",
       " '4jx',\n",
       " '4msgs',\n",
       " '4mths',\n",
       " '4my',\n",
       " '4qf2',\n",
       " '4t',\n",
       " '4th',\n",
       " '4the',\n",
       " '4thnov.behind',\n",
       " '4txt',\n",
       " '4u',\n",
       " '4utxt',\n",
       " '4w',\n",
       " '4ward',\n",
       " '4wrd',\n",
       " '4xx26',\n",
       " '4years',\n",
       " '5',\n",
       " '5.00',\n",
       " '5.15',\n",
       " '5.30',\n",
       " '5.ful',\n",
       " '5.gardener',\n",
       " '5.terror',\n",
       " '5/9',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '5000.00',\n",
       " '50award',\n",
       " '50p',\n",
       " '50s',\n",
       " '5120',\n",
       " '515',\n",
       " '5226',\n",
       " '523',\n",
       " '5249',\n",
       " '526',\n",
       " '528',\n",
       " '530',\n",
       " '54',\n",
       " '545',\n",
       " '5digital',\n",
       " '5free',\n",
       " '5ish',\n",
       " '5k',\n",
       " '5min',\n",
       " '5mls',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5th',\n",
       " '5times',\n",
       " '5wb',\n",
       " '5we',\n",
       " '5wkg',\n",
       " '5wq',\n",
       " '5years',\n",
       " '6',\n",
       " '6.30',\n",
       " '6.45',\n",
       " '6.cruel',\n",
       " '6.house',\n",
       " '6.romantic',\n",
       " '60',\n",
       " '60,400',\n",
       " '600',\n",
       " '60p',\n",
       " '61',\n",
       " '61200',\n",
       " '61610',\n",
       " '62220cncl',\n",
       " '6230',\n",
       " '62468',\n",
       " '62735',\n",
       " '630',\n",
       " '63miles',\n",
       " '645',\n",
       " '65,61',\n",
       " '650',\n",
       " '66,382',\n",
       " '6600',\n",
       " '6650',\n",
       " '674',\n",
       " '6744123',\n",
       " '68866',\n",
       " '69',\n",
       " '69101',\n",
       " '69200',\n",
       " '69669',\n",
       " '69696',\n",
       " '69698',\n",
       " '69855',\n",
       " '69866.18',\n",
       " '69876',\n",
       " '69888',\n",
       " '69888nyt',\n",
       " '69911',\n",
       " '69969',\n",
       " '69988',\n",
       " '6days',\n",
       " '6gbp',\n",
       " '6hl',\n",
       " '6hrs',\n",
       " '6ish',\n",
       " '6missed',\n",
       " '6months',\n",
       " '6ph',\n",
       " '6pm',\n",
       " '6th',\n",
       " '6times',\n",
       " '6wu',\n",
       " '6zf',\n",
       " '7',\n",
       " '7.30',\n",
       " '7.8',\n",
       " '7.children',\n",
       " '7.romantic',\n",
       " '7.shy',\n",
       " '700',\n",
       " '71',\n",
       " '7250',\n",
       " '7250i',\n",
       " '730',\n",
       " '731',\n",
       " '734ls27yf',\n",
       " '74355',\n",
       " '75,000',\n",
       " '750',\n",
       " '7548',\n",
       " '75ldns7',\n",
       " '762',\n",
       " '7634',\n",
       " '7684',\n",
       " '77.11',\n",
       " '7732584351',\n",
       " '78',\n",
       " '786',\n",
       " '7876150',\n",
       " '79',\n",
       " '7:30',\n",
       " '7am',\n",
       " '7cfca1a',\n",
       " '7ish',\n",
       " '7oz',\n",
       " '7pm',\n",
       " '7th',\n",
       " '7ws',\n",
       " '7zs',\n",
       " '8',\n",
       " '8,22',\n",
       " '8-8',\n",
       " '8.30',\n",
       " '8.attractive',\n",
       " '8.lovable',\n",
       " '8.neighbour',\n",
       " '80',\n",
       " '800',\n",
       " '8000930705',\n",
       " '80062',\n",
       " '8007',\n",
       " '80082',\n",
       " '80086',\n",
       " '8012230',\n",
       " '80155',\n",
       " '80160',\n",
       " '80182',\n",
       " '8027',\n",
       " '80488',\n",
       " '80488.biz',\n",
       " '80608',\n",
       " '8077',\n",
       " '80878',\n",
       " '81010',\n",
       " '81151',\n",
       " '81303',\n",
       " '81618',\n",
       " '820554ad0a1705572711',\n",
       " '82228',\n",
       " '82242',\n",
       " '82277',\n",
       " '82277.unsub',\n",
       " '82324',\n",
       " '82468',\n",
       " '83021',\n",
       " '83039',\n",
       " '83049',\n",
       " '83110',\n",
       " '83118',\n",
       " '83222',\n",
       " '83332.please',\n",
       " '83338',\n",
       " '83355',\n",
       " '83370',\n",
       " '83383',\n",
       " '83435',\n",
       " '83600',\n",
       " '83738',\n",
       " '84',\n",
       " '84025',\n",
       " '84122',\n",
       " '84128',\n",
       " '84199',\n",
       " '84484',\n",
       " '85',\n",
       " '850',\n",
       " '85023',\n",
       " '85069',\n",
       " '85222',\n",
       " '85233',\n",
       " '8552',\n",
       " '85555',\n",
       " '86021',\n",
       " '861',\n",
       " '864233',\n",
       " '86688',\n",
       " '86888',\n",
       " '87021',\n",
       " '87066',\n",
       " '87070',\n",
       " '87077',\n",
       " '87121',\n",
       " '87131',\n",
       " '8714714',\n",
       " '87239',\n",
       " '87575',\n",
       " '8800',\n",
       " '88039',\n",
       " '88039.skilgme',\n",
       " '88066',\n",
       " '88088',\n",
       " '88222',\n",
       " '88600',\n",
       " '88800',\n",
       " '8883',\n",
       " '88877',\n",
       " '88888',\n",
       " '89',\n",
       " '89034',\n",
       " '89070',\n",
       " '89080',\n",
       " '89105',\n",
       " '89123',\n",
       " '89545',\n",
       " '89555',\n",
       " '89693',\n",
       " '89938',\n",
       " '8am',\n",
       " '8ball',\n",
       " '8i',\n",
       " '8lb',\n",
       " '8p',\n",
       " '8r',\n",
       " '8th',\n",
       " '8wp',\n",
       " '9',\n",
       " '9-6',\n",
       " '9.decent',\n",
       " '9.funny',\n",
       " '900',\n",
       " '9061100010',\n",
       " '910',\n",
       " '9280114',\n",
       " '92h',\n",
       " '930',\n",
       " '9307622',\n",
       " '945',\n",
       " '946',\n",
       " '95',\n",
       " '95qu',\n",
       " '97n7qp',\n",
       " '9832156',\n",
       " '9ae',\n",
       " ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>#150</th>\n",
       "      <th>...</th>\n",
       "      <th>…</th>\n",
       "      <th>┾</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic0</th>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>0.064</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic2</th>\n",
       "      <td>0.071</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic3</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 9232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            !      \"      #   #150  ...      …      ┾    〨ud      鈥\n",
       "topic0 -0.071  0.008 -0.001 -0.000  ... -0.002  0.001  0.001  0.001\n",
       "topic1  0.064  0.008  0.000 -0.000  ...  0.003  0.001  0.001  0.001\n",
       "topic2  0.071  0.027  0.000  0.001  ...  0.002 -0.001 -0.001 -0.001\n",
       "topic3 -0.059 -0.032 -0.001 -0.000  ...  0.001  0.001  0.001  0.001\n",
       "\n",
       "[4 rows x 9232 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = pd.DataFrame(pca.components_, columns=terms, index=['topic{}'.format(i) for i in range(16)])\n",
    "pd.options.display.max_columns = 8\n",
    "weights.head(4).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>;)</th>\n",
       "      <th>:)</th>\n",
       "      <th>half</th>\n",
       "      <th>off</th>\n",
       "      <th>free</th>\n",
       "      <th>crazy</th>\n",
       "      <th>deal</th>\n",
       "      <th>only</th>\n",
       "      <th>$</th>\n",
       "      <th>80</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic0</th>\n",
       "      <td>-7.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic2</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic3</th>\n",
       "      <td>-5.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic4</th>\n",
       "      <td>38.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-12.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic5</th>\n",
       "      <td>-26.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic6</th>\n",
       "      <td>-10.9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic7</th>\n",
       "      <td>16.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic8</th>\n",
       "      <td>34.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic9</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic10</th>\n",
       "      <td>-31.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic11</th>\n",
       "      <td>23.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>29.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic12</th>\n",
       "      <td>-18.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>46.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic13</th>\n",
       "      <td>16.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>19.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic14</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            !   ;)    :)  half  off  free  crazy  deal  only    $   80    %\n",
       "topic0   -7.1  0.1  -0.5  -0.0 -0.4  -2.0   -0.0  -0.1  -2.2  0.3 -0.0 -0.0\n",
       "topic1    6.4  0.0   7.4   0.1  0.4  -2.3   -0.2  -0.1  -3.8 -0.1 -0.0 -0.2\n",
       "topic2    7.1  0.2  -0.1   0.0  0.3   4.4    0.1  -0.1   0.7  0.0  0.0  0.1\n",
       "topic3   -5.9 -0.3  -7.1   0.2  0.3  -0.2    0.0   0.1  -2.3  0.1 -0.1 -0.3\n",
       "topic4   38.1 -0.1 -12.4  -0.1 -0.2   9.9    0.1  -0.2   3.0  0.3  0.1 -0.1\n",
       "topic5  -26.5  0.1  -1.5  -0.3 -0.7  -1.4   -0.6  -0.2  -1.8 -0.9  0.0 -0.0\n",
       "topic6  -10.9 -0.5  19.9  -0.4 -0.9  -0.6   -0.2  -0.1  -1.4 -0.0 -0.0 -0.1\n",
       "topic7   16.3  0.1 -18.0   0.7  0.8  -2.9    0.0   0.0  -1.8 -0.3  0.0 -0.1\n",
       "topic8   34.1  0.2   4.9  -0.4 -0.5  -0.0   -0.4  -0.4   3.1 -0.6 -0.0 -0.2\n",
       "topic9    7.7 -0.3  16.4   1.5 -0.9   6.2   -0.5  -0.4   3.1 -0.5 -0.0 -0.0\n",
       "topic10 -31.9 -0.2  -9.4   0.1  0.1  12.6    0.1   0.0   0.3 -0.0 -0.0 -0.2\n",
       "topic11  23.2  0.4  29.1   0.4  1.4  -3.8    0.1   0.1   0.1 -0.4 -0.0 -0.4\n",
       "topic12 -18.5 -0.3  46.3  -0.3  0.4  -1.3   -0.3   0.1   2.8  0.2 -0.0  0.2\n",
       "topic13  16.5 -0.1  19.2  -0.2  0.3   5.7    0.4   0.2  -3.2 -0.4  0.0 -0.2\n",
       "topic14  -1.0 -0.1  14.5  -0.1 -0.7   5.4    0.2  -0.1   3.9 -0.0  0.0 -0.3\n",
       "topic15   2.0 -0.6  -1.0  -0.5 -1.2  -4.0   -0.8   0.5   3.0 -0.7  0.1 -0.3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 12\n",
    "deals = weights['! ;) :) half off free crazy deal only $ 80 %'.split()].round(3) * 100\n",
    "deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic0    -11.9\n",
       "topic1      7.6\n",
       "topic2     12.7\n",
       "topic3    -15.5\n",
       "topic4     38.4\n",
       "topic5    -33.8\n",
       "topic6      4.8\n",
       "topic7     -5.2\n",
       "topic8     39.8\n",
       "topic9     32.3\n",
       "topic10   -28.5\n",
       "topic11    50.2\n",
       "topic12    29.3\n",
       "topic13    38.2\n",
       "topic14    21.7\n",
       "topic15    -3.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deals.T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>...</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic0  topic1  topic2  topic3  topic4  topic5  ...  topic10  topic11  topic12  topic13  topic14  topic15\n",
       "sms0    0.201   0.003   0.037   0.011  -0.019  -0.053  ...    0.007   -0.007    0.002   -0.036   -0.014    0.037\n",
       "sms1    0.404  -0.094  -0.078   0.051   0.100   0.047  ...   -0.004    0.036    0.043   -0.021    0.051   -0.042\n",
       "sms2!  -0.030  -0.048   0.090  -0.067   0.091  -0.043  ...    0.125    0.023    0.026   -0.020   -0.042    0.052\n",
       "sms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  ...    0.022    0.023    0.073   -0.046    0.022   -0.070\n",
       "sms4    0.002   0.031   0.038   0.034  -0.075  -0.093  ...    0.028   -0.009    0.027    0.034   -0.083   -0.021\n",
       "sms5!  -0.016   0.059   0.014  -0.006   0.122  -0.040  ...    0.041    0.055   -0.037    0.075   -0.001    0.020\n",
       "\n",
       "[6 rows x 16 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=16, n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf_docs.values)\n",
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns, index=index)\n",
    "svd_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms0</th>\n",
       "      <th>sms1</th>\n",
       "      <th>sms2!</th>\n",
       "      <th>sms3</th>\n",
       "      <th>sms4</th>\n",
       "      <th>sms5!</th>\n",
       "      <th>sms6</th>\n",
       "      <th>sms7</th>\n",
       "      <th>sms8!</th>\n",
       "      <th>sms9!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sms0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms2!</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms4</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms5!</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms6</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms7</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms8!</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sms9!</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sms0  sms1  sms2!  sms3  sms4  sms5!  sms6  sms7  sms8!  sms9!\n",
       "sms0    1.0   0.6   -0.1   0.6  -0.0   -0.3  -0.3  -0.1   -0.3   -0.3\n",
       "sms1    0.6   1.0   -0.2   0.8  -0.2    0.0  -0.2  -0.2   -0.1   -0.1\n",
       "sms2!  -0.1  -0.2    1.0  -0.2   0.1    0.4   0.0   0.3    0.5    0.4\n",
       "sms3    0.6   0.8   -0.2   1.0  -0.2   -0.3  -0.1  -0.3   -0.2   -0.1\n",
       "sms4   -0.0  -0.2    0.1  -0.2   1.0    0.2   0.0   0.1   -0.4   -0.2\n",
       "sms5!  -0.3   0.0    0.4  -0.3   0.2    1.0  -0.1   0.1    0.3    0.4\n",
       "sms6   -0.3  -0.2    0.0  -0.1   0.0   -0.1   1.0   0.1   -0.2   -0.2\n",
       "sms7   -0.1  -0.2    0.3  -0.3   0.1    0.1   0.1   1.0    0.1    0.4\n",
       "sms8!  -0.3  -0.1    0.5  -0.2  -0.4    0.3  -0.2   0.1    1.0    0.3\n",
       "sms9!  -0.3  -0.1    0.4  -0.1  -0.2    0.4  -0.2   0.4    0.3    1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_topic_vectors = (svd_topic_vectors.T / np.linalg.norm(svd_topic_vectors, axis=1)).T\n",
    "svd_topic_vectors.iloc[:10].dot(svd_topic_vectors.iloc[:10].T).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpriors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstore_covariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                 \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                 \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Linear Discriminant Analysis\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    A classifier with a linear decision boundary, generated by fitting class\u001b[0m\n",
       "\u001b[0;34m    conditional densities to the data and using Bayes' rule.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The model fits a Gaussian density to each class, assuming that all classes\u001b[0m\n",
       "\u001b[0;34m    share the same covariance matrix.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    The fitted model can also be used to reduce the dimensionality of the input\u001b[0m\n",
       "\u001b[0;34m    by projecting it to the most discriminative directions, using the\u001b[0m\n",
       "\u001b[0;34m    `transform` method.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. versionadded:: 0.17\u001b[0m\n",
       "\u001b[0;34m       *LinearDiscriminantAnalysis*.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <lda_qda>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    solver : {'svd', 'lsqr', 'eigen'}, default='svd'\u001b[0m\n",
       "\u001b[0;34m        Solver to use, possible values:\u001b[0m\n",
       "\u001b[0;34m          - 'svd': Singular value decomposition (default).\u001b[0m\n",
       "\u001b[0;34m            Does not compute the covariance matrix, therefore this solver is\u001b[0m\n",
       "\u001b[0;34m            recommended for data with a large number of features.\u001b[0m\n",
       "\u001b[0;34m          - 'lsqr': Least squares solution.\u001b[0m\n",
       "\u001b[0;34m            Can be combined with shrinkage or custom covariance estimator.\u001b[0m\n",
       "\u001b[0;34m          - 'eigen': Eigenvalue decomposition.\u001b[0m\n",
       "\u001b[0;34m            Can be combined with shrinkage or custom covariance estimator.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    shrinkage : 'auto' or float, default=None\u001b[0m\n",
       "\u001b[0;34m        Shrinkage parameter, possible values:\u001b[0m\n",
       "\u001b[0;34m          - None: no shrinkage (default).\u001b[0m\n",
       "\u001b[0;34m          - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.\u001b[0m\n",
       "\u001b[0;34m          - float between 0 and 1: fixed shrinkage parameter.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        This should be left to None if `covariance_estimator` is used.\u001b[0m\n",
       "\u001b[0;34m        Note that shrinkage works only with 'lsqr' and 'eigen' solvers.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    priors : array-like of shape (n_classes,), default=None\u001b[0m\n",
       "\u001b[0;34m        The class prior probabilities. By default, the class proportions are\u001b[0m\n",
       "\u001b[0;34m        inferred from the training data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_components : int, default=None\u001b[0m\n",
       "\u001b[0;34m        Number of components (<= min(n_classes - 1, n_features)) for\u001b[0m\n",
       "\u001b[0;34m        dimensionality reduction. If None, will be set to\u001b[0m\n",
       "\u001b[0;34m        min(n_classes - 1, n_features). This parameter only affects the\u001b[0m\n",
       "\u001b[0;34m        `transform` method.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    store_covariance : bool, default=False\u001b[0m\n",
       "\u001b[0;34m        If True, explicitely compute the weighted within-class covariance\u001b[0m\n",
       "\u001b[0;34m        matrix when solver is 'svd'. The matrix is always computed\u001b[0m\n",
       "\u001b[0;34m        and stored for the other solvers.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.17\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    tol : float, default=1.0e-4\u001b[0m\n",
       "\u001b[0;34m        Absolute threshold for a singular value of X to be considered\u001b[0m\n",
       "\u001b[0;34m        significant, used to estimate the rank of X. Dimensions whose\u001b[0m\n",
       "\u001b[0;34m        singular values are non-significant are discarded. Only used if\u001b[0m\n",
       "\u001b[0;34m        solver is 'svd'.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.17\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    covariance_estimator : covariance estimator, default=None\u001b[0m\n",
       "\u001b[0;34m        If not None, `covariance_estimator` is used to estimate\u001b[0m\n",
       "\u001b[0;34m        the covariance matrices instead of relying on the empirical\u001b[0m\n",
       "\u001b[0;34m        covariance estimator (with potential shrinkage).\u001b[0m\n",
       "\u001b[0;34m        The object should have a fit method and a ``covariance_`` attribute\u001b[0m\n",
       "\u001b[0;34m        like the estimators in :mod:`sklearn.covariance`.\u001b[0m\n",
       "\u001b[0;34m        if None the shrinkage parameter drives the estimate.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        This should be left to None if `shrinkage` is used.\u001b[0m\n",
       "\u001b[0;34m        Note that `covariance_estimator` works only with 'lsqr' and 'eigen'\u001b[0m\n",
       "\u001b[0;34m        solvers.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.24\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Attributes\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    coef_ : ndarray of shape (n_features,) or (n_classes, n_features)\u001b[0m\n",
       "\u001b[0;34m        Weight vector(s).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    intercept_ : ndarray of shape (n_classes,)\u001b[0m\n",
       "\u001b[0;34m        Intercept term.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    covariance_ : array-like of shape (n_features, n_features)\u001b[0m\n",
       "\u001b[0;34m        Weighted within-class covariance matrix. It corresponds to\u001b[0m\n",
       "\u001b[0;34m        `sum_k prior_k * C_k` where `C_k` is the covariance matrix of the\u001b[0m\n",
       "\u001b[0;34m        samples in class `k`. The `C_k` are estimated using the (potentially\u001b[0m\n",
       "\u001b[0;34m        shrunk) biased estimator of covariance. If solver is 'svd', only\u001b[0m\n",
       "\u001b[0;34m        exists when `store_covariance` is True.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    explained_variance_ratio_ : ndarray of shape (n_components,)\u001b[0m\n",
       "\u001b[0;34m        Percentage of variance explained by each of the selected components.\u001b[0m\n",
       "\u001b[0;34m        If ``n_components`` is not set then all components are stored and the\u001b[0m\n",
       "\u001b[0;34m        sum of explained variances is equal to 1.0. Only available when eigen\u001b[0m\n",
       "\u001b[0;34m        or svd solver is used.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    means_ : array-like of shape (n_classes, n_features)\u001b[0m\n",
       "\u001b[0;34m        Class-wise means.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    priors_ : array-like of shape (n_classes,)\u001b[0m\n",
       "\u001b[0;34m        Class priors (sum to 1).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    scalings_ : array-like of shape (rank, n_classes - 1)\u001b[0m\n",
       "\u001b[0;34m        Scaling of the features in the space spanned by the class centroids.\u001b[0m\n",
       "\u001b[0;34m        Only available for 'svd' and 'eigen' solvers.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    xbar_ : array-like of shape (n_features,)\u001b[0m\n",
       "\u001b[0;34m        Overall mean. Only present if solver is 'svd'.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    classes_ : array-like of shape (n_classes,)\u001b[0m\n",
       "\u001b[0;34m        Unique class labels.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See Also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    QuadraticDiscriminantAnalysis : Quadratic Discriminant Analysis.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\u001b[0m\n",
       "\u001b[0;34m    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\u001b[0m\n",
       "\u001b[0;34m    >>> y = np.array([1, 1, 1, 2, 2, 2])\u001b[0m\n",
       "\u001b[0;34m    >>> clf = LinearDiscriminantAnalysis()\u001b[0m\n",
       "\u001b[0;34m    >>> clf.fit(X, y)\u001b[0m\n",
       "\u001b[0;34m    LinearDiscriminantAnalysis()\u001b[0m\n",
       "\u001b[0;34m    >>> print(clf.predict([[-0.8, -1]]))\u001b[0m\n",
       "\u001b[0;34m    [1]\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_covariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_covariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore_covariance\u001b[0m  \u001b[0;31m# used only in svd solver\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtol\u001b[0m  \u001b[0;31m# used only in svd solver\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_solve_lsqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Least squares solver.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The least squares solver computes a straightforward solution of the\u001b[0m\n",
       "\u001b[0;34m        optimal decision rule based directly on the discriminant functions. It\u001b[0m\n",
       "\u001b[0;34m        can only be used for classification (with any covariance estimator),\u001b[0m\n",
       "\u001b[0;34m        because\u001b[0m\n",
       "\u001b[0;34m        estimation of eigenvectors is not performed. Therefore, dimensionality\u001b[0m\n",
       "\u001b[0;34m        reduction with the transform is not supported.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Training data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        y : array-like of shape (n_samples,) or (n_samples, n_classes)\u001b[0m\n",
       "\u001b[0;34m            Target values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        shrinkage : 'auto', float or None\u001b[0m\n",
       "\u001b[0;34m            Shrinkage parameter, possible values:\u001b[0m\n",
       "\u001b[0;34m              - None: no shrinkage.\u001b[0m\n",
       "\u001b[0;34m              - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.\u001b[0m\n",
       "\u001b[0;34m              - float between 0 and 1: fixed shrinkage parameter.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            Shrinkage parameter is ignored if  `covariance_estimator` i\u001b[0m\n",
       "\u001b[0;34m            not None\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        covariance_estimator : estimator, default=None\u001b[0m\n",
       "\u001b[0;34m            If not None, `covariance_estimator` is used to estimate\u001b[0m\n",
       "\u001b[0;34m            the covariance matrices instead of relying the empirical\u001b[0m\n",
       "\u001b[0;34m            covariance estimator (with potential shrinkage).\u001b[0m\n",
       "\u001b[0;34m            The object should have a fit method and a ``covariance_`` attribute\u001b[0m\n",
       "\u001b[0;34m            like the estimators in sklearn.covariance.\u001b[0m\n",
       "\u001b[0;34m            if None the shrinkage parameter drives the estimate.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            .. versionadded:: 0.24\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Notes\u001b[0m\n",
       "\u001b[0;34m        -----\u001b[0m\n",
       "\u001b[0;34m        This solver is based on [1]_, section 2.6.2, pp. 39-41.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        References\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        .. [1] R. O. Duda, P. E. Hart, D. G. Stork. Pattern Classification\u001b[0m\n",
       "\u001b[0;34m           (Second Edition). John Wiley & Sons, Inc., New York, 2001. ISBN\u001b[0m\n",
       "\u001b[0;34m           0-471-05669-3.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_solve_eigen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Eigenvalue solver.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The eigenvalue solver computes the optimal solution of the Rayleigh\u001b[0m\n",
       "\u001b[0;34m        coefficient (basically the ratio of between class scatter to within\u001b[0m\n",
       "\u001b[0;34m        class scatter). This solver supports both classification and\u001b[0m\n",
       "\u001b[0;34m        dimensionality reduction (with any covariance estimator).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Training data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        y : array-like of shape (n_samples,) or (n_samples, n_targets)\u001b[0m\n",
       "\u001b[0;34m            Target values.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        shrinkage : 'auto', float or None\u001b[0m\n",
       "\u001b[0;34m            Shrinkage parameter, possible values:\u001b[0m\n",
       "\u001b[0;34m              - None: no shrinkage.\u001b[0m\n",
       "\u001b[0;34m              - 'auto': automatic shrinkage using the Ledoit-Wolf lemma.\u001b[0m\n",
       "\u001b[0;34m              - float between 0 and 1: fixed shrinkage constant.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            Shrinkage parameter is ignored if  `covariance_estimator` i\u001b[0m\n",
       "\u001b[0;34m            not None\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        covariance_estimator : estimator, default=None\u001b[0m\n",
       "\u001b[0;34m            If not None, `covariance_estimator` is used to estimate\u001b[0m\n",
       "\u001b[0;34m            the covariance matrices instead of relying the empirical\u001b[0m\n",
       "\u001b[0;34m            covariance estimator (with potential shrinkage).\u001b[0m\n",
       "\u001b[0;34m            The object should have a fit method and a ``covariance_`` attribute\u001b[0m\n",
       "\u001b[0;34m            like the estimators in sklearn.covariance.\u001b[0m\n",
       "\u001b[0;34m            if None the shrinkage parameter drives the estimate.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            .. versionadded:: 0.24\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Notes\u001b[0m\n",
       "\u001b[0;34m        -----\u001b[0m\n",
       "\u001b[0;34m        This solver is based on [1]_, section 3.8.3, pp. 121-124.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        References\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        .. [1] R. O. Duda, P. E. Hart, D. G. Stork. Pattern Classification\u001b[0m\n",
       "\u001b[0;34m           (Second Edition). John Wiley & Sons, Inc., New York, 2001. ISBN\u001b[0m\n",
       "\u001b[0;34m           0-471-05669-3.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mSw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m  \u001b[0;31m# within scatter\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mSt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# total scatter\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mSb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mSw\u001b[0m  \u001b[0;31m# between scatter\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                                 \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mevecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# sort eigenvectors\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevecs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_solve_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"SVD solver.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Training data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        y : array-like of shape (n_samples,) or (n_samples, n_targets)\u001b[0m\n",
       "\u001b[0;34m            Target values.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_covariance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mXc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mXg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mXc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mXc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 1) within (univariate) scaling by with classes std-dev\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# avoid division by zero in normalization\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 2) Within variance scaling\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# SVD of centered (within)scaled data\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Scaling of within covariance is: V' 1/S\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mscalings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# 3) Between variance scaling\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Scale weighted centers\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Centers are living in a space with n_classes-1 dim (maximum)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Use SVD to find projection in the space spanned by the\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# (n_classes) centers\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mS\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Fit LinearDiscriminantAnalysis model according to the given\u001b[0m\n",
       "\u001b[0;34m           training data and parameters.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m           .. versionchanged:: 0.19\u001b[0m\n",
       "\u001b[0;34m              *store_covariance* has been moved to main constructor.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m           .. versionchanged:: 0.19\u001b[0m\n",
       "\u001b[0;34m              *tol* has been moved to main constructor.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Training data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        y : array-like of shape (n_samples,)\u001b[0m\n",
       "\u001b[0;34m            Target values.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                   \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The number of samples must be more \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\"than the number of classes.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# estimate priors from sample\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# non-negative ints\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"priors must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The priors do not sum to 1. Renormalizing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                          \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Maximum number of components no matter what n_components is\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# specified:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_components\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_components\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"n_components cannot be larger than min(n_features, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"n_classes - 1).\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shrinkage not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;34m'covariance estimator '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;34m'is not supported '\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;34m'with svd solver. Try another solver'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lsqr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_lsqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eigen'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_eigen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                              \u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown solver {} (valid solvers are 'svd', \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                             \u001b[0;34m\"'lsqr', and 'eigen').\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# treat binary case as a special case\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                  \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                       \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Project data to maximize class separation.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Input data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        X_new : ndarray of shape (n_samples, n_components)\u001b[0m\n",
       "\u001b[0;34m            Transformed data.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lsqr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transform not implemented for 'lsqr' \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                      \u001b[0;34m\"solver (use 'svd' or 'eigen').\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxbar_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eigen'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalings_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_components\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Estimate probability.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Input data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        C : ndarray of shape (n_samples, n_classes)\u001b[0m\n",
       "\u001b[0;34m            Estimated probabilities.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Estimate log probability.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Input data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        C : ndarray of shape (n_samples, n_classes)\u001b[0m\n",
       "\u001b[0;34m            Estimated log probabilities.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiny\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Apply decision function to an array of samples.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        The decision function is equal (up to a constant factor) to the\u001b[0m\n",
       "\u001b[0;34m        log-posterior of the model, i.e. `log p(y = k | x)`. In a binary\u001b[0m\n",
       "\u001b[0;34m        classification setting this instead corresponds to the difference\u001b[0m\n",
       "\u001b[0;34m        `log p(y = 1 | x) - log p(y = 0 | x)`. See :ref:`lda_qda_math`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
       "\u001b[0;34m            Array of samples (test vectors).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        C : ndarray of shape (n_samples,) or (n_samples, n_classes)\u001b[0m\n",
       "\u001b[0;34m            Decision function values related to each class, per sample.\u001b[0m\n",
       "\u001b[0;34m            In the two-class case, the shape is (n_samples,), giving the\u001b[0m\n",
       "\u001b[0;34m            log likelihood ratio of the positive class.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Only override for the doc\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/nlpiaenv/lib/python3.7/site-packages/sklearn/discriminant_analysis.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "LDA??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02435253, 0.48411019])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
